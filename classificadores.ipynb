{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importando bibliotecas</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n",
      "1.18.5\n",
      "3.8.3 (default, May 19 2020, 06:50:17) [MSC v.1916 64 bit (AMD64)]\n",
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(sys.version)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pré-processamento dos dados</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Carregando o dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nomes das colunas\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 42)\n",
      "Dimensions of the Test set: (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "# KDDTrain+_2.csv & KDDTest+_2.csv are the datafiles without the last column about the difficulty score\n",
    "# these have already been removed.\n",
    "df = pd.read_csv(\"KDDTrain+_2.csv\", header=None, names = col_names)\n",
    "df_test = pd.read_csv(\"KDDTest+_2.csv\", header=None, names = col_names)\n",
    "\n",
    "# shape, this gives the dimensions of the dataset\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Selecionando as colunas desejadas para cada ataque</h2>\n",
    "Baseado no artigo: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.677.8198&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'col_names_dos = [\"num_failed_logins\",\\n    \"logged_in\",\"count\",\"same_srv_rate\",\\n    \"srv_diff_host_rate\",   \\n    \"dst_host_srv_diff_host_rate\", \"label\"]\\n\\ncol_names_probe = [\"logged_in\",\"serror_rate\",\"rerror_rate\",\"same_srv_rate\",\\n    \"dst_host_srv_count\",\\n    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\", \"label\"]\\n\\ncol_names_u2r = [\"urgent\",\"root_shell\",\"num_shells\",\"is_host_login\",\"dst_host_srv_count\",\\n    \"dst_host_serror_rate\", \"label\"]\\n\\ncol_names_r2l = [\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\\n    \"num_failed_logins\",\\n    \"logged_in\",\"num_shells\",\"num_access_files\",\\n    \"is_host_login\",\"is_guest_login\",\"srv_count\",\"rerror_rate\",\"srv_rerror_rate\",\\n    \"srv_diff_host_rate\",\"dst_host_serror_rate\",\\n    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\", \"label\"]'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''col_names_dos = [\"num_failed_logins\",\n",
    "    \"logged_in\",\"count\",\"same_srv_rate\",\n",
    "    \"srv_diff_host_rate\",   \n",
    "    \"dst_host_srv_diff_host_rate\", \"label\"]\n",
    "\n",
    "col_names_probe = [\"logged_in\",\"serror_rate\",\"rerror_rate\",\"same_srv_rate\",\n",
    "    \"dst_host_srv_count\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\", \"label\"]\n",
    "\n",
    "col_names_u2r = [\"urgent\",\"root_shell\",\"num_shells\",\"is_host_login\",\"dst_host_srv_count\",\n",
    "    \"dst_host_serror_rate\", \"label\"]\n",
    "\n",
    "col_names_r2l = [\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"num_failed_logins\",\n",
    "    \"logged_in\",\"num_shells\",\"num_access_files\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"srv_count\",\"rerror_rate\",\"srv_rerror_rate\",\n",
    "    \"srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\", \"label\"]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Funções auxiliares</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLabelEncoder(df, df_test, categorical_columns):\n",
    "    df_categorical_values = df[categorical_columns]\n",
    "    testdf_categorical_values = df_test[categorical_columns]\n",
    "    uniqueVal = {}\n",
    "    dumcols = []\n",
    "    for st in categorical_columns:\n",
    "        aux = sorted(df[st].unique())\n",
    "        uniqueVal[st] = [st + '_' + x for x in aux]\n",
    "        dumcols = dumcols + uniqueVal[st]\n",
    "    uniqueValTest = {}   \n",
    "    testdumcols = []\n",
    "    for st in categorical_columns:\n",
    "        aux = sorted(df_test[st].unique())\n",
    "        uniqueValTest[st] = [st + '_' + x for x in aux]\n",
    "        testdumcols = testdumcols + uniqueValTest[st]\n",
    "    df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "    testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "    enc = OneHotEncoder()\n",
    "    df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "    df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "    # test set\n",
    "    testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "    testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "    if 'service' in categorical_columns:\n",
    "        trainservice=df['service'].tolist()\n",
    "        testservice= df_test['service'].tolist()\n",
    "        difference=list(set(trainservice) - set(testservice))\n",
    "        string = 'service_'\n",
    "        difference=[string + x for x in difference]\n",
    "        for col in difference:\n",
    "            testdf_cat_data[col] = 0\n",
    "    newdf=df.join(df_cat_data)\n",
    "    for st in categorical_columns:\n",
    "        newdf.drop(st, axis=1, inplace=True)\n",
    "    # test data\n",
    "    newdf_test=df_test.join(testdf_cat_data)\n",
    "    for st in categorical_columns:\n",
    "        newdf_test.drop(st, axis=1, inplace=True)\n",
    "    return (newdf, newdf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitClass(df, df_test, classe):\n",
    "    # take label column\n",
    "    newdf = df.copy()\n",
    "    newdf_test = df_test.copy()\n",
    "    labeldf=newdf['label']\n",
    "    labeldf_test=newdf_test['label']\n",
    "    # change the label column\n",
    "    newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                               'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                               ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                               'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "    newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                               'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                               ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                               'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "    # put the new label column back\n",
    "    newdf['label'] = newlabeldf\n",
    "    newdf_test['label'] = newlabeldf_test\n",
    "    to_drop = []\n",
    "    for x in range(4):\n",
    "        c = x + 1\n",
    "        if (c == classe):\n",
    "            continue\n",
    "        to_drop.append(c)\n",
    "    dfClasse = newdf[~newdf['label'].isin(to_drop)]\n",
    "    dfClasse_test = newdf_test[~newdf_test['label'].isin(to_drop)]\n",
    "    return (dfClasse, dfClasse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataFrame(df):\n",
    "    X = df.drop('label', 1)\n",
    "    Y = df.label\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LabelEncoder</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          normal\n",
       "1          normal\n",
       "2         neptune\n",
       "3          normal\n",
       "4          normal\n",
       "           ...   \n",
       "125968    neptune\n",
       "125969     normal\n",
       "125970     normal\n",
       "125971    neptune\n",
       "125972     normal\n",
       "Name: label, Length: 125973, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2, df2_test = processLabelEncoder(df, df_test, ['protocol_type', 'service', 'flag'])\n",
    "df2.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113270, 123)\n",
      "(17171, 123)\n",
      "(78999, 123)\n",
      "(12132, 123)\n",
      "(68338, 123)\n",
      "(12596, 123)\n",
      "(67395, 123)\n",
      "(9778, 123)\n"
     ]
    }
   ],
   "source": [
    "dfDos, dfDos_test = splitClass(df2, df2_test, 1)\n",
    "print(dfDos.shape)\n",
    "print(dfDos_test.shape)\n",
    "X_DoS, Y_DoS = splitDataFrame(dfDos)\n",
    "X_DoS_test, Y_DoS_test = splitDataFrame(dfDos_test)\n",
    "\n",
    "dfProbe, dfProbe_test = splitClass(df2, df2_test, 2)\n",
    "print(dfProbe.shape)\n",
    "print(dfProbe_test.shape)\n",
    "X_Probe, Y_Probe = splitDataFrame(dfProbe)\n",
    "X_Probe_test, Y_Probe_test = splitDataFrame(dfProbe_test)\n",
    "\n",
    "dfr2l, dfr2l_test = splitClass(df2, df2_test, 3)\n",
    "print(dfr2l.shape)\n",
    "print(dfr2l_test.shape)\n",
    "X_R2L, Y_R2L = splitDataFrame(dfr2l)\n",
    "X_R2L_test, Y_R2L_test = splitDataFrame(dfr2l_test)\n",
    "\n",
    "dfu2r, dfu2r_test = splitClass(df2, df2_test, 4)\n",
    "print(dfu2r.shape)\n",
    "print(dfu2r_test.shape)\n",
    "X_U2R, Y_U2R = splitDataFrame(dfu2r)\n",
    "X_U2R_test, Y_U2R_test = splitDataFrame(dfu2r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duration',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'land',\n",
       " 'wrong_fragment',\n",
       " 'urgent',\n",
       " 'hot',\n",
       " 'num_failed_logins',\n",
       " 'logged_in',\n",
       " 'num_compromised',\n",
       " 'root_shell',\n",
       " 'su_attempted',\n",
       " 'num_root',\n",
       " 'num_file_creations',\n",
       " 'num_shells',\n",
       " 'num_access_files',\n",
       " 'num_outbound_cmds',\n",
       " 'is_host_login',\n",
       " 'is_guest_login',\n",
       " 'count',\n",
       " 'srv_count',\n",
       " 'serror_rate',\n",
       " 'srv_serror_rate',\n",
       " 'rerror_rate',\n",
       " 'srv_rerror_rate',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'srv_diff_host_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate',\n",
       " 'dst_host_rerror_rate',\n",
       " 'dst_host_srv_rerror_rate',\n",
       " 'protocol_type_icmp',\n",
       " 'protocol_type_tcp',\n",
       " 'protocol_type_udp',\n",
       " 'service_IRC',\n",
       " 'service_X11',\n",
       " 'service_Z39_50',\n",
       " 'service_aol',\n",
       " 'service_auth',\n",
       " 'service_bgp',\n",
       " 'service_courier',\n",
       " 'service_csnet_ns',\n",
       " 'service_ctf',\n",
       " 'service_daytime',\n",
       " 'service_discard',\n",
       " 'service_domain',\n",
       " 'service_domain_u',\n",
       " 'service_echo',\n",
       " 'service_eco_i',\n",
       " 'service_ecr_i',\n",
       " 'service_efs',\n",
       " 'service_exec',\n",
       " 'service_finger',\n",
       " 'service_ftp',\n",
       " 'service_ftp_data',\n",
       " 'service_gopher',\n",
       " 'service_harvest',\n",
       " 'service_hostnames',\n",
       " 'service_http',\n",
       " 'service_http_2784',\n",
       " 'service_http_443',\n",
       " 'service_http_8001',\n",
       " 'service_imap4',\n",
       " 'service_iso_tsap',\n",
       " 'service_klogin',\n",
       " 'service_kshell',\n",
       " 'service_ldap',\n",
       " 'service_link',\n",
       " 'service_login',\n",
       " 'service_mtp',\n",
       " 'service_name',\n",
       " 'service_netbios_dgm',\n",
       " 'service_netbios_ns',\n",
       " 'service_netbios_ssn',\n",
       " 'service_netstat',\n",
       " 'service_nnsp',\n",
       " 'service_nntp',\n",
       " 'service_ntp_u',\n",
       " 'service_other',\n",
       " 'service_pm_dump',\n",
       " 'service_pop_2',\n",
       " 'service_pop_3',\n",
       " 'service_printer',\n",
       " 'service_private',\n",
       " 'service_red_i',\n",
       " 'service_remote_job',\n",
       " 'service_rje',\n",
       " 'service_shell',\n",
       " 'service_smtp',\n",
       " 'service_sql_net',\n",
       " 'service_ssh',\n",
       " 'service_sunrpc',\n",
       " 'service_supdup',\n",
       " 'service_systat',\n",
       " 'service_telnet',\n",
       " 'service_tftp_u',\n",
       " 'service_tim_i',\n",
       " 'service_time',\n",
       " 'service_urh_i',\n",
       " 'service_urp_i',\n",
       " 'service_uucp',\n",
       " 'service_uucp_path',\n",
       " 'service_vmnet',\n",
       " 'service_whois',\n",
       " 'flag_OTH',\n",
       " 'flag_REJ',\n",
       " 'flag_RSTO',\n",
       " 'flag_RSTOS0',\n",
       " 'flag_RSTR',\n",
       " 'flag_S0',\n",
       " 'flag_S1',\n",
       " 'flag_S2',\n",
       " 'flag_S3',\n",
       " 'flag_SF',\n",
       " 'flag_SH']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames=list(X_DoS)\n",
    "colNames_test=list(X_DoS_test)\n",
    "colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalizando dados</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...       0.0        0.0   \n",
       "1                  0          0                0  ...       0.0        0.0   \n",
       "2                  0          0                0  ...       0.0        0.0   \n",
       "3                  0          1                0  ...       0.0        0.0   \n",
       "4                  0          1                0  ...       0.0        0.0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "2          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "3          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "4          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "   flag_SH  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sem normalização\n",
    "X_DoS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>service_http_2784</th>\n",
       "      <th>service_urh_i</th>\n",
       "      <th>service_red_i</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_http_8001</th>\n",
       "      <th>service_harvest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>14515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1022</td>\n",
       "      <td>387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0          0          0     0               0       0    0   \n",
       "1         0          0          0     0               0       0    0   \n",
       "2         2      12983          0     0               0       0    0   \n",
       "5         0        267      14515     0               0       0    0   \n",
       "6         0       1022        387     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_S2  flag_S3  \\\n",
       "0                  0          0                0  ...      0.0      0.0   \n",
       "1                  0          0                0  ...      0.0      0.0   \n",
       "2                  0          0                0  ...      0.0      0.0   \n",
       "5                  0          1                0  ...      0.0      0.0   \n",
       "6                  0          1                0  ...      0.0      0.0   \n",
       "\n",
       "   flag_SF  flag_SH  service_http_2784  service_urh_i  service_red_i  \\\n",
       "0      0.0      0.0                  0              0              0   \n",
       "1      0.0      0.0                  0              0              0   \n",
       "2      1.0      0.0                  0              0              0   \n",
       "5      1.0      0.0                  0              0              0   \n",
       "6      1.0      0.0                  0              0              0   \n",
       "\n",
       "   service_aol  service_http_8001  service_harvest  \n",
       "0            0                  0                0  \n",
       "1            0                  0                0  \n",
       "2            0                  0                0  \n",
       "5            0                  0                0  \n",
       "6            0                  0                0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_DoS_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerDoS = preprocessing.StandardScaler().fit(X_DoS)\n",
    "X_DoS = scalerDoS.transform(X_DoS)\n",
    "X_DoS_test = scalerDoS.transform(X_DoS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09931945, -0.02416949, -0.05230875, ..., -0.01993587,\n",
       "         0.81604613, -0.00420205],\n",
       "       [-0.09931945, -0.02523933, -0.05230875, ..., -0.01993587,\n",
       "         0.81604613, -0.00420205],\n",
       "       [-0.09931945, -0.02569207, -0.05230875, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205],\n",
       "       ...,\n",
       "       [-0.09931945, -0.01877379, -0.04470814, ..., -0.01993587,\n",
       "         0.81604613, -0.00420205],\n",
       "       [-0.09931945, -0.02569207, -0.05230875, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205],\n",
       "       [-0.09931945, -0.02522383, -0.05230875, ..., -0.01993587,\n",
       "         0.81604613, -0.00420205]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalizado\n",
    "X_DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09931945, -0.02569207, -0.05230875, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205],\n",
       "       [-0.09931945, -0.02569207, -0.05230875, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205],\n",
       "       [-0.09733769,  0.01456792, -0.05230875, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205],\n",
       "       ...,\n",
       "       [-0.09931945, -0.02470906, -0.03374267, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205],\n",
       "       [-0.09931945,  0.14343524,  0.11225242, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205],\n",
       "       [-0.09931945, -0.02556183, -0.05147743, ..., -0.01993587,\n",
       "        -1.22542092, -0.00420205]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_DoS_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 4.910e+02, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 1.460e+02, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [0.000e+00, 2.231e+03, 3.840e+02, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 1.510e+02, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"Desnormalizado\"\n",
    "scalerDoS.inverse_transform(X_DoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.0000e+00, 1.2983e+04, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [0.0000e+00, 3.1700e+02, 9.3800e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [0.0000e+00, 5.4540e+04, 8.3140e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [0.0000e+00, 4.2000e+01, 4.2000e+01, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalerDoS.inverse_transform(X_DoS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerProbe = preprocessing.StandardScaler().fit(X_Probe)\n",
    "X_Probe = scalerProbe.transform(X_Probe)\n",
    "X_Probe_test = scalerProbe.transform(X_Probe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerR2L = preprocessing.StandardScaler().fit(X_R2L)\n",
    "X_R2L = scalerR2L.transform(X_R2L)\n",
    "X_R2L_test = scalerR2L.transform(X_R2L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerU2R = preprocessing.StandardScaler().fit(X_U2R)\n",
    "X_U2R = scalerU2R.transform(X_U2R)\n",
    "X_U2R_test = scalerU2R.transform(X_U2R_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Redistribuição dos datasets</h3>\n",
    "Os classificadores para os ataques U2R e R2L, especialmente, não estavam atingindo bons resultados. A forma que encontrei de sanar isso (e acho que para nossos propósitos não tem nenhum problema) foi retirar 20% do conjunto de teste e adicionar ao conjunto de treino, ou colocando como conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainValTest(X, Y, X_test, Y_test, porcent):\n",
    "    X_cv, X_testr = np.array_split(X_test, [int(X_test.shape[0]*porcent)])\n",
    "    Y_cv, Y_testr = np.array_split(Y_test, [int(Y_test.shape[0]*porcent)])\n",
    "    X_train = np.concatenate((X, X_cv),axis=0)\n",
    "    Y_train = np.concatenate((Y, Y_cv),axis=0)\n",
    "    train_indices = np.full((X.shape[0],),-1,dtype=int)\n",
    "    test_indices = np.full((X_cv.shape[0],), 0, dtype=int)\n",
    "    test_fold = np.append(train_indices, test_indices)\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_cv.shape)\n",
    "    print(Y_cv.shape)\n",
    "    print(X_testr.shape)\n",
    "    print(Y_testr.shape)\n",
    "    print(test_fold.shape)\n",
    "    print('')\n",
    "    return (X_train, pd.Series(Y_train), X_cv, pd.Series(Y_cv), X_testr, pd.Series(Y_testr), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116704, 122)\n",
      "(116704,)\n",
      "(3434, 122)\n",
      "(3434,)\n",
      "(13737, 122)\n",
      "(13737,)\n",
      "(116704,)\n",
      "\n",
      "(81425, 122)\n",
      "(81425,)\n",
      "(2426, 122)\n",
      "(2426,)\n",
      "(9706, 122)\n",
      "(9706,)\n",
      "(81425,)\n",
      "\n",
      "(70857, 122)\n",
      "(70857,)\n",
      "(2519, 122)\n",
      "(2519,)\n",
      "(10077, 122)\n",
      "(10077,)\n",
      "(70857,)\n",
      "\n",
      "(69350, 122)\n",
      "(69350,)\n",
      "(1955, 122)\n",
      "(1955,)\n",
      "(7823, 122)\n",
      "(7823,)\n",
      "(69350,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_DoS_train, Y_DoS_train, X_DoS_cv, Y_DoS_cv, X_DoS_testr, Y_DoS_testr, ps_DoS = splitTrainValTest(X_DoS, Y_DoS, X_DoS_test, Y_DoS_test, 0.2)\n",
    "X_Probe_train, Y_Probe_train, X_Probe_cv, Y_Probe_cv, X_Probe_testr, Y_Probe_testr, ps_Probe = splitTrainValTest(X_Probe, Y_Probe, X_Probe_test, Y_Probe_test, 0.2)\n",
    "X_R2L_train, Y_R2L_train, X_R2L_cv, Y_R2L_cv, X_R2L_testr, Y_R2L_testr, ps_R2L = splitTrainValTest(X_R2L, Y_R2L, X_R2L_test, Y_R2L_test, 0.2)\n",
    "X_U2R_train, Y_U2R_train, X_U2R_cv, Y_U2R_cv, X_U2R_testr, Y_U2R_testr, ps_U2R = splitTrainValTest(X_U2R, Y_U2R, X_U2R_test, Y_U2R_test, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classificadores</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarModelo(model, X, Y, X_test, Y_test, classe):\n",
    "    Y = Y.replace(classe, 1)\n",
    "    Y_test = Y_test.replace(classe, 1)\n",
    "    model.fit(X, Y)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    print('Matriz de confusão')\n",
    "    print('')\n",
    "    print(pd.crosstab(Y_test, Y_pred, rownames=['Actual attacks'], colnames=['Predicted attacks']))\n",
    "    print('')\n",
    "    print('Métricas I')\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred, average=\"binary\")\n",
    "    precision = precision_score(Y_test, Y_pred, average=\"binary\")\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"binary\")\n",
    "    print(\"accuracy\")\n",
    "    print(\"%.6f\" %accuracy)\n",
    "    print(\"racall\")\n",
    "    print(\"%.6f\" %recall)\n",
    "    print(\"precision\")\n",
    "    print(\"%.6f\" %precision)\n",
    "    print(\"f1score\")\n",
    "    print(\"%.6f\" %f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinarModelo(model, hyper, X, Y, classe):\n",
    "    Y = Y.replace(classe, 1)\n",
    "    \n",
    "    metricas = ['f1', 'accuracy', 'precision', 'recall']\n",
    "\n",
    "    search = RandomizedSearchCV(estimator = model, param_distributions =hyper, scoring=metricas, verbose=3, refit='f1', n_iter=50, cv = 3, return_train_score=False, n_jobs=2)\n",
    "    search.fit(X, Y);\n",
    "    model = search.best_estimator_\n",
    "    print('Melhor f1-score:', search.best_score_)\n",
    "    print('Melhores parâmetros:', search.best_params_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinarModelo(model, hyper, X, Y, classe, ps):\n",
    "    Y = Y.replace(classe, 1)\n",
    "    \n",
    "    metricas = ['f1', 'accuracy', 'precision', 'recall']\n",
    "\n",
    "    search = RandomizedSearchCV(estimator = model, param_distributions =hyper, scoring=metricas, verbose=3, refit='f1', n_iter=50, cv = ps, return_train_score=False, n_jobs=2)\n",
    "    search.fit(X, Y);\n",
    "    model = search.best_estimator_\n",
    "    print('Melhor f1-score:', search.best_score_)\n",
    "    print('Melhores parâmetros:', search.best_params_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testarModelo(model, X_test, Y_test, classe): \n",
    "    Y_test = Y_test.replace(classe, 1)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    try:\n",
    "        Y_pred = np.around(np.reshape(Y_pred, Y_pred.shape[0]))\n",
    "    except:\n",
    "        print('')\n",
    "    print('Matriz de confusão')\n",
    "    print('')\n",
    "    print(pd.crosstab(Y_test, Y_pred, rownames=['Actual attacks'], colnames=['Predicted attacks']))\n",
    "    print('')\n",
    "    print('Métricas I')\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred, average=\"binary\")\n",
    "    precision = precision_score(Y_test, Y_pred, average=\"binary\")\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"binary\")\n",
    "    print(\"accuracy\")\n",
    "    print(\"%.6f\" %accuracy)\n",
    "    print(\"racall\")\n",
    "    print(\"%.6f\" %recall)\n",
    "    print(\"precision\")\n",
    "    print(\"%.6f\" %precision)\n",
    "    print(\"f1score\")\n",
    "    print(\"%.6f\" %f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decision Tree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_DoS=DecisionTreeClassifier()\n",
    "clf_Probe=DecisionTreeClassifier()\n",
    "clf_R2L=DecisionTreeClassifier()\n",
    "clf_U2R=DecisionTreeClassifier()\n",
    "hyper = {'max_depth': [1, 2, 4, 8, 16],\n",
    "         'min_samples_split': [0.1, 0.3, 0.5, 0.75, 1.0],\n",
    "         'min_samples_leaf': [0.1, 0.25, 0.5],\n",
    "         'random_state': [0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>DoS</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9494   217\n",
      "1                  2667  4793\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.832042\n",
      "racall\n",
      "0.642493\n",
      "precision\n",
      "0.956687\n",
      "f1score\n",
      "0.768725\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(clf_DoS, X_DoS, Y_DoS, X_DoS_test, Y_DoS_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7761    32\n",
      "1                    25  5919\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.995851\n",
      "racall\n",
      "0.995794\n",
      "precision\n",
      "0.994623\n",
      "f1score\n",
      "0.995208\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(clf_DoS, X_DoS_train, Y_DoS_train, X_DoS_testr, Y_DoS_testr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.7398042414355628\n",
      "Melhores parâmetros: {'random_state': 0, 'min_samples_split': 1.0, 'min_samples_leaf': 0.25, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "clf_DoS = treinarModelo(clf_DoS, hyper, X_DoS_train, Y_DoS_train, 1, ps_DoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7677   116\n",
      "1                  2283  3661\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.825362\n",
      "racall\n",
      "0.615915\n",
      "precision\n",
      "0.969288\n",
      "f1score\n",
      "0.753215\n"
     ]
    }
   ],
   "source": [
    "testarModelo(clf_DoS, X_DoS_testr, Y_DoS_testr, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Probe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  8764   947\n",
      "1                   413  2008\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.887900\n",
      "racall\n",
      "0.829409\n",
      "precision\n",
      "0.679526\n",
      "f1score\n",
      "0.747024\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(clf_Probe, X_Probe, Y_Probe, X_Probe_test, Y_Probe_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7741    32\n",
      "1                    47  1886\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.991861\n",
      "racall\n",
      "0.975685\n",
      "precision\n",
      "0.983316\n",
      "f1score\n",
      "0.979486\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(clf_Probe, X_Probe_train, Y_Probe_train, X_Probe_testr, Y_Probe_testr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.9108341323106424\n",
      "Melhores parâmetros: {'random_state': 0, 'min_samples_split': 0.3, 'min_samples_leaf': 0.1, 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "clf_Probe = treinarModelo(clf_Probe, hyper, X_Probe_train, Y_Probe_train, 2, ps_Probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7461   312\n",
      "1                    63  1870\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.961364\n",
      "racall\n",
      "0.967408\n",
      "precision\n",
      "0.857012\n",
      "f1score\n",
      "0.908870\n"
     ]
    }
   ],
   "source": [
    "testarModelo(clf_Probe, X_Probe_testr, Y_Probe_testr, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>R2L</h3>\n",
    "<h4>Todas as features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0    1\n",
      "Actual attacks              \n",
      "0                  9711    0\n",
      "1                  2625  260\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.791601\n",
      "racall\n",
      "0.090121\n",
      "precision\n",
      "1.000000\n",
      "f1score\n",
      "0.165342\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(clf_R2L, X_R2L, Y_R2L, X_R2L_test, Y_R2L_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7658    86\n",
      "1                   119  2214\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.979657\n",
      "racall\n",
      "0.948993\n",
      "precision\n",
      "0.962609\n",
      "f1score\n",
      "0.955752\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(clf_R2L, X_R2L_train, Y_R2L_train, X_R2L_testr, Y_R2L_testr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.0\n",
      "Melhores parâmetros: {'random_state': 0, 'min_samples_split': 0.75, 'min_samples_leaf': 0.1, 'max_depth': 16}\n"
     ]
    }
   ],
   "source": [
    "clf_R2L = treinarModelo(clf_R2L, hyper, X_R2L_train, Y_R2L_train, 3, ps_R2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0\n",
      "Actual attacks         \n",
      "0                  7744\n",
      "1                  2333\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.768483\n",
      "racall\n",
      "0.000000\n",
      "precision\n",
      "0.000000\n",
      "f1score\n",
      "0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "testarModelo(clf_R2L, X_R2L_testr, Y_R2L_testr, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>U2R</h3>\n",
    "<h4>Todas as features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0   1\n",
      "Actual attacks             \n",
      "0                  9707   4\n",
      "1                    55  12\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.993966\n",
      "racall\n",
      "0.179104\n",
      "precision\n",
      "0.750000\n",
      "f1score\n",
      "0.289157\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(clf_U2R, X_U2R, Y_U2R, X_U2R_test, Y_U2R_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0   1\n",
      "Actual attacks             \n",
      "0                  7767   9\n",
      "1                    22  25\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.996037\n",
      "racall\n",
      "0.531915\n",
      "precision\n",
      "0.735294\n",
      "f1score\n",
      "0.617284\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(clf_U2R, X_U2R_train, Y_U2R_train, X_U2R_testr, Y_U2R_testr, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.0\n",
      "Melhores parâmetros: {'random_state': 0, 'min_samples_split': 0.5, 'min_samples_leaf': 0.25, 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "clf_U2R = treinarModelo(clf_U2R, hyper, X_U2R_train, Y_U2R_train, 4, ps_U2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0\n",
      "Actual attacks         \n",
      "0                  7776\n",
      "1                    47\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.993992\n",
      "racall\n",
      "0.000000\n",
      "precision\n",
      "0.000000\n",
      "f1score\n",
      "0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "testarModelo(clf_U2R, X_U2R_testr, Y_U2R_testr, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_DoS=RandomForestClassifier()\n",
    "rfc_Probe=RandomForestClassifier()\n",
    "rfc_R2L=RandomForestClassifier()\n",
    "rfc_U2R=RandomForestClassifier()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 35, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "hyperRFC = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>DoS</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9666    45\n",
      "1                  2074  5386\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.876594\n",
      "racall\n",
      "0.721984\n",
      "precision\n",
      "0.991714\n",
      "f1score\n",
      "0.835622\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(rfc_DoS, X_DoS, Y_DoS, X_DoS_test, Y_DoS_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7788     5\n",
      "1                    28  5916\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.997598\n",
      "racall\n",
      "0.995289\n",
      "precision\n",
      "0.999156\n",
      "f1score\n",
      "0.997219\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(rfc_DoS, X_DoS_train, Y_DoS_train, X_DoS_testr, Y_DoS_testr, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Probe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9511   200\n",
      "1                  1048  1373\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.897132\n",
      "racall\n",
      "0.567121\n",
      "precision\n",
      "0.872854\n",
      "f1score\n",
      "0.687531\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(rfc_Probe, X_Probe, Y_Probe, X_Probe_test, Y_Probe_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7753    20\n",
      "1                    35  1898\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.994333\n",
      "racall\n",
      "0.981893\n",
      "precision\n",
      "0.989572\n",
      "f1score\n",
      "0.985718\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(rfc_Probe, X_Probe_train, Y_Probe_train, X_Probe_testr, Y_Probe_testr, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>R2L</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0\n",
      "Actual attacks         \n",
      "0                  9711\n",
      "1                  2885\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.770959\n",
      "racall\n",
      "0.000000\n",
      "precision\n",
      "0.000000\n",
      "f1score\n",
      "0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(rfc_R2L, X_R2L, Y_R2L, X_R2L_test, Y_R2L_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7650    94\n",
      "1                   166  2167\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.974199\n",
      "racall\n",
      "0.928847\n",
      "precision\n",
      "0.958425\n",
      "f1score\n",
      "0.943404\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(rfc_R2L, X_R2L_train, Y_R2L_train, X_R2L_testr, Y_R2L_testr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.0\n",
      "Melhores parâmetros: {'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "rfc_R2L = treinarModelo(rfc_R2L, hyperRFC, X_R2L_train, Y_R2L_train, 3, ps_R2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7652    92\n",
      "1                   183  2150\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.972710\n",
      "racall\n",
      "0.921560\n",
      "precision\n",
      "0.958965\n",
      "f1score\n",
      "0.939891\n"
     ]
    }
   ],
   "source": [
    "testarModelo(rfc_R2L, X_R2L_testr, Y_R2L_testr, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>U2R</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0  1\n",
      "Actual attacks            \n",
      "0                  9711  0\n",
      "1                    66  1\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.993250\n",
      "racall\n",
      "0.014925\n",
      "precision\n",
      "1.000000\n",
      "f1score\n",
      "0.029412\n"
     ]
    }
   ],
   "source": [
    "#Dataset original\n",
    "aplicarModelo(rfc_U2R, X_U2R, Y_U2R, X_U2R_test, Y_U2R_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0   1\n",
      "Actual attacks             \n",
      "0                  7775   1\n",
      "1                    22  25\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.997060\n",
      "racall\n",
      "0.531915\n",
      "precision\n",
      "0.961538\n",
      "f1score\n",
      "0.684932\n"
     ]
    }
   ],
   "source": [
    "#Dataset redistribuido\n",
    "aplicarModelo(rfc_U2R, X_U2R_train, Y_U2R_train, X_U2R_testr, Y_U2R_testr, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.09523809523809523\n",
      "Melhores parâmetros: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "rfc_U2R = treinarModelo(rfc_U2R, hyperRFC, X_U2R_train, Y_U2R_train, 4, ps_U2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0   1\n",
      "Actual attacks             \n",
      "0                  7774   2\n",
      "1                    22  25\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.996932\n",
      "racall\n",
      "0.531915\n",
      "precision\n",
      "0.925926\n",
      "f1score\n",
      "0.675676\n"
     ]
    }
   ],
   "source": [
    "testarModelo(rfc_U2R, X_U2R_testr, Y_U2R_testr, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>AdaBoostClassifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_DoS=AdaBoostClassifier()\n",
    "ada_Probe=AdaBoostClassifier()\n",
    "ada_R2L=AdaBoostClassifier()\n",
    "ada_U2R=AdaBoostClassifier()\n",
    "\n",
    "hyperAda = {'learning_rate': [0.1, 0.25, 0.5, 0.8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>DoS</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9581   130\n",
      "1                  1235  6225\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.920506\n",
      "racall\n",
      "0.834450\n",
      "precision\n",
      "0.979544\n",
      "f1score\n",
      "0.901194\n"
     ]
    }
   ],
   "source": [
    "#dataset original\n",
    "aplicarModelo(ada_DoS, X_DoS, Y_DoS, X_DoS_test, Y_DoS_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7667   126\n",
      "1                    63  5881\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.986242\n",
      "racall\n",
      "0.989401\n",
      "precision\n",
      "0.979024\n",
      "f1score\n",
      "0.984185\n"
     ]
    }
   ],
   "source": [
    "#dataset redistribuido\n",
    "aplicarModelo(ada_DoS, X_DoS_train, Y_DoS_train, X_DoS_testr, Y_DoS_testr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   4 out of   4 | elapsed:   49.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.9020452099031216\n",
      "Melhores parâmetros: {'learning_rate': 0.8}\n"
     ]
    }
   ],
   "source": [
    "ada_DoS = treinarModelo(ada_DoS, hyperAda, X_DoS_train, Y_DoS_train, 1, ps_DoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7666   127\n",
      "1                   234  5710\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.973721\n",
      "racall\n",
      "0.960633\n",
      "precision\n",
      "0.978242\n",
      "f1score\n",
      "0.969357\n"
     ]
    }
   ],
   "source": [
    "testarModelo(ada_DoS, X_DoS_testr, Y_DoS_testr, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Probe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks    0     1\n",
      "Actual attacks              \n",
      "0                   41  9670\n",
      "1                  421  2000\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.168233\n",
      "racall\n",
      "0.826105\n",
      "precision\n",
      "0.171380\n",
      "f1score\n",
      "0.283869\n"
     ]
    }
   ],
   "source": [
    "#dataset original\n",
    "aplicarModelo(ada_Probe, X_Probe, Y_Probe, X_Probe_test, Y_Probe_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7593   180\n",
      "1                   171  1762\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.963837\n",
      "racall\n",
      "0.911536\n",
      "precision\n",
      "0.907312\n",
      "f1score\n",
      "0.909419\n"
     ]
    }
   ],
   "source": [
    "#dataset redistribuido\n",
    "aplicarModelo(ada_Probe, X_Probe_train, Y_Probe_train, X_Probe_testr, Y_Probe_testr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   4 out of   4 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.7952586206896552\n",
      "Melhores parâmetros: {'learning_rate': 0.8}\n"
     ]
    }
   ],
   "source": [
    "ada_Probe = treinarModelo(ada_Probe, hyperAda, X_Probe_train, Y_Probe_train, 2, ps_Probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7530   243\n",
      "1                   105  1828\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.964146\n",
      "racall\n",
      "0.945680\n",
      "precision\n",
      "0.882665\n",
      "f1score\n",
      "0.913087\n"
     ]
    }
   ],
   "source": [
    "testarModelo(ada_Probe, X_Probe_testr, Y_Probe_testr, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>R2L</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0    1\n",
      "Actual attacks              \n",
      "0                  9710    1\n",
      "1                  2713  172\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.784535\n",
      "racall\n",
      "0.059619\n",
      "precision\n",
      "0.994220\n",
      "f1score\n",
      "0.112492\n"
     ]
    }
   ],
   "source": [
    "#dataset original\n",
    "aplicarModelo(ada_R2L, X_R2L, Y_R2L, X_R2L_test, Y_R2L_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7579   165\n",
      "1                   426  1907\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.941352\n",
      "racall\n",
      "0.817402\n",
      "precision\n",
      "0.920367\n",
      "f1score\n",
      "0.865834\n"
     ]
    }
   ],
   "source": [
    "#dataset redistribuido\n",
    "aplicarModelo(ada_R2L, X_R2L_train, Y_R2L_train, X_R2L_testr, Y_R2L_testr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   4 out of   4 | elapsed:   37.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.039076376554174064\n",
      "Melhores parâmetros: {'learning_rate': 0.8}\n"
     ]
    }
   ],
   "source": [
    "ada_R2L = treinarModelo(ada_R2L, hyperAda, X_R2L_train, Y_R2L_train, 3,ps_R2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  7555   189\n",
      "1                   470  1863\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.934604\n",
      "racall\n",
      "0.798543\n",
      "precision\n",
      "0.907895\n",
      "f1score\n",
      "0.849715\n"
     ]
    }
   ],
   "source": [
    "testarModelo(ada_R2L, X_R2L_testr, Y_R2L_testr, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>U2R</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0  1\n",
      "Actual attacks            \n",
      "0                  9711  0\n",
      "1                    61  6\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.993762\n",
      "racall\n",
      "0.089552\n",
      "precision\n",
      "1.000000\n",
      "f1score\n",
      "0.164384\n"
     ]
    }
   ],
   "source": [
    "#dataset original\n",
    "aplicarModelo(ada_U2R, X_U2R, Y_U2R, X_U2R_test, Y_U2R_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0   1\n",
      "Actual attacks             \n",
      "0                  7771   5\n",
      "1                    27  20\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.995909\n",
      "racall\n",
      "0.425532\n",
      "precision\n",
      "0.800000\n",
      "f1score\n",
      "0.555556\n"
     ]
    }
   ],
   "source": [
    "#dataset redistribuido\n",
    "aplicarModelo(ada_U2R, X_U2R_train, Y_U2R_train, X_U2R_testr, Y_U2R_testr, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   4 out of   4 | elapsed:   37.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor f1-score: 0.4\n",
      "Melhores parâmetros: {'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "ada_U2R = treinarModelo(ada_R2L, hyperAda, X_U2R_train, Y_U2R_train, 4, ps_U2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks     0   1\n",
      "Actual attacks             \n",
      "0                  7771   5\n",
      "1                    28  19\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.995782\n",
      "racall\n",
      "0.404255\n",
      "precision\n",
      "0.791667\n",
      "f1score\n",
      "0.535211\n"
     ]
    }
   ],
   "source": [
    "testarModelo(ada_U2R, X_U2R_testr, Y_U2R_testr, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>DoS</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'DOS'\n",
    "cnnDoS = Sequential()\n",
    "cnnDoS.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnDoS.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnDoS.add(MaxPooling1D(pool_size=2))\n",
    "cnnDoS.add(Flatten())\n",
    "cnnDoS.add(Dense(128, activation=\"relu\"))\n",
    "cnnDoS.add(Dropout(0.5))\n",
    "cnnDoS.add(Dense(1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnDoS.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_DoS = np.reshape(X_DoS, (X_DoS.shape[0], X_DoS.shape[1], 1))\n",
    "x_DoS_cv = np.reshape(X_DoS_cv, (X_DoS_cv.shape[0], X_DoS_cv.shape[1], 1))\n",
    "x_DoS_testr = np.reshape(X_DoS_testr, (X_DoS_testr.shape[0], X_DoS_testr.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0174 - f1_m: 0.9946\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.82250, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0175 - f1_m: 0.9946 - val_loss: 0.7200 - val_f1_m: 0.8225\n",
      "Epoch 2/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0048 - f1_m: 0.9985\n",
      "Epoch 00002: val_f1_m improved from 0.82250 to 0.89702, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 0.0048 - f1_m: 0.9985 - val_loss: 0.5842 - val_f1_m: 0.8970\n",
      "Epoch 3/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0038 - f1_m: 0.9988\n",
      "Epoch 00003: val_f1_m improved from 0.89702 to 0.89763, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0038 - f1_m: 0.9988 - val_loss: 0.6206 - val_f1_m: 0.8976\n",
      "Epoch 4/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0025 - f1_m: 0.9992\n",
      "Epoch 00004: val_f1_m did not improve from 0.89763\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0025 - f1_m: 0.9992 - val_loss: 0.7635 - val_f1_m: 0.8497\n",
      "Epoch 5/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0020 - f1_m: 0.9993\n",
      "Epoch 00005: val_f1_m did not improve from 0.89763\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0020 - f1_m: 0.9993 - val_loss: 0.6629 - val_f1_m: 0.8949\n",
      "Epoch 6/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0017 - f1_m: 0.9993\n",
      "Epoch 00006: val_f1_m did not improve from 0.89763\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0017 - f1_m: 0.9993 - val_loss: 0.6672 - val_f1_m: 0.8474\n",
      "Epoch 7/50\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 0.0014 - f1_m: 0.9994\n",
      "Epoch 00007: val_f1_m did not improve from 0.89763\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0014 - f1_m: 0.9994 - val_loss: 0.6438 - val_f1_m: 0.8544\n",
      "Epoch 8/50\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0015 - f1_m: 0.9994\n",
      "Epoch 00008: val_f1_m did not improve from 0.89763\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0015 - f1_m: 0.9994 - val_loss: 0.9485 - val_f1_m: 0.8560\n",
      "Epoch 9/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0013 - f1_m: 0.9995\n",
      "Epoch 00009: val_f1_m did not improve from 0.89763\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0013 - f1_m: 0.9995 - val_loss: 0.7059 - val_f1_m: 0.8543\n",
      "Epoch 10/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0013 - f1_m: 0.9995\n",
      "Epoch 00010: val_f1_m improved from 0.89763 to 0.90531, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0013 - f1_m: 0.9995 - val_loss: 0.5523 - val_f1_m: 0.9053\n",
      "Epoch 11/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0016 - f1_m: 0.9994\n",
      "Epoch 00011: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 0.0016 - f1_m: 0.9994 - val_loss: 0.8411 - val_f1_m: 0.8787\n",
      "Epoch 12/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0011 - f1_m: 0.9995\n",
      "Epoch 00012: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0011 - f1_m: 0.9995 - val_loss: 1.0436 - val_f1_m: 0.8705\n",
      "Epoch 13/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0013 - f1_m: 0.9995\n",
      "Epoch 00013: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0013 - f1_m: 0.9995 - val_loss: 0.6851 - val_f1_m: 0.8697\n",
      "Epoch 14/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0012 - f1_m: 0.9995\n",
      "Epoch 00014: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0012 - f1_m: 0.9995 - val_loss: 0.9402 - val_f1_m: 0.8739\n",
      "Epoch 15/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0012 - f1_m: 0.9995\n",
      "Epoch 00015: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0012 - f1_m: 0.9995 - val_loss: 1.0650 - val_f1_m: 0.8788\n",
      "Epoch 16/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0010 - f1_m: 0.9995\n",
      "Epoch 00016: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0010 - f1_m: 0.9995 - val_loss: 1.0583 - val_f1_m: 0.8759\n",
      "Epoch 17/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0011 - f1_m: 0.9995\n",
      "Epoch 00017: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0011 - f1_m: 0.9995 - val_loss: 0.8737 - val_f1_m: 0.8966\n",
      "Epoch 18/50\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0010 - f1_m: 0.9996\n",
      "Epoch 00018: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0010 - f1_m: 0.9996 - val_loss: 0.4192 - val_f1_m: 0.8932\n",
      "Epoch 19/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0011 - f1_m: 0.9995\n",
      "Epoch 00019: val_f1_m did not improve from 0.90531\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0011 - f1_m: 0.9995 - val_loss: 1.2711 - val_f1_m: 0.8565\n",
      "Epoch 20/50\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 0.0013 - f1_m: 0.9995\n",
      "Epoch 00020: val_f1_m improved from 0.90531 to 0.91341, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0013 - f1_m: 0.9995 - val_loss: 0.7735 - val_f1_m: 0.9134\n",
      "Epoch 21/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 9.2911e-04 - f1_m: 0.9995\n",
      "Epoch 00021: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 9.2814e-04 - f1_m: 0.9995 - val_loss: 0.7851 - val_f1_m: 0.8918\n",
      "Epoch 22/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 9.0238e-04 - f1_m: 0.9996\n",
      "Epoch 00022: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 9.0279e-04 - f1_m: 0.9996 - val_loss: 1.0995 - val_f1_m: 0.8909\n",
      "Epoch 23/50\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0015 - f1_m: 0.9995\n",
      "Epoch 00023: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0015 - f1_m: 0.9995 - val_loss: 0.7255 - val_f1_m: 0.9030\n",
      "Epoch 24/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0011 - f1_m: 0.9995\n",
      "Epoch 00024: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 10ms/step - loss: 0.0011 - f1_m: 0.9995 - val_loss: 0.7403 - val_f1_m: 0.8985\n",
      "Epoch 25/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0010 - f1_m: 0.9996\n",
      "Epoch 00025: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0010 - f1_m: 0.9996 - val_loss: 0.6663 - val_f1_m: 0.9009\n",
      "Epoch 26/50\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 8.8996e-04 - f1_m: 0.9996\n",
      "Epoch 00026: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.8803e-04 - f1_m: 0.9996 - val_loss: 1.5469 - val_f1_m: 0.8824\n",
      "Epoch 27/50\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 8.6495e-04 - f1_m: 0.9995\n",
      "Epoch 00027: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 8.6307e-04 - f1_m: 0.9995 - val_loss: 0.6893 - val_f1_m: 0.8769\n",
      "Epoch 28/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 9.0668e-04 - f1_m: 0.9995\n",
      "Epoch 00028: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 9.0573e-04 - f1_m: 0.9995 - val_loss: 1.3725 - val_f1_m: 0.9029\n",
      "Epoch 29/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 9.8211e-04 - f1_m: 0.9996\n",
      "Epoch 00029: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 9.8109e-04 - f1_m: 0.9996 - val_loss: 0.8520 - val_f1_m: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 8.2825e-04 - f1_m: 0.9996\n",
      "Epoch 00030: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 8.2825e-04 - f1_m: 0.9996 - val_loss: 1.6291 - val_f1_m: 0.8932\n",
      "Epoch 31/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0014 - f1_m: 0.9995\n",
      "Epoch 00031: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 0.0014 - f1_m: 0.9995 - val_loss: 1.0511 - val_f1_m: 0.9067\n",
      "Epoch 32/50\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 7.5363e-04 - f1_m: 0.9996\n",
      "Epoch 00032: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 7.5363e-04 - f1_m: 0.9996 - val_loss: 0.7932 - val_f1_m: 0.8981\n",
      "Epoch 33/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0014 - f1_m: 0.9996\n",
      "Epoch 00033: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0014 - f1_m: 0.9996 - val_loss: 1.0603 - val_f1_m: 0.8974\n",
      "Epoch 34/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 7.3697e-04 - f1_m: 0.9996\n",
      "Epoch 00034: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.4600e-04 - f1_m: 0.9996 - val_loss: 1.0404 - val_f1_m: 0.8853\n",
      "Epoch 35/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 8.7806e-04 - f1_m: 0.9997\n",
      "Epoch 00035: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.7965e-04 - f1_m: 0.9997 - val_loss: 0.5809 - val_f1_m: 0.8943\n",
      "Epoch 36/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 7.5783e-04 - f1_m: 0.9996\n",
      "Epoch 00036: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 7.5576e-04 - f1_m: 0.9996 - val_loss: 0.8135 - val_f1_m: 0.9029\n",
      "Epoch 37/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 8.3132e-04 - f1_m: 0.9996\n",
      "Epoch 00037: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 8.3007e-04 - f1_m: 0.9996 - val_loss: 0.6154 - val_f1_m: 0.8897\n",
      "Epoch 38/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 7.6939e-04 - f1_m: 0.9997\n",
      "Epoch 00038: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 7.6902e-04 - f1_m: 0.9997 - val_loss: 1.6991 - val_f1_m: 0.8306\n",
      "Epoch 39/50\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0010 - f1_m: 0.9996\n",
      "Epoch 00039: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 0.0010 - f1_m: 0.9996 - val_loss: 1.8603 - val_f1_m: 0.8314\n",
      "Epoch 40/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 7.4354e-04 - f1_m: 0.9996\n",
      "Epoch 00040: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 7.4240e-04 - f1_m: 0.9996 - val_loss: 1.4641 - val_f1_m: 0.8775\n",
      "Epoch 41/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 7.0748e-04 - f1_m: 0.9996\n",
      "Epoch 00041: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 7.0731e-04 - f1_m: 0.9996 - val_loss: 0.7848 - val_f1_m: 0.8813\n",
      "Epoch 42/50\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 7.5997e-04 - f1_m: 0.9997\n",
      "Epoch 00042: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 7.5961e-04 - f1_m: 0.9997 - val_loss: 2.2054 - val_f1_m: 0.8156\n",
      "Epoch 43/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0015 - f1_m: 0.9996\n",
      "Epoch 00043: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0015 - f1_m: 0.9996 - val_loss: 1.0810 - val_f1_m: 0.8667\n",
      "Epoch 44/50\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 9.7693e-04 - f1_m: 0.9995\n",
      "Epoch 00044: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 9.7682e-04 - f1_m: 0.9995 - val_loss: 2.1127 - val_f1_m: 0.8221\n",
      "Epoch 45/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0010 - f1_m: 0.9996\n",
      "Epoch 00045: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0010 - f1_m: 0.9996 - val_loss: 1.4969 - val_f1_m: 0.8797\n",
      "Epoch 46/50\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 6.8844e-04 - f1_m: 0.9997\n",
      "Epoch 00046: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 6.8772e-04 - f1_m: 0.9997 - val_loss: 1.7945 - val_f1_m: 0.8514\n",
      "Epoch 47/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 7.0073e-04 - f1_m: 0.9996\n",
      "Epoch 00047: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 6.9965e-04 - f1_m: 0.9996 - val_loss: 1.3289 - val_f1_m: 0.8797\n",
      "Epoch 48/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 8.4373e-04 - f1_m: 0.9996\n",
      "Epoch 00048: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 8.4237e-04 - f1_m: 0.9996 - val_loss: 2.0345 - val_f1_m: 0.8786\n",
      "Epoch 49/50\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0013 - f1_m: 0.9996\n",
      "Epoch 00049: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0013 - f1_m: 0.9996 - val_loss: 1.6084 - val_f1_m: 0.8330\n",
      "Epoch 50/50\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 6.8326e-04 - f1_m: 0.9996\n",
      "Epoch 00050: val_f1_m did not improve from 0.91341\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 6.8226e-04 - f1_m: 0.9996 - val_loss: 1.7249 - val_f1_m: 0.8412\n"
     ]
    }
   ],
   "source": [
    "#Treino\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-best.hdf5\", verbose=1, save_best_only=True, monitor='val_f1_m',mode='max')\n",
    "csv_logger = CSVLogger('results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnnDoS.fit(x_DoS, Y_DoS, batch_size=64, epochs=50, validation_data=(x_DoS_cv, Y_DoS_cv), callbacks=[checkpointer,csv_logger])\n",
    "cnnDoS.save(\"results/cnn_DoS_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7475</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1352</td>\n",
       "      <td>4592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks   0.0   1.0\n",
       "Actual attacks               \n",
       "0                  7475   318\n",
       "1                  1352  4592"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_DoS_pred=cnnDoS.predict(x_DoS_testr)\n",
    "y_DoS_pred = np.around(np.reshape(y_DoS_pred, y_DoS_pred.shape[0]))\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_testr, y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "\n",
      "Predicted attacks   0.0   1.0\n",
      "Actual attacks               \n",
      "0                  7475   318\n",
      "1                  1352  4592\n",
      "\n",
      "Métricas I\n",
      "accuracy\n",
      "0.878431\n",
      "racall\n",
      "0.772544\n",
      "precision\n",
      "0.935234\n",
      "f1score\n",
      "0.846140\n"
     ]
    }
   ],
   "source": [
    "testarModelo(cnnDoS, x_DoS_testr, Y_DoS_testr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Probe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'Probe'\n",
    "cnnProbe = Sequential()\n",
    "cnnProbe.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnProbe.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnProbe.add(MaxPooling1D(pool_size=2))\n",
    "cnnProbe.add(Flatten())\n",
    "cnnProbe.add(Dense(128, activation=\"relu\"))\n",
    "cnnProbe.add(Dropout(0.5))\n",
    "cnnProbe.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnProbe.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_Probe = np.reshape(X_Probe, (X_Probe.shape[0], X_Probe.shape[1], 1))\n",
    "x_Probe_cv = np.reshape(X_Probe_cv, (X_Probe_cv.shape[0], X_Probe_cv.shape[1], 1))\n",
    "x_Probe_testr = np.reshape(X_Probe_testr, (X_Probe_testr.shape[0], X_Probe_testr.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: -2661927.5000 - f1_m: 0.6623\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.49738, saving model to results/checkpoint-best.hdf5\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: -2704463.2500 - f1_m: 0.6622 - val_loss: 5608219.0000 - val_f1_m: 0.4974\n",
      "Epoch 2/50\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: -73035440.0000 - f1_m: 0.6530\n",
      "Epoch 00002: val_f1_m improved from 0.49738 to 0.52562, saving model to results/checkpoint-best.hdf5\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: -73205952.0000 - f1_m: 0.6533 - val_loss: 17671028.0000 - val_f1_m: 0.5256\n",
      "Epoch 3/50\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: -391772320.0000 - f1_m: 0.6533\n",
      "Epoch 00003: val_f1_m improved from 0.52562 to 0.54463, saving model to results/checkpoint-best.hdf5\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: -393677536.0000 - f1_m: 0.6532 - val_loss: -68771928.0000 - val_f1_m: 0.5446\n",
      "Epoch 4/50\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: -1171260672.0000 - f1_m: 0.6550\n",
      "Epoch 00004: val_f1_m improved from 0.54463 to 0.55433, saving model to results/checkpoint-best.hdf5\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: -1170212608.0000 - f1_m: 0.6542 - val_loss: -353027520.0000 - val_f1_m: 0.5543\n",
      "Epoch 5/50\n",
      "1235/1235 [==============================] - ETA: 0s - loss: -2600464640.0000 - f1_m: 0.6541\n",
      "Epoch 00005: val_f1_m did not improve from 0.55433\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: -2600464640.0000 - f1_m: 0.6541 - val_loss: -879430976.0000 - val_f1_m: 0.5510\n",
      "Epoch 6/50\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: -4930475520.0000 - f1_m: 0.6545\n",
      "Epoch 00006: val_f1_m did not improve from 0.55433\n",
      "1235/1235 [==============================] - 14s 12ms/step - loss: -4933146112.0000 - f1_m: 0.6546 - val_loss: -1843001984.0000 - val_f1_m: 0.5332\n",
      "Epoch 7/50\n",
      "1235/1235 [==============================] - ETA: 0s - loss: -8361062400.0000 - f1_m: 0.6534\n",
      "Epoch 00007: val_f1_m did not improve from 0.55433\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: -8361062400.0000 - f1_m: 0.6534 - val_loss: -2993494528.0000 - val_f1_m: 0.5356\n",
      "Epoch 8/50\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: -13172827136.0000 - f1_m: 0.6522\n",
      "Epoch 00008: val_f1_m did not improve from 0.55433\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: -13175755776.0000 - f1_m: 0.6522 - val_loss: -4750693888.0000 - val_f1_m: 0.5340\n",
      "Epoch 9/50\n",
      " 122/1235 [=>............................] - ETA: 11s - loss: -16525450240.0000 - f1_m: 0.6570"
     ]
    }
   ],
   "source": [
    "#Treino\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-best.hdf5\", verbose=1, save_best_only=True, monitor='val_f1_m',mode='max')\n",
    "csv_logger = CSVLogger('results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnnProbe.fit(x_Probe, Y_Probe, batch_size=64, epochs=50, validation_data=(x_Probe_cv, Y_Probe_cv), callbacks=[checkpointer,csv_logger])\n",
    "cnnProbe.save(\"results/cnn_Probe_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testarModelo(cnnProbe, x_Probe_testr, Y_Probe_testr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>R2L</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'Probe'\n",
    "cnnR2L = Sequential()\n",
    "cnnR2L.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnR2L.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnR2L.add(MaxPooling1D(pool_size=2))\n",
    "cnnR2L.add(Flatten())\n",
    "cnnR2L.add(Dense(128, activation=\"relu\"))\n",
    "cnnR2L.add(Dropout(0.5))\n",
    "cnnR2L.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnR2L.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_R2L = np.reshape(X_R2L_train, (X_R2L_train.shape[0], X_R2L_train.shape[1], 1))\n",
    "#x_R2L_cv = np.reshape(X_R2L_cv, (X_R2L_cv.shape[0], X_R2L_cv.shape[1], 1))\n",
    "x_R2L_testr = np.reshape(X_R2L_testr, (X_R2L_testr.shape[0], X_R2L_testr.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-best.hdf5\", verbose=1, save_best_only=True, monitor='val_f1_m',mode='max')\n",
    "csv_logger = CSVLogger('results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnnR2L.fit(x_R2L, Y_R2L_train, batch_size=64, epochs=50, validation_data=(x_R2L_testr, Y_R2L_testr), callbacks=[checkpointer,csv_logger])\n",
    "cnnR2L.save(\"results/cnn_R2L_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnR2L.load_weights(\"results/cnn_R2L_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testarModelo(cnnR2L, x_R2L_testr, Y_R2L_testr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>U2R</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'Probe'\n",
    "cnnU2R = Sequential()\n",
    "cnnU2R.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnU2R.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnU2R.add(MaxPooling1D(pool_size=2))\n",
    "cnnU2R.add(Flatten())\n",
    "cnnU2R.add(Dense(128, activation=\"relu\"))\n",
    "cnnU2R.add(Dropout(0.5))\n",
    "cnnU2R.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnU2R.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_U2R = np.reshape(X_U2R_train, (X_U2R_train.shape[0], X_U2R_train.shape[1], 1))\n",
    "#x_U2R_cv = np.reshape(X_U2R_cv, (X_U2R_cv.shape[0], X_U2R_cv.shape[1], 1))\n",
    "x_U2R_testr = np.reshape(X_U2R_testr, (X_U2R_testr.shape[0], X_U2R_testr.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-best.hdf5\", verbose=1, save_best_only=True, monitor='val_f1_m',mode='max')\n",
    "csv_logger = CSVLogger('results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnnU2R.fit(x_U2R, Y_U2R_train, batch_size=64, epochs=50, validation_data=(x_U2R_testr, Y_U2R_testr), callbacks=[checkpointer,csv_logger])\n",
    "cnnU2R.save(\"results/cnn_U2R_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnR2L.load_weights(\"results/cnn_U2R_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testarModelo(cnnU2R, x_U2R_testr, Y_U2R_testr, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
