{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Intrusion Detection: Analysis of a Feature Selection Mechanism\n",
    "\n",
    "## Method Description\n",
    "\n",
    "### Step 1: Data preprocessing:\n",
    "All features are made numerical using one-Hot-encoding. The features are scaled to avoid features with large values that may weigh too much in the results.\n",
    "\n",
    "### Step 2: Feature Selection:\n",
    "Eliminate redundant and irrelevant data by selecting a subset of relevant features that fully represents the given problem.\n",
    "Univariate feature selection with ANOVA F-test. This analyzes each feature individually to detemine the strength of the relationship between the feature and labels. Using SecondPercentile method (sklearn.feature_selection) to select features based on percentile of the highest scores. \n",
    "When this subset is found: Recursive Feature Elimination (RFE) is applied.\n",
    "\n",
    "### Step 4: Build the model:\n",
    "Decision tree model is built.\n",
    "\n",
    "### Step 5: Prediction & Evaluation (validation):\n",
    "Using the test data to make predictions of the model.\n",
    "Multiple scores are considered such as:accuracy score, recall, f-measure, confusion matrix.\n",
    "perform a 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n",
      "1.18.5\n",
      "3.8.3 (default, May 19 2020, 06:50:17) [MSC v.1916 64 bit (AMD64)]\n",
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(sys.version)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 42)\n",
      "Dimensions of the Test set: (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "# attach the column names to the dataset\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "# KDDTrain+_2.csv & KDDTest+_2.csv are the datafiles without the last column about the difficulty score\n",
    "# these have already been removed.\n",
    "df = pd.read_csv(\"KDDTrain+_2.csv\", header=None, names = col_names)\n",
    "df_test = pd.read_csv(\"KDDTest+_2.csv\", header=None, names = col_names)\n",
    "\n",
    "# shape, this gives the dimensions of the dataset\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample view of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  neptune  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first five rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>182.148945</td>\n",
       "      <td>115.653005</td>\n",
       "      <td>0.521242</td>\n",
       "      <td>0.082951</td>\n",
       "      <td>0.148379</td>\n",
       "      <td>0.032542</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.278485</td>\n",
       "      <td>0.118832</td>\n",
       "      <td>0.120240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>99.206213</td>\n",
       "      <td>110.702741</td>\n",
       "      <td>0.448949</td>\n",
       "      <td>0.188922</td>\n",
       "      <td>0.308997</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.444784</td>\n",
       "      <td>0.445669</td>\n",
       "      <td>0.306557</td>\n",
       "      <td>0.319459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...  dst_host_count  \\\n",
       "count  125973.000000    125973.000000  ...   125973.000000   \n",
       "mean        0.395736         0.279250  ...      182.148945   \n",
       "std         0.489010        23.942042  ...       99.206213   \n",
       "min         0.000000         0.000000  ...        0.000000   \n",
       "25%         0.000000         0.000000  ...       82.000000   \n",
       "50%         0.000000         0.000000  ...      255.000000   \n",
       "75%         1.000000         0.000000  ...      255.000000   \n",
       "max         1.000000      7479.000000  ...      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count       125973.000000           125973.000000           125973.000000   \n",
       "mean           115.653005                0.521242                0.082951   \n",
       "std            110.702741                0.448949                0.188922   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             10.000000                0.050000                0.000000   \n",
       "50%             63.000000                0.510000                0.020000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                125973.000000                125973.000000   \n",
       "mean                      0.148379                     0.032542   \n",
       "std                       0.308997                     0.112564   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         125973.000000             125973.000000         125973.000000   \n",
       "mean               0.284452                  0.278485              0.118832   \n",
       "std                0.444784                  0.445669              0.306557   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             125973.000000  \n",
       "mean                   0.120240  \n",
       "std                    0.319459  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution of Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Training set:\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Label distribution Test set:\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "xterm                13\n",
      "rootkit              13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "udpstorm              2\n",
      "sqlattack             2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Training set:')\n",
    "print(df['label'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data preprocessing:\n",
    "One-Hot-Encoding (one-of-K) is used to to transform all categorical features into binary features. \n",
    "Requirement for One-Hot-encoding:\n",
    "\"The input to this transformer should be a matrix of integers, denoting the values taken on by categorical (discrete) features. The output will be a sparse matrix where each column corresponds to one possible value of one feature. It is assumed that input features take on values in the range [0, n_values).\"\n",
    "\n",
    "Therefore the features first need to be transformed with LabelEncoder, to transform every category to a number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 70 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 23 categories\n",
      "\n",
      "Distribution of categories in service:\n",
      "http        40338\n",
      "private     21853\n",
      "domain_u     9043\n",
      "smtp         7313\n",
      "ftp_data     6860\n",
      "Name: service, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# colums that are categorical and not binary yet: protocol_type (column 2), service (column 3), flag (column 4).\n",
    "# explore categorical features\n",
    "print('Training set:')\n",
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df['service'].value_counts().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 64 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 38 categories\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "print('Test set:')\n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Need to make dummies for all categories as the distribution is fairly even. In total: 3+70+11=84 dummies.\n",
    "### Comparing the results shows that the Test set has fewer categories (6), these need to be added as empty columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert categorical features into a 2D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type   service flag\n",
       "0           tcp  ftp_data   SF\n",
       "1           udp     other   SF\n",
       "2           tcp   private   S0\n",
       "3           tcp      http   SF\n",
       "4           tcp      http   SF"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "categorical_columns=['protocol_type', 'service', 'flag']\n",
    "# insert code to get a list of categorical columns into a variable, categorical_columns\n",
    "categorical_columns=['protocol_type', 'service', 'flag'] \n",
    " # Get the categorical values into a 2D numpy array\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]\n",
    "df_categorical_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make column names for dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
     ]
    }
   ],
   "source": [
    "# protocol type\n",
    "unique_protocol=sorted(df.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2=[string1 + x for x in unique_protocol]\n",
    "# service\n",
    "unique_service=sorted(df.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2=[string2 + x for x in unique_service]\n",
    "# flag\n",
    "unique_flag=sorted(df.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2=[string3 + x for x in unique_flag]\n",
    "# put together\n",
    "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
    "print(dumcols)\n",
    "\n",
    "#do same for test set\n",
    "unique_service_test=sorted(df_test.service.unique())\n",
    "unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features into numbers using LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   protocol_type  service  flag\n",
      "0              1       20     9\n",
      "1              2       44     9\n",
      "2              1       49     5\n",
      "3              1       24     9\n",
      "4              1       24     9\n"
     ]
    }
   ],
   "source": [
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(df_categorical_values_enc.head())\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol_type_icmp</th>\n",
       "      <th>Protocol_type_tcp</th>\n",
       "      <th>Protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>service_courier</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol_type_icmp  Protocol_type_tcp  Protocol_type_udp  service_IRC  \\\n",
       "0                 0.0                1.0                0.0          0.0   \n",
       "1                 0.0                0.0                1.0          0.0   \n",
       "2                 0.0                1.0                0.0          0.0   \n",
       "3                 0.0                1.0                0.0          0.0   \n",
       "4                 0.0                1.0                0.0          0.0   \n",
       "\n",
       "   service_X11  service_Z39_50  service_aol  service_auth  service_bgp  \\\n",
       "0          0.0             0.0          0.0           0.0          0.0   \n",
       "1          0.0             0.0          0.0           0.0          0.0   \n",
       "2          0.0             0.0          0.0           0.0          0.0   \n",
       "3          0.0             0.0          0.0           0.0          0.0   \n",
       "4          0.0             0.0          0.0           0.0          0.0   \n",
       "\n",
       "   service_courier  ...  flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR  flag_S0  \\\n",
       "0              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "1              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "2              0.0  ...       0.0        0.0          0.0        0.0      1.0   \n",
       "3              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "4              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "\n",
       "   flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  \n",
       "0      0.0      0.0      0.0      1.0      0.0  \n",
       "1      0.0      0.0      0.0      1.0      0.0  \n",
       "2      0.0      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      1.0      0.0  \n",
       "4      0.0      0.0      0.0      1.0      0.0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "# test set\n",
    "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "\n",
    "df_cat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 6 missing categories from train set to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['service_http_2784',\n",
       " 'service_red_i',\n",
       " 'service_http_8001',\n",
       " 'service_urh_i',\n",
       " 'service_harvest',\n",
       " 'service_aol']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainservice=df['service'].tolist()\n",
    "testservice= df_test['service'].tolist()\n",
    "difference=list(set(trainservice) - set(testservice))\n",
    "string = 'service_'\n",
    "difference=[string + x for x in difference]\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 84)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in difference:\n",
    "    testdf_cat_data[col] = 0\n",
    "\n",
    "testdf_cat_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join encoded categorical dataframe with the non-categorical dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 123)\n",
      "(22544, 123)\n"
     ]
    }
   ],
   "source": [
    "newdf=df.join(df_cat_data)\n",
    "newdf.drop('flag', axis=1, inplace=True)\n",
    "newdf.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf.drop('service', axis=1, inplace=True)\n",
    "# test data\n",
    "newdf_test=df_test.join(testdf_cat_data)\n",
    "newdf_test.drop('flag', axis=1, inplace=True)\n",
    "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf_test.drop('service', axis=1, inplace=True)\n",
    "print(newdf.shape)\n",
    "print(newdf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into 4 datasets for every attack category\n",
    "## Rename every attack label: 0=normal, 1=DoS, 2=Probe, 3=R2L and 4=U2R.\n",
    "## Replace labels column with new labels column\n",
    "## Make new datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# take label column\n",
    "labeldf=newdf['label']\n",
    "labeldf_test=newdf_test['label']\n",
    "# change the label column\n",
    "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "# put the new label column back\n",
    "newdf['label'] = newlabeldf\n",
    "newdf_test['label'] = newlabeldf_test\n",
    "print(newdf['label'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Dimensions of DoS: (113270, 123)\n",
      "Dimensions of Probe: (78999, 123)\n",
      "Dimensions of R2L: (68338, 123)\n",
      "Dimensions of U2R: (67395, 123)\n",
      "Test:\n",
      "Dimensions of DoS: (17171, 123)\n",
      "Dimensions of Probe: (12132, 123)\n",
      "Dimensions of R2L: (12596, 123)\n",
      "Dimensions of U2R: (9778, 123)\n"
     ]
    }
   ],
   "source": [
    "to_drop_DoS = [2,3,4]\n",
    "to_drop_Probe = [1,3,4]\n",
    "to_drop_R2L = [1,2,4]\n",
    "to_drop_U2R = [1,2,3]\n",
    "DoS_df=newdf[~newdf['label'].isin(to_drop_DoS)];\n",
    "Probe_df=newdf[~newdf['label'].isin(to_drop_Probe)];\n",
    "R2L_df=newdf[~newdf['label'].isin(to_drop_R2L)];\n",
    "U2R_df=newdf[~newdf['label'].isin(to_drop_U2R)];\n",
    "\n",
    "#test\n",
    "DoS_df_test=newdf_test[~newdf_test['label'].isin(to_drop_DoS)];\n",
    "Probe_df_test=newdf_test[~newdf_test['label'].isin(to_drop_Probe)];\n",
    "R2L_df_test=newdf_test[~newdf_test['label'].isin(to_drop_R2L)];\n",
    "U2R_df_test=newdf_test[~newdf_test['label'].isin(to_drop_U2R)];\n",
    "print('Train:')\n",
    "print('Dimensions of DoS:' ,DoS_df.shape)\n",
    "print('Dimensions of Probe:' ,Probe_df.shape)\n",
    "print('Dimensions of R2L:' ,R2L_df.shape)\n",
    "print('Dimensions of U2R:' ,U2R_df.shape)\n",
    "print('Test:')\n",
    "print('Dimensions of DoS:' ,DoS_df_test.shape)\n",
    "print('Dimensions of Probe:' ,Probe_df_test.shape)\n",
    "print('Dimensions of R2L:' ,R2L_df_test.shape)\n",
    "print('Dimensions of U2R:' ,U2R_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Feature Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframes into X & Y\n",
    "# assign X as a dataframe of feautures and Y as a series of outcome variables\n",
    "X_DoS = DoS_df.drop('label',1)\n",
    "Y_DoS = DoS_df.label\n",
    "X_Probe = Probe_df.drop('label',1)\n",
    "Y_Probe = Probe_df.label\n",
    "X_R2L = R2L_df.drop('label',1)\n",
    "Y_R2L = R2L_df.label\n",
    "X_U2R = U2R_df.drop('label',1)\n",
    "Y_U2R = U2R_df.label\n",
    "# test set\n",
    "X_DoS_test = DoS_df_test.drop('label',1)\n",
    "Y_DoS_test = DoS_df_test.label\n",
    "X_Probe_test = Probe_df_test.drop('label',1)\n",
    "Y_Probe_test = Probe_df_test.label\n",
    "X_R2L_test = R2L_df_test.drop('label',1)\n",
    "Y_R2L_test = R2L_df_test.label\n",
    "X_U2R_test = U2R_df_test.drop('label',1)\n",
    "Y_U2R_test = U2R_df_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a list of feature names for later use (it is the same for every attack category). Column names are dropped at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames=list(X_DoS)\n",
    "colNames_test=list(X_DoS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use StandardScaler() to scale the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler1 = preprocessing.StandardScaler().fit(X_DoS)\n",
    "X_DoS=scaler1.transform(X_DoS) \n",
    "scaler2 = preprocessing.StandardScaler().fit(X_Probe)\n",
    "X_Probe=scaler2.transform(X_Probe) \n",
    "scaler3 = preprocessing.StandardScaler().fit(X_R2L)\n",
    "X_R2L=scaler3.transform(X_R2L) \n",
    "scaler4 = preprocessing.StandardScaler().fit(X_U2R)\n",
    "X_U2R=scaler4.transform(X_U2R) \n",
    "# test data\n",
    "scaler5 = preprocessing.StandardScaler().fit(X_DoS_test)\n",
    "X_DoS_test=scaler5.transform(X_DoS_test) \n",
    "scaler6 = preprocessing.StandardScaler().fit(X_Probe_test)\n",
    "X_Probe_test=scaler6.transform(X_Probe_test) \n",
    "scaler7 = preprocessing.StandardScaler().fit(X_R2L_test)\n",
    "X_R2L_test=scaler7.transform(X_R2L_test) \n",
    "scaler8 = preprocessing.StandardScaler().fit(X_U2R_test)\n",
    "X_U2R_test=scaler8.transform(X_U2R_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the Standard Deviation is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_DoS.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Probe.std(axis=0);\n",
    "X_R2L.std(axis=0);\n",
    "X_U2R.std(axis=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Univariate Feature Selection using ANOVA F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [ 16  44  63  66  68  86 114] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(113270, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#univariate feature selection with ANOVA F-test. using secondPercentile method, then RFE\n",
    "#Scikit-learn exposes feature selection routines as objects that implement the transform method\n",
    "#SelectPercentile: removes all but a user-specified highest scoring percentage of features\n",
    "#f_classif: ANOVA F-value between label/feature for classification tasks.\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "np.seterr(divide='ignore', invalid='ignore');\n",
    "selector=SelectPercentile(f_classif, percentile=10)\n",
    "X_newDoS = selector.fit_transform(X_DoS,Y_DoS)\n",
    "X_newDoS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features that were selected: DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logged_in',\n",
       " 'count',\n",
       " 'serror_rate',\n",
       " 'srv_serror_rate',\n",
       " 'same_srv_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate',\n",
       " 'service_http',\n",
       " 'flag_S0',\n",
       " 'flag_SF']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_DoS=[i for i, x in enumerate(true) if x]\n",
    "newcolname_DoS=list( colNames[i] for i in newcolindex_DoS )\n",
    "newcolname_DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [ 4 16] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78999, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_newProbe = selector.fit_transform(X_Probe,Y_Probe)\n",
    "X_newProbe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features that were selected: Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logged_in',\n",
       " 'rerror_rate',\n",
       " 'srv_rerror_rate',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'dst_host_rerror_rate',\n",
       " 'dst_host_srv_rerror_rate',\n",
       " 'Protocol_type_icmp',\n",
       " 'service_eco_i',\n",
       " 'service_private',\n",
       " 'flag_SF']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_Probe=[i for i, x in enumerate(true) if x]\n",
    "newcolname_Probe=list( colNames[i] for i in newcolindex_Probe )\n",
    "newcolname_Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [  4  16  43  44  46  47  48  49  50  51  54  57  58  62  63  64  66  67\n",
      "  68  70  71  72  73  74  76  77  78  79  80  81  82  83  86  87  89  92\n",
      "  93  96  98  99 100 107 108 109 110 114] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68338, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_newR2L = selector.fit_transform(X_R2L,Y_R2L)\n",
    "X_newR2L.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features that were selected: R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src_bytes',\n",
       " 'dst_bytes',\n",
       " 'hot',\n",
       " 'num_failed_logins',\n",
       " 'is_guest_login',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'service_ftp',\n",
       " 'service_ftp_data',\n",
       " 'service_http',\n",
       " 'service_imap4',\n",
       " 'flag_RSTO']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_R2L=[i for i, x in enumerate(true) if x]\n",
    "newcolname_R2L=list( colNames[i] for i in newcolindex_R2L)\n",
    "newcolname_R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [  4  16  43  44  46  47  48  49  50  51  54  57  58  62  63  64  66  67\n",
      "  68  70  71  72  73  74  75  76  77  78  79  80  81  82  83  86  87  89\n",
      "  92  93  96  98  99 100 107 108 109 110 114] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67395, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_newU2R = selector.fit_transform(X_U2R,Y_U2R)\n",
    "X_newU2R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features that were selected: U2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urgent',\n",
       " 'hot',\n",
       " 'root_shell',\n",
       " 'num_file_creations',\n",
       " 'num_shells',\n",
       " 'srv_diff_host_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'service_ftp_data',\n",
       " 'service_http',\n",
       " 'service_telnet']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_U2R=[i for i, x in enumerate(true) if x]\n",
    "newcolname_U2R=list( colNames[i] for i in newcolindex_U2R)\n",
    "newcolname_U2R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of features selected by Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected for DoS: ['logged_in', 'count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'service_http', 'flag_S0', 'flag_SF']\n",
      "\n",
      "Features selected for Probe: ['logged_in', 'rerror_rate', 'srv_rerror_rate', 'dst_host_srv_count', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'Protocol_type_icmp', 'service_eco_i', 'service_private', 'flag_SF']\n",
      "\n",
      "Features selected for R2L: ['src_bytes', 'dst_bytes', 'hot', 'num_failed_logins', 'is_guest_login', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp', 'service_ftp_data', 'service_http', 'service_imap4', 'flag_RSTO']\n",
      "\n",
      "Features selected for U2R: ['urgent', 'hot', 'root_shell', 'num_file_creations', 'num_shells', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp_data', 'service_http', 'service_telnet']\n"
     ]
    }
   ],
   "source": [
    "print('Features selected for DoS:',newcolname_DoS)\n",
    "print()\n",
    "print('Features selected for Probe:',newcolname_Probe)\n",
    "print()\n",
    "print('Features selected for R2L:',newcolname_R2L)\n",
    "print()\n",
    "print('Features selected for U2R:',newcolname_U2R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The authors state that \"After obtaining the adequate number of features during the univariate selection process, a recursive feature elimination (RFE) was operated with the number of features passed as parameter to identify the features selected\". This either implies that RFE is only used for obtaining the features previously selected but also obtaining the rank. This use of RFE is however very redundant as the features selected can be obtained in another way (Done in this project). One can also not say that the features were selected by RFE, as it was not used for this. The quote could however also imply that only the number 13 from univariate feature selection was used. RFE is then used for feature selection trying to find the best 13 features. With this use of RFE one can actually say that it was used for feature selection. However the authors obtained different numbers of features for every attack category, 12 for DoS, 15 for Probe, 13 for R2L and 11 for U2R. This concludes that it is not clear what mechanism is used for feature selection. \n",
    "\n",
    "## To procede with the data mining, the second option is considered as this uses RFE. From now on the number of features for every attack category is 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Recursive Feature Elimination for feature ranking (Option 1: get importance from previous selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoS Features sorted by their rank:\n",
      "[(1, 'same_srv_rate'), (2, 'count'), (3, 'flag_SF'), (4, 'dst_host_serror_rate'), (5, 'dst_host_same_srv_rate'), (6, 'dst_host_srv_count'), (7, 'dst_host_count'), (8, 'logged_in'), (9, 'serror_rate'), (10, 'dst_host_srv_serror_rate'), (11, 'srv_serror_rate'), (12, 'service_http'), (13, 'flag_S0')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create a decision tree classifier. By convention, clf means 'classifier'\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(clf, n_features_to_select=1)\n",
    "rfe.fit(X_newDoS, Y_DoS)\n",
    "print (\"DoS Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_DoS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe Features sorted by their rank:\n",
      "[(1, 'dst_host_same_src_port_rate'), (2, 'dst_host_srv_count'), (3, 'dst_host_rerror_rate'), (4, 'service_private'), (5, 'logged_in'), (6, 'dst_host_diff_srv_rate'), (7, 'dst_host_srv_diff_host_rate'), (8, 'flag_SF'), (9, 'service_eco_i'), (10, 'rerror_rate'), (11, 'Protocol_type_icmp'), (12, 'dst_host_srv_rerror_rate'), (13, 'srv_rerror_rate')]\n"
     ]
    }
   ],
   "source": [
    "rfe.fit(X_newProbe, Y_Probe)\n",
    "print (\"Probe Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_Probe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2L Features sorted by their rank:\n",
      "[(1, 'src_bytes'), (2, 'dst_bytes'), (3, 'hot'), (4, 'dst_host_srv_diff_host_rate'), (5, 'service_ftp_data'), (6, 'dst_host_same_src_port_rate'), (7, 'dst_host_srv_count'), (8, 'num_failed_logins'), (9, 'service_imap4'), (10, 'is_guest_login'), (11, 'service_ftp'), (12, 'flag_RSTO'), (13, 'service_http')]\n"
     ]
    }
   ],
   "source": [
    "rfe.fit(X_newR2L, Y_R2L)\n",
    " \n",
    "print (\"R2L Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_R2L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U2R Features sorted by their rank:\n",
      "[(1, 'hot'), (2, 'dst_host_srv_count'), (3, 'dst_host_count'), (4, 'root_shell'), (5, 'num_shells'), (6, 'service_ftp_data'), (7, 'dst_host_srv_diff_host_rate'), (8, 'num_file_creations'), (9, 'dst_host_same_src_port_rate'), (10, 'service_telnet'), (11, 'srv_diff_host_rate'), (12, 'service_http'), (13, 'urgent')]\n"
     ]
    }
   ],
   "source": [
    "rfe.fit(X_newU2R, Y_U2R)\n",
    " \n",
    "print (\"U2R Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_U2R)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Recursive Feature Elimination, select 13 features each of 122 (Option 2: get 13 best features from 122 from RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "rfe = RFE(estimator=clf, n_features_to_select=13, step=1)\n",
    "rfe.fit(X_DoS, Y_DoS)\n",
    "X_rfeDoS=rfe.transform(X_DoS)\n",
    "true=rfe.support_\n",
    "rfecolindex_DoS=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_DoS=list(colNames[i] for i in rfecolindex_DoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_Probe, Y_Probe)\n",
    "X_rfeProbe=rfe.transform(X_Probe)\n",
    "true=rfe.support_\n",
    "rfecolindex_Probe=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_Probe=list(colNames[i] for i in rfecolindex_Probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_R2L, Y_R2L)\n",
    "X_rfeR2L=rfe.transform(X_R2L)\n",
    "true=rfe.support_\n",
    "rfecolindex_R2L=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_R2L=list(colNames[i] for i in rfecolindex_R2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_U2R, Y_U2R)\n",
    "X_rfeU2R=rfe.transform(X_U2R)\n",
    "true=rfe.support_\n",
    "rfecolindex_U2R=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_U2R=list(colNames[i] for i in rfecolindex_U2R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of features selected by RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected for DoS: ['src_bytes', 'dst_bytes', 'wrong_fragment', 'num_compromised', 'same_srv_rate', 'diff_srv_rate', 'dst_host_count', 'dst_host_same_srv_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'service_ecr_i', 'flag_RSTR', 'flag_S0']\n",
      "\n",
      "Features selected for Probe: ['src_bytes', 'dst_bytes', 'rerror_rate', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_rerror_rate', 'service_finger', 'service_ftp_data', 'service_http', 'service_private', 'service_smtp', 'service_telnet']\n",
      "\n",
      "Features selected for R2L: ['duration', 'src_bytes', 'dst_bytes', 'hot', 'num_failed_logins', 'num_access_files', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp_data', 'service_imap4']\n",
      "\n",
      "Features selected for U2R: ['duration', 'src_bytes', 'dst_bytes', 'hot', 'root_shell', 'num_file_creations', 'num_shells', 'srv_count', 'dst_host_count', 'dst_host_same_srv_rate', 'dst_host_srv_diff_host_rate', 'service_ftp_data', 'service_other']\n"
     ]
    }
   ],
   "source": [
    "print('Features selected for DoS:',rfecolname_DoS)\n",
    "print()\n",
    "print('Features selected for Probe:',rfecolname_Probe)\n",
    "print()\n",
    "print('Features selected for R2L:',rfecolname_R2L)\n",
    "print()\n",
    "print('Features selected for U2R:',rfecolname_U2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113270, 13)\n",
      "(78999, 13)\n",
      "(68338, 13)\n",
      "(67395, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_rfeDoS.shape)\n",
    "print(X_rfeProbe.shape)\n",
    "print(X_rfeR2L.shape)\n",
    "print(X_rfeU2R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the model:\n",
    "### Classifier is trained for all features and for reduced features, for later comparison.\n",
    "#### The classifier model itself is stored in the clf variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all features\n",
    "clf_DoS=DecisionTreeClassifier(random_state=0)\n",
    "clf_Probe=DecisionTreeClassifier(random_state=0)\n",
    "clf_R2L=DecisionTreeClassifier(random_state=0)\n",
    "clf_U2R=DecisionTreeClassifier(random_state=0)\n",
    "clf_DoS.fit(X_DoS, Y_DoS)\n",
    "clf_Probe.fit(X_Probe, Y_Probe)\n",
    "clf_R2L.fit(X_R2L, Y_R2L)\n",
    "clf_U2R.fit(X_U2R, Y_U2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selected features\n",
    "clf_rfeDoS=DecisionTreeClassifier(random_state=0)\n",
    "clf_rfeProbe=DecisionTreeClassifier(random_state=0)\n",
    "clf_rfeR2L=DecisionTreeClassifier(random_state=0)\n",
    "clf_rfeU2R=DecisionTreeClassifier(random_state=0)\n",
    "clf_rfeDoS.fit(X_rfeDoS, Y_DoS)\n",
    "clf_rfeProbe.fit(X_rfeProbe, Y_Probe)\n",
    "clf_rfeR2L.fit(X_rfeR2L, Y_R2L)\n",
    "clf_rfeU2R.fit(X_rfeU2R, Y_U2R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Prediction & Evaluation (validation):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all Features for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices\n",
    "## DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier we trained to the test data (which it has never seen before)\n",
    "clf_DoS.predict(X_DoS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the predicted probabilities of the first 10 observations\n",
    "clf_DoS.predict_proba(X_DoS_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9499</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2830</td>\n",
       "      <td>4630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     1\n",
       "Actual attacks               \n",
       "0                  9499   212\n",
       "1                  2830  4630"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_DoS_pred=clf_DoS.predict(X_DoS_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2337</td>\n",
       "      <td>7374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212</td>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     2\n",
       "Actual attacks               \n",
       "0                  2337  7374\n",
       "2                   212  2209"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Probe_pred=clf_Probe.predict(X_Probe_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9707</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2573</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0    3\n",
       "Actual attacks              \n",
       "0                  9707    4\n",
       "3                  2573  312"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_R2L_pred=clf_R2L.predict(X_R2L_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9703</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0  4\n",
       "Actual attacks            \n",
       "0                  9703  8\n",
       "4                    60  7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_U2R_pred=clf_U2R.predict(X_U2R_test)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation: Accuracy, Precision, Recall, F-measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99639 (+/- 0.00341)\n",
      "Precision: 0.99505 (+/- 0.00477)\n",
      "Recall: 0.99665 (+/- 0.00483)\n",
      "F-measure: 0.99585 (+/- 0.00392)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "accuracy = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='precision')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='recall')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='f1')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99571 (+/- 0.00328)\n",
      "Precision: 0.99392 (+/- 0.00684)\n",
      "Recall: 0.99267 (+/- 0.00405)\n",
      "F-measure: 0.99329 (+/- 0.00512)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97920 (+/- 0.01053)\n",
      "Precision: 0.97151 (+/- 0.01736)\n",
      "Recall: 0.96958 (+/- 0.01379)\n",
      "F-measure: 0.97051 (+/- 0.01478)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99652 (+/- 0.00228)\n",
      "Precision: 0.86295 (+/- 0.08961)\n",
      "Recall: 0.90958 (+/- 0.09211)\n",
      "F-measure: 0.88210 (+/- 0.06559)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFECV for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv_DoS = RFECV(estimator=clf_DoS, step=1, cv=10, scoring='accuracy')\n",
    "rfecv_DoS.fit(X_DoS_test, Y_DoS_test)\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.title('RFECV DoS')\n",
    "plt.plot(range(1, len(rfecv_DoS.grid_scores_) + 1), rfecv_DoS.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfecv_Probe = RFECV(estimator=clf_Probe, step=1, cv=10, scoring='accuracy')\n",
    "rfecv_Probe.fit(X_Probe_test, Y_Probe_test)\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.title('RFECV Probe')\n",
    "plt.plot(range(1, len(rfecv_Probe.grid_scores_) + 1), rfecv_Probe.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfecv_R2L = RFECV(estimator=clf_R2L, step=1, cv=10, scoring='accuracy')\n",
    "rfecv_R2L.fit(X_R2L_test, Y_R2L_test)\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.title('RFECV R2L')\n",
    "plt.plot(range(1, len(rfecv_R2L.grid_scores_) + 1), rfecv_R2L.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfecv_U2R = RFECV(estimator=clf_U2R, step=1, cv=10, scoring='accuracy')\n",
    "rfecv_U2R.fit(X_U2R_test, Y_U2R_test)\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.title('RFECV U2R')\n",
    "plt.plot(range(1, len(rfecv_U2R.grid_scores_) + 1), rfecv_U2R.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 13 Features for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices\n",
    "## DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9778, 13)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce test dataset to 13 features, use only features described in rfecolname_DoS etc.\n",
    "X_DoS_test2=X_DoS_test[:,rfecolindex_DoS]\n",
    "X_Probe_test2=X_Probe_test[:,rfecolindex_Probe]\n",
    "X_R2L_test2=X_R2L_test[:,rfecolindex_R2L]\n",
    "X_U2R_test2=X_U2R_test[:,rfecolindex_U2R]\n",
    "X_U2R_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9602</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2625</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     1\n",
       "Actual attacks               \n",
       "0                  9602   109\n",
       "1                  2625  4835"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_DoS_pred2=clf_rfeDoS.predict(X_DoS_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8709</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     2\n",
       "Actual attacks               \n",
       "0                  8709  1002\n",
       "2                   944  1477"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Probe_pred2=clf_rfeProbe.predict(X_Probe_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9649</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2560</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0    3\n",
       "Actual attacks              \n",
       "0                  9649   62\n",
       "3                  2560  325"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_R2L_pred2=clf_rfeR2L.predict(X_R2L_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9706</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0   4\n",
       "Actual attacks             \n",
       "0                  9706   5\n",
       "4                    52  15"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_U2R_pred2=clf_rfeU2R.predict(X_U2R_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation: Accuracy, Precision, Recall, F-measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99738 (+/- 0.00267)\n",
      "Precision: 0.99692 (+/- 0.00492)\n",
      "Recall: 0.99705 (+/- 0.00356)\n",
      "F-measure: 0.99698 (+/- 0.00307)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='precision')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='recall')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='f1')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99085 (+/- 0.00559)\n",
      "Precision: 0.98674 (+/- 0.01179)\n",
      "Recall: 0.98467 (+/- 0.01026)\n",
      "F-measure: 0.98566 (+/- 0.00871)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97459 (+/- 0.00910)\n",
      "Precision: 0.96689 (+/- 0.01311)\n",
      "Recall: 0.96086 (+/- 0.01571)\n",
      "F-measure: 0.96379 (+/- 0.01305)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99652 (+/- 0.00278)\n",
      "Precision: 0.87538 (+/- 0.15433)\n",
      "Recall: 0.89540 (+/- 0.14777)\n",
      "F-measure: 0.87731 (+/- 0.09647)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "precision = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "recall = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "f = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified CV => Stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99738 (+/- 0.00267)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99085 (+/- 0.00559)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97459 (+/- 0.00910)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99652 (+/- 0.00278)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV 2, 5, 10, 30, 50 fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99662 (+/- 0.00116)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=2, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99709 (+/- 0.00064)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99738 (+/- 0.00267)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99726 (+/- 0.00430)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=30, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99703 (+/- 0.00622)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=50, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99060 (+/- 0.00165)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=2, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99093 (+/- 0.00233)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99085 (+/- 0.00559)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99118 (+/- 0.00742)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=30, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99085 (+/- 0.01122)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=50, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97118 (+/- 0.00143)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=2, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97388 (+/- 0.00624)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97459 (+/- 0.00910)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97467 (+/- 0.01644)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=30, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97523 (+/- 0.01795)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=50, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99519 (+/- 0.00184)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=2, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99714 (+/- 0.00153)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99652 (+/- 0.00278)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99693 (+/- 0.00571)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=30, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99662 (+/- 0.00755)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=50, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Passo 1: preparando os dados</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newdf.drop('label',1)\n",
    "Y_train = to_categorical(newdf.label, num_classes=5)\n",
    "# test set\n",
    "X_test = newdf_test.drop('label',1)\n",
    "Y_test = to_categorical(newdf_test.label, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames2=list(X_train)\n",
    "colNames_test2=list(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerAll = Normalizer().fit(X_train)\n",
    "X_train = scalerAll.transform(X_train)\n",
    "X_test = scalerAll.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 122)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Construindo a CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo o \"optimizer\" e o objetivo, compilando a CNN\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.2713 - accuracy: 0.9127 - val_loss: 1.4546 - val_accuracy: 0.6980\n",
      "Epoch 2/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.1578 - accuracy: 0.9490 - val_loss: 1.7419 - val_accuracy: 0.7166\n",
      "Epoch 3/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.1215 - accuracy: 0.9612 - val_loss: 1.8539 - val_accuracy: 0.7289\n",
      "Epoch 4/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.1037 - accuracy: 0.9676 - val_loss: 1.9915 - val_accuracy: 0.7429\n",
      "Epoch 5/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0907 - accuracy: 0.9721 - val_loss: 2.1054 - val_accuracy: 0.7222\n",
      "Epoch 6/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0812 - accuracy: 0.9749 - val_loss: 2.2632 - val_accuracy: 0.7284\n",
      "Epoch 7/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0754 - accuracy: 0.9768 - val_loss: 2.1649 - val_accuracy: 0.7355\n",
      "Epoch 8/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0700 - accuracy: 0.9791 - val_loss: 2.6817 - val_accuracy: 0.7224\n",
      "Epoch 9/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0671 - accuracy: 0.9798 - val_loss: 2.4013 - val_accuracy: 0.7425\n",
      "Epoch 10/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0642 - accuracy: 0.9808 - val_loss: 2.0209 - val_accuracy: 0.7427\n",
      "Epoch 11/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0620 - accuracy: 0.9817 - val_loss: 2.6257 - val_accuracy: 0.7361\n",
      "Epoch 12/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0579 - accuracy: 0.9833 - val_loss: 2.3682 - val_accuracy: 0.7461\n",
      "Epoch 13/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0569 - accuracy: 0.9830 - val_loss: 2.5562 - val_accuracy: 0.7423\n",
      "Epoch 14/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0546 - accuracy: 0.9839 - val_loss: 2.6662 - val_accuracy: 0.7372\n",
      "Epoch 15/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0540 - accuracy: 0.9846 - val_loss: 2.5464 - val_accuracy: 0.7421\n",
      "Epoch 16/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0511 - accuracy: 0.9852 - val_loss: 3.0152 - val_accuracy: 0.7390\n",
      "Epoch 17/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 2.8938 - val_accuracy: 0.7448\n",
      "Epoch 18/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0499 - accuracy: 0.9855 - val_loss: 2.8010 - val_accuracy: 0.7379\n",
      "Epoch 19/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0480 - accuracy: 0.9857 - val_loss: 2.9803 - val_accuracy: 0.7422\n",
      "Epoch 20/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 2.9399 - val_accuracy: 0.7454\n",
      "Epoch 21/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0442 - accuracy: 0.9868 - val_loss: 2.8852 - val_accuracy: 0.7480\n",
      "Epoch 22/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0436 - accuracy: 0.9873 - val_loss: 2.9535 - val_accuracy: 0.7461\n",
      "Epoch 23/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 3.1072 - val_accuracy: 0.7454\n",
      "Epoch 24/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 3.2853 - val_accuracy: 0.7414\n",
      "Epoch 25/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0406 - accuracy: 0.9876 - val_loss: 2.8752 - val_accuracy: 0.7502\n",
      "Epoch 26/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0382 - accuracy: 0.9883 - val_loss: 3.0418 - val_accuracy: 0.7449\n",
      "Epoch 27/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 3.3406 - val_accuracy: 0.7452\n",
      "Epoch 28/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 3.1924 - val_accuracy: 0.7452\n",
      "Epoch 29/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 3.4014 - val_accuracy: 0.7476\n",
      "Epoch 30/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0349 - accuracy: 0.9896 - val_loss: 3.0426 - val_accuracy: 0.7567\n",
      "Epoch 31/1000\n",
      "1969/1969 [==============================] - 23s 11ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 3.1136 - val_accuracy: 0.7535\n",
      "Epoch 32/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 3.1357 - val_accuracy: 0.7463\n",
      "Epoch 33/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 3.3503 - val_accuracy: 0.7427\n",
      "Epoch 34/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0329 - accuracy: 0.9901 - val_loss: 3.1598 - val_accuracy: 0.7463\n",
      "Epoch 35/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 3.3958 - val_accuracy: 0.7508\n",
      "Epoch 36/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 3.6897 - val_accuracy: 0.7465\n",
      "Epoch 37/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 3.2714 - val_accuracy: 0.7578\n",
      "Epoch 38/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 3.3412 - val_accuracy: 0.7499\n",
      "Epoch 39/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 3.6255 - val_accuracy: 0.7514\n",
      "Epoch 40/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 3.7210 - val_accuracy: 0.7393\n",
      "Epoch 41/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 3.3350 - val_accuracy: 0.7453\n",
      "Epoch 42/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 3.7379 - val_accuracy: 0.7568\n",
      "Epoch 43/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 3.7803 - val_accuracy: 0.7538\n",
      "Epoch 44/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 3.7138 - val_accuracy: 0.7460\n",
      "Epoch 45/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 3.7189 - val_accuracy: 0.7529\n",
      "Epoch 46/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 3.9619 - val_accuracy: 0.7475\n",
      "Epoch 47/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 3.9757 - val_accuracy: 0.7549\n",
      "Epoch 48/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 3.3629 - val_accuracy: 0.7587\n",
      "Epoch 49/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 3.5537 - val_accuracy: 0.7593\n",
      "Epoch 50/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 3.9765 - val_accuracy: 0.7485\n",
      "Epoch 51/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 3.8064 - val_accuracy: 0.7537\n",
      "Epoch 52/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 3.9595 - val_accuracy: 0.7655\n",
      "Epoch 53/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 4.4362 - val_accuracy: 0.7515\n",
      "Epoch 54/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 4.0316 - val_accuracy: 0.7669\n",
      "Epoch 55/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 3.9664 - val_accuracy: 0.7630\n",
      "Epoch 56/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 3.6470 - val_accuracy: 0.7518\n",
      "Epoch 57/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 3.9597 - val_accuracy: 0.7502\n",
      "Epoch 58/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 4.1577 - val_accuracy: 0.7566\n",
      "Epoch 59/1000\n",
      "1969/1969 [==============================] - 24s 12ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 3.9009 - val_accuracy: 0.7510\n",
      "Epoch 60/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 4.1160 - val_accuracy: 0.7490\n",
      "Epoch 61/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 3.6170 - val_accuracy: 0.7621\n",
      "Epoch 62/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 4.0262 - val_accuracy: 0.7473\n",
      "Epoch 63/1000\n",
      "1969/1969 [==============================] - 23s 12ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 4.0926 - val_accuracy: 0.7538\n",
      "Epoch 64/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 3.9466 - val_accuracy: 0.7491\n",
      "Epoch 65/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 4.0421 - val_accuracy: 0.7430\n",
      "Epoch 66/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 4.3468 - val_accuracy: 0.7603\n",
      "Epoch 67/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 4.4709 - val_accuracy: 0.7524\n",
      "Epoch 68/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 4.3810 - val_accuracy: 0.7560\n",
      "Epoch 69/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 4.2384 - val_accuracy: 0.7569\n",
      "Epoch 70/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 4.3882 - val_accuracy: 0.7560\n",
      "Epoch 71/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 4.1969 - val_accuracy: 0.7593\n",
      "Epoch 72/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 4.8176 - val_accuracy: 0.7555\n",
      "Epoch 73/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 4.9846 - val_accuracy: 0.7563\n",
      "Epoch 74/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 4.6000 - val_accuracy: 0.7724\n",
      "Epoch 75/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 4.4134 - val_accuracy: 0.7607\n",
      "Epoch 76/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 5.1280 - val_accuracy: 0.7443\n",
      "Epoch 77/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 4.5980 - val_accuracy: 0.7569\n",
      "Epoch 78/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 5.1149 - val_accuracy: 0.7525\n",
      "Epoch 79/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 4.2439 - val_accuracy: 0.7618\n",
      "Epoch 80/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 4.5162 - val_accuracy: 0.7563\n",
      "Epoch 81/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 4.5438 - val_accuracy: 0.7574\n",
      "Epoch 82/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 4.8015 - val_accuracy: 0.7508\n",
      "Epoch 83/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 4.3867 - val_accuracy: 0.7531\n",
      "Epoch 84/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 4.7885 - val_accuracy: 0.7630\n",
      "Epoch 85/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 5.1150 - val_accuracy: 0.7618\n",
      "Epoch 86/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 4.5168 - val_accuracy: 0.7598\n",
      "Epoch 87/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 4.8103 - val_accuracy: 0.7582\n",
      "Epoch 88/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 5.0992 - val_accuracy: 0.7672\n",
      "Epoch 89/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 4.7590 - val_accuracy: 0.7610\n",
      "Epoch 90/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 4.8743 - val_accuracy: 0.7646\n",
      "Epoch 91/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 5.6384 - val_accuracy: 0.7514\n",
      "Epoch 92/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 5.1601 - val_accuracy: 0.7623\n",
      "Epoch 93/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 4.8291 - val_accuracy: 0.7596\n",
      "Epoch 94/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 5.3758 - val_accuracy: 0.7571\n",
      "Epoch 95/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 4.9700 - val_accuracy: 0.7584\n",
      "Epoch 96/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 5.5924 - val_accuracy: 0.7483\n",
      "Epoch 97/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 5.0120 - val_accuracy: 0.7721\n",
      "Epoch 98/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 5.5811 - val_accuracy: 0.7516\n",
      "Epoch 99/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 4.9838 - val_accuracy: 0.7654\n",
      "Epoch 100/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 5.2747 - val_accuracy: 0.7733\n",
      "Epoch 101/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 5.3804 - val_accuracy: 0.7565\n",
      "Epoch 102/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 4.7487 - val_accuracy: 0.7583\n",
      "Epoch 103/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 5.7939 - val_accuracy: 0.7612\n",
      "Epoch 104/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 5.2597 - val_accuracy: 0.7642\n",
      "Epoch 105/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 5.1767 - val_accuracy: 0.7597\n",
      "Epoch 106/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 4.8860 - val_accuracy: 0.7534\n",
      "Epoch 107/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 5.8373 - val_accuracy: 0.7616\n",
      "Epoch 108/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 5.6496 - val_accuracy: 0.7668\n",
      "Epoch 109/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 5.5106 - val_accuracy: 0.7587\n",
      "Epoch 110/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 5.3433 - val_accuracy: 0.7562\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 5.4756 - val_accuracy: 0.7623\n",
      "Epoch 112/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 5.5745 - val_accuracy: 0.7645\n",
      "Epoch 113/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 5.6420 - val_accuracy: 0.7620\n",
      "Epoch 114/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 5.2130 - val_accuracy: 0.7762\n",
      "Epoch 115/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 5.3589 - val_accuracy: 0.7632\n",
      "Epoch 116/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 5.8884 - val_accuracy: 0.7432\n",
      "Epoch 117/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 5.7391 - val_accuracy: 0.7548\n",
      "Epoch 118/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 5.5433 - val_accuracy: 0.7637\n",
      "Epoch 119/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 6.2899 - val_accuracy: 0.7594\n",
      "Epoch 120/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 5.9024 - val_accuracy: 0.7618\n",
      "Epoch 121/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 5.1069 - val_accuracy: 0.7736\n",
      "Epoch 122/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 5.7431 - val_accuracy: 0.7550\n",
      "Epoch 123/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 5.1503 - val_accuracy: 0.7580\n",
      "Epoch 124/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 6.0840 - val_accuracy: 0.7536\n",
      "Epoch 125/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 6.0214 - val_accuracy: 0.7520\n",
      "Epoch 126/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 6.2427 - val_accuracy: 0.7490\n",
      "Epoch 127/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 6.0007 - val_accuracy: 0.7579\n",
      "Epoch 128/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 5.5357 - val_accuracy: 0.7543\n",
      "Epoch 129/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 6.1247 - val_accuracy: 0.7551\n",
      "Epoch 130/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 6.5968 - val_accuracy: 0.7577\n",
      "Epoch 131/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 6.4264 - val_accuracy: 0.7550\n",
      "Epoch 132/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 5.7082 - val_accuracy: 0.7602\n",
      "Epoch 133/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 6.0980 - val_accuracy: 0.7530\n",
      "Epoch 134/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 5.8860 - val_accuracy: 0.7560\n",
      "Epoch 135/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 6.7066 - val_accuracy: 0.7563\n",
      "Epoch 136/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 5.9341 - val_accuracy: 0.7673\n",
      "Epoch 137/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 5.8849 - val_accuracy: 0.7636\n",
      "Epoch 138/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 5.8608 - val_accuracy: 0.7622\n",
      "Epoch 139/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 6.2167 - val_accuracy: 0.7508\n",
      "Epoch 140/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 5.8339 - val_accuracy: 0.7686\n",
      "Epoch 141/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 6.2888 - val_accuracy: 0.7596\n",
      "Epoch 142/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 5.9361 - val_accuracy: 0.7636\n",
      "Epoch 143/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 6.1386 - val_accuracy: 0.7631\n",
      "Epoch 144/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 6.6278 - val_accuracy: 0.7532\n",
      "Epoch 145/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 6.2850 - val_accuracy: 0.7466\n",
      "Epoch 146/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 6.3582 - val_accuracy: 0.7477\n",
      "Epoch 147/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 6.4618 - val_accuracy: 0.7610\n",
      "Epoch 148/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 6.1899 - val_accuracy: 0.7629\n",
      "Epoch 149/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 5.6489 - val_accuracy: 0.7548\n",
      "Epoch 150/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 7.1141 - val_accuracy: 0.7464\n",
      "Epoch 151/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 5.8234 - val_accuracy: 0.7583\n",
      "Epoch 152/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 6.4598 - val_accuracy: 0.7545\n",
      "Epoch 153/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 7.1855 - val_accuracy: 0.7464\n",
      "Epoch 154/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 6.7900 - val_accuracy: 0.7610\n",
      "Epoch 155/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 6.2475 - val_accuracy: 0.7545\n",
      "Epoch 156/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 6.3192 - val_accuracy: 0.7507\n",
      "Epoch 157/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 5.5339 - val_accuracy: 0.7626\n",
      "Epoch 158/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 6.5581 - val_accuracy: 0.7693\n",
      "Epoch 159/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 6.3014 - val_accuracy: 0.7614\n",
      "Epoch 160/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 6.2249 - val_accuracy: 0.7636\n",
      "Epoch 161/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 6.3861 - val_accuracy: 0.7477\n",
      "Epoch 162/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 6.7447 - val_accuracy: 0.7677\n",
      "Epoch 163/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 6.9484 - val_accuracy: 0.7695\n",
      "Epoch 164/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 7.2485 - val_accuracy: 0.7472\n",
      "Epoch 165/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 5.8343 - val_accuracy: 0.7664\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 6.2396 - val_accuracy: 0.7610\n",
      "Epoch 167/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 6.9878 - val_accuracy: 0.7602\n",
      "Epoch 168/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 5.8599 - val_accuracy: 0.7534\n",
      "Epoch 169/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 6.5754 - val_accuracy: 0.7594\n",
      "Epoch 170/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 6.2766 - val_accuracy: 0.7610\n",
      "Epoch 171/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 6.8477 - val_accuracy: 0.7547\n",
      "Epoch 172/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 6.6205 - val_accuracy: 0.7560\n",
      "Epoch 173/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 7.0072 - val_accuracy: 0.7493\n",
      "Epoch 174/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 6.2083 - val_accuracy: 0.7614\n",
      "Epoch 175/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 6.2213 - val_accuracy: 0.7538\n",
      "Epoch 176/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 7.1203 - val_accuracy: 0.7493\n",
      "Epoch 177/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 6.8391 - val_accuracy: 0.7621\n",
      "Epoch 178/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 6.0084 - val_accuracy: 0.7661\n",
      "Epoch 179/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 6.3356 - val_accuracy: 0.7633\n",
      "Epoch 180/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 5.8998 - val_accuracy: 0.7519\n",
      "Epoch 181/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 5.9427 - val_accuracy: 0.7726\n",
      "Epoch 182/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 6.9785 - val_accuracy: 0.7569\n",
      "Epoch 183/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 6.8544 - val_accuracy: 0.7506\n",
      "Epoch 184/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 6.7151 - val_accuracy: 0.7598\n",
      "Epoch 185/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 7.0873 - val_accuracy: 0.7592\n",
      "Epoch 186/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 6.5976 - val_accuracy: 0.7656\n",
      "Epoch 187/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 8.0092 - val_accuracy: 0.7469\n",
      "Epoch 188/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 6.7148 - val_accuracy: 0.7681\n",
      "Epoch 189/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 6.7147 - val_accuracy: 0.7530\n",
      "Epoch 190/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 6.8704 - val_accuracy: 0.7459\n",
      "Epoch 191/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 7.4469 - val_accuracy: 0.7505\n",
      "Epoch 192/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 6.5699 - val_accuracy: 0.7609\n",
      "Epoch 193/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 7.0115 - val_accuracy: 0.7476\n",
      "Epoch 194/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 5.3834 - val_accuracy: 0.7479\n",
      "Epoch 195/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 6.7284 - val_accuracy: 0.7689\n",
      "Epoch 196/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 6.7937 - val_accuracy: 0.7516\n",
      "Epoch 197/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 5.4654 - val_accuracy: 0.7560\n",
      "Epoch 198/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 6.8301 - val_accuracy: 0.7492\n",
      "Epoch 199/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 7.1224 - val_accuracy: 0.7519\n",
      "Epoch 200/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 5.9793 - val_accuracy: 0.7586\n",
      "Epoch 201/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 6.6190 - val_accuracy: 0.7537\n",
      "Epoch 202/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 7.7793 - val_accuracy: 0.7505\n",
      "Epoch 203/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 6.9865 - val_accuracy: 0.7555\n",
      "Epoch 204/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 6.7243 - val_accuracy: 0.7610\n",
      "Epoch 205/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 8.0052 - val_accuracy: 0.7520\n",
      "Epoch 206/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 7.3655 - val_accuracy: 0.7424\n",
      "Epoch 207/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 7.4157 - val_accuracy: 0.7493\n",
      "Epoch 208/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 7.3814 - val_accuracy: 0.7506\n",
      "Epoch 209/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 6.8663 - val_accuracy: 0.7599\n",
      "Epoch 210/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 7.0645 - val_accuracy: 0.7525\n",
      "Epoch 211/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 6.7336 - val_accuracy: 0.7492\n",
      "Epoch 212/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 7.3977 - val_accuracy: 0.7437\n",
      "Epoch 213/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 6.7415 - val_accuracy: 0.7661\n",
      "Epoch 214/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 7.1617 - val_accuracy: 0.7653\n",
      "Epoch 215/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 6.2402 - val_accuracy: 0.7627\n",
      "Epoch 216/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 6.9859 - val_accuracy: 0.7599\n",
      "Epoch 217/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 7.1893 - val_accuracy: 0.7504\n",
      "Epoch 218/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 6.9989 - val_accuracy: 0.7476\n",
      "Epoch 219/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 7.3780 - val_accuracy: 0.7551\n",
      "Epoch 220/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 7.2016 - val_accuracy: 0.7594\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 6.3882 - val_accuracy: 0.7645\n",
      "Epoch 222/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 7.2369 - val_accuracy: 0.7587\n",
      "Epoch 223/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 6.7855 - val_accuracy: 0.7597\n",
      "Epoch 224/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 5.7296 - val_accuracy: 0.7600\n",
      "Epoch 225/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 8.6112 - val_accuracy: 0.7452\n",
      "Epoch 226/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 6.2138 - val_accuracy: 0.7608\n",
      "Epoch 227/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 7.1768 - val_accuracy: 0.7641\n",
      "Epoch 228/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 7.3682 - val_accuracy: 0.7520\n",
      "Epoch 229/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 6.8023 - val_accuracy: 0.7484\n",
      "Epoch 230/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 7.7638 - val_accuracy: 0.7486\n",
      "Epoch 231/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 7.1289 - val_accuracy: 0.7519\n",
      "Epoch 232/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 7.2337 - val_accuracy: 0.7540\n",
      "Epoch 233/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 7.1467 - val_accuracy: 0.7568\n",
      "Epoch 234/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 8.0735 - val_accuracy: 0.7553\n",
      "Epoch 235/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 7.1658 - val_accuracy: 0.7621\n",
      "Epoch 236/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 7.3788 - val_accuracy: 0.7545\n",
      "Epoch 237/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 7.4481 - val_accuracy: 0.7595\n",
      "Epoch 238/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 7.1202 - val_accuracy: 0.7630\n",
      "Epoch 239/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 7.1569 - val_accuracy: 0.7539\n",
      "Epoch 240/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 6.9841 - val_accuracy: 0.7608\n",
      "Epoch 241/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 8.1440 - val_accuracy: 0.7512\n",
      "Epoch 242/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 7.0575 - val_accuracy: 0.7546\n",
      "Epoch 243/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 8.5030 - val_accuracy: 0.7524\n",
      "Epoch 244/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 7.8456 - val_accuracy: 0.7478\n",
      "Epoch 245/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 7.7852 - val_accuracy: 0.7488\n",
      "Epoch 246/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 8.2548 - val_accuracy: 0.7568\n",
      "Epoch 247/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 7.5047 - val_accuracy: 0.7547\n",
      "Epoch 248/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 7.1213 - val_accuracy: 0.7624\n",
      "Epoch 249/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 8.3200 - val_accuracy: 0.7609\n",
      "Epoch 250/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 8.2978 - val_accuracy: 0.7528\n",
      "Epoch 251/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 7.0749 - val_accuracy: 0.7534\n",
      "Epoch 252/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 7.4620 - val_accuracy: 0.7496\n",
      "Epoch 253/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 7.0748 - val_accuracy: 0.7590\n",
      "Epoch 254/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 8.2801 - val_accuracy: 0.7542\n",
      "Epoch 255/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 7.5151 - val_accuracy: 0.7598\n",
      "Epoch 256/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 7.2698 - val_accuracy: 0.7472\n",
      "Epoch 257/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 6.9653 - val_accuracy: 0.7554\n",
      "Epoch 258/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 7.4705 - val_accuracy: 0.7598\n",
      "Epoch 259/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 7.1831 - val_accuracy: 0.7511\n",
      "Epoch 260/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 7.3346 - val_accuracy: 0.7518\n",
      "Epoch 261/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 9.0331 - val_accuracy: 0.7612\n",
      "Epoch 262/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 7.4189 - val_accuracy: 0.7610\n",
      "Epoch 263/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 7.9575 - val_accuracy: 0.7673\n",
      "Epoch 264/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 8.3172 - val_accuracy: 0.7536\n",
      "Epoch 265/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 8.1611 - val_accuracy: 0.7580\n",
      "Epoch 266/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 8.4835 - val_accuracy: 0.7551\n",
      "Epoch 267/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 8.1272 - val_accuracy: 0.7499\n",
      "Epoch 268/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 7.2028 - val_accuracy: 0.7597\n",
      "Epoch 269/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 6.8998 - val_accuracy: 0.7564\n",
      "Epoch 270/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 7.9651 - val_accuracy: 0.7549\n",
      "Epoch 271/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 7.6846 - val_accuracy: 0.7568\n",
      "Epoch 272/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 8.0568 - val_accuracy: 0.7559\n",
      "Epoch 273/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 7.7905 - val_accuracy: 0.7494\n",
      "Epoch 274/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 7.4756 - val_accuracy: 0.7587\n",
      "Epoch 275/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 7.6843 - val_accuracy: 0.7627\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 8.5032 - val_accuracy: 0.7573\n",
      "Epoch 277/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 6.9161 - val_accuracy: 0.7592\n",
      "Epoch 278/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 7.7801 - val_accuracy: 0.7558\n",
      "Epoch 279/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 7.1866 - val_accuracy: 0.7601\n",
      "Epoch 280/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 8.4243 - val_accuracy: 0.7523\n",
      "Epoch 281/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 7.9306 - val_accuracy: 0.7475\n",
      "Epoch 282/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 8.2423 - val_accuracy: 0.7583\n",
      "Epoch 283/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 8.2600 - val_accuracy: 0.7561\n",
      "Epoch 284/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 8.2943 - val_accuracy: 0.7611\n",
      "Epoch 285/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 7.3913 - val_accuracy: 0.7519\n",
      "Epoch 286/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 7.0789 - val_accuracy: 0.7674\n",
      "Epoch 287/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 7.0675 - val_accuracy: 0.7686\n",
      "Epoch 288/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 8.6184 - val_accuracy: 0.7549\n",
      "Epoch 289/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 7.5707 - val_accuracy: 0.7666\n",
      "Epoch 290/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 7.4791 - val_accuracy: 0.7609\n",
      "Epoch 291/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 7.1349 - val_accuracy: 0.7665\n",
      "Epoch 292/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 7.9052 - val_accuracy: 0.7619\n",
      "Epoch 293/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 7.8277 - val_accuracy: 0.7528\n",
      "Epoch 294/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 8.6454 - val_accuracy: 0.7596\n",
      "Epoch 295/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 7.9988 - val_accuracy: 0.7601\n",
      "Epoch 296/1000\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 6.6395 - val_accuracy: 0.7523\n",
      "Epoch 297/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 7.9684 - val_accuracy: 0.7534\n",
      "Epoch 298/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 7.1491 - val_accuracy: 0.7535\n",
      "Epoch 299/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 7.5875 - val_accuracy: 0.7453\n",
      "Epoch 300/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 8.1303 - val_accuracy: 0.7465\n",
      "Epoch 301/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 7.2187 - val_accuracy: 0.7513\n",
      "Epoch 302/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 7.3304 - val_accuracy: 0.7616\n",
      "Epoch 303/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 7.6612 - val_accuracy: 0.7652\n",
      "Epoch 304/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 7.7026 - val_accuracy: 0.7579\n",
      "Epoch 305/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 8.0009 - val_accuracy: 0.7480\n",
      "Epoch 306/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 7.4025 - val_accuracy: 0.7531\n",
      "Epoch 307/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 8.3966 - val_accuracy: 0.7545\n",
      "Epoch 308/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 7.0361 - val_accuracy: 0.7631\n",
      "Epoch 309/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 7.9876 - val_accuracy: 0.7540\n",
      "Epoch 310/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 8.7057 - val_accuracy: 0.7560\n",
      "Epoch 311/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 7.7672 - val_accuracy: 0.7688\n",
      "Epoch 312/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 7.3510 - val_accuracy: 0.7593\n",
      "Epoch 313/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 7.5623 - val_accuracy: 0.7560\n",
      "Epoch 314/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 8.0895 - val_accuracy: 0.7598\n",
      "Epoch 315/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 7.8199 - val_accuracy: 0.7467\n",
      "Epoch 316/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 7.9405 - val_accuracy: 0.7580\n",
      "Epoch 317/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 7.7604 - val_accuracy: 0.7620\n",
      "Epoch 318/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 7.8332 - val_accuracy: 0.7584\n",
      "Epoch 319/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 7.7170 - val_accuracy: 0.7606\n",
      "Epoch 320/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 8.3285 - val_accuracy: 0.7581\n",
      "Epoch 321/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 6.9437 - val_accuracy: 0.7475\n",
      "Epoch 322/1000\n",
      "1969/1969 [==============================] - 22s 11ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 7.8454 - val_accuracy: 0.7565\n",
      "Epoch 323/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 7.0560 - val_accuracy: 0.7498\n",
      "Epoch 324/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 8.8093 - val_accuracy: 0.7557\n",
      "Epoch 325/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 8.3383 - val_accuracy: 0.7421\n",
      "Epoch 326/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 7.7519 - val_accuracy: 0.7547\n",
      "Epoch 327/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 8.6576 - val_accuracy: 0.7492\n",
      "Epoch 328/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 8.9625 - val_accuracy: 0.7494\n",
      "Epoch 329/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 8.7908 - val_accuracy: 0.7517\n",
      "Epoch 330/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 7.6164 - val_accuracy: 0.7617\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 7.7127 - val_accuracy: 0.7613\n",
      "Epoch 332/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 7.0970 - val_accuracy: 0.7579\n",
      "Epoch 333/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 7.9191 - val_accuracy: 0.7466\n",
      "Epoch 334/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 7.9078 - val_accuracy: 0.7621\n",
      "Epoch 335/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 8.7436 - val_accuracy: 0.7597\n",
      "Epoch 336/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 8.1440 - val_accuracy: 0.7642\n",
      "Epoch 337/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 6.5049 - val_accuracy: 0.7520\n",
      "Epoch 338/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 8.3259 - val_accuracy: 0.7571\n",
      "Epoch 339/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 8.7058 - val_accuracy: 0.7513\n",
      "Epoch 340/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 8.1504 - val_accuracy: 0.7535\n",
      "Epoch 341/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 8.9124 - val_accuracy: 0.7595\n",
      "Epoch 342/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 7.7739 - val_accuracy: 0.7529\n",
      "Epoch 343/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 9.0367 - val_accuracy: 0.7549\n",
      "Epoch 344/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 7.1086 - val_accuracy: 0.7689\n",
      "Epoch 345/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 7.4048 - val_accuracy: 0.7633\n",
      "Epoch 346/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 9.1419 - val_accuracy: 0.7524\n",
      "Epoch 347/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 8.0192 - val_accuracy: 0.7539\n",
      "Epoch 348/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 7.6071 - val_accuracy: 0.7693\n",
      "Epoch 349/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 8.5349 - val_accuracy: 0.7514\n",
      "Epoch 350/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 7.9462 - val_accuracy: 0.7617\n",
      "Epoch 351/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 8.9782 - val_accuracy: 0.7587\n",
      "Epoch 352/1000\n",
      "1969/1969 [==============================] - 21s 10ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 8.9240 - val_accuracy: 0.7642\n",
      "Epoch 353/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 8.5984 - val_accuracy: 0.7565\n",
      "Epoch 354/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 6.8971 - val_accuracy: 0.7575\n",
      "Epoch 355/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 8.0456 - val_accuracy: 0.7520\n",
      "Epoch 356/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 8.2436 - val_accuracy: 0.7535\n",
      "Epoch 357/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 7.8556 - val_accuracy: 0.7554\n",
      "Epoch 358/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 7.3244 - val_accuracy: 0.7531\n",
      "Epoch 359/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 9.9306 - val_accuracy: 0.7429\n",
      "Epoch 360/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 7.6360 - val_accuracy: 0.7629\n",
      "Epoch 361/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 7.8755 - val_accuracy: 0.7475\n",
      "Epoch 362/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 8.5987 - val_accuracy: 0.7627\n",
      "Epoch 363/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 9.4333 - val_accuracy: 0.7599\n",
      "Epoch 364/1000\n",
      "1969/1969 [==============================] - 23s 12ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 9.1062 - val_accuracy: 0.7540\n",
      "Epoch 365/1000\n",
      "1969/1969 [==============================] - 28s 14ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 8.9606 - val_accuracy: 0.7466\n",
      "Epoch 366/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 8.2005 - val_accuracy: 0.7447\n",
      "Epoch 367/1000\n",
      "1969/1969 [==============================] - 27s 14ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 9.3478 - val_accuracy: 0.7511\n",
      "Epoch 368/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 7.4594 - val_accuracy: 0.7524\n",
      "Epoch 369/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 7.4547 - val_accuracy: 0.7546\n",
      "Epoch 370/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 7.9393 - val_accuracy: 0.7595\n",
      "Epoch 371/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 7.8257 - val_accuracy: 0.7580\n",
      "Epoch 372/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 7.7288 - val_accuracy: 0.7550\n",
      "Epoch 373/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 8.2960 - val_accuracy: 0.7601\n",
      "Epoch 374/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 8.2872 - val_accuracy: 0.7579\n",
      "Epoch 375/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 8.7987 - val_accuracy: 0.7600\n",
      "Epoch 376/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 8.5292 - val_accuracy: 0.7682\n",
      "Epoch 377/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 7.6324 - val_accuracy: 0.7695\n",
      "Epoch 378/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 9.4914 - val_accuracy: 0.7530\n",
      "Epoch 379/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 7.7286 - val_accuracy: 0.7649\n",
      "Epoch 380/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 7.8223 - val_accuracy: 0.7540\n",
      "Epoch 381/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 8.2684 - val_accuracy: 0.7642\n",
      "Epoch 382/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 7.4606 - val_accuracy: 0.7607\n",
      "Epoch 383/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 7.9485 - val_accuracy: 0.7618\n",
      "Epoch 384/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 9.1138 - val_accuracy: 0.7456\n",
      "Epoch 385/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 9.0796 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000\n",
      "1969/1969 [==============================] - 23s 11ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 7.1188 - val_accuracy: 0.7677\n",
      "Epoch 387/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 7.8344 - val_accuracy: 0.7586\n",
      "Epoch 388/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 8.0883 - val_accuracy: 0.7506\n",
      "Epoch 389/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 8.5951 - val_accuracy: 0.7627\n",
      "Epoch 390/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 9.6302 - val_accuracy: 0.7528\n",
      "Epoch 391/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 9.4308 - val_accuracy: 0.7602\n",
      "Epoch 392/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 8.3488 - val_accuracy: 0.7460\n",
      "Epoch 393/1000\n",
      "1969/1969 [==============================] - 19s 9ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 7.6373 - val_accuracy: 0.7508\n",
      "Epoch 394/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 7.5163 - val_accuracy: 0.7553\n",
      "Epoch 395/1000\n",
      "1969/1969 [==============================] - 22s 11ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 8.5862 - val_accuracy: 0.7608\n",
      "Epoch 396/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 9.2707 - val_accuracy: 0.7583\n",
      "Epoch 397/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 7.0894 - val_accuracy: 0.7558\n",
      "Epoch 398/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 7.6287 - val_accuracy: 0.7600\n",
      "Epoch 399/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 7.7804 - val_accuracy: 0.7695\n",
      "Epoch 400/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 8.6879 - val_accuracy: 0.7638\n",
      "Epoch 401/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 8.7023 - val_accuracy: 0.7453\n",
      "Epoch 402/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 6.6835 - val_accuracy: 0.7602\n",
      "Epoch 403/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 8.0281 - val_accuracy: 0.7634\n",
      "Epoch 404/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 8.8815 - val_accuracy: 0.7601\n",
      "Epoch 405/1000\n",
      "1969/1969 [==============================] - 31s 16ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 9.1181 - val_accuracy: 0.7688\n",
      "Epoch 406/1000\n",
      "1969/1969 [==============================] - 34s 17ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 9.4351 - val_accuracy: 0.7533\n",
      "Epoch 407/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 8.6071 - val_accuracy: 0.7409\n",
      "Epoch 408/1000\n",
      "1969/1969 [==============================] - 27s 14ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 8.9404 - val_accuracy: 0.7480\n",
      "Epoch 409/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 7.4330 - val_accuracy: 0.7531\n",
      "Epoch 410/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 8.7494 - val_accuracy: 0.7478\n",
      "Epoch 411/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 8.4305 - val_accuracy: 0.7551\n",
      "Epoch 412/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 7.7878 - val_accuracy: 0.7579\n",
      "Epoch 413/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 8.0781 - val_accuracy: 0.7523\n",
      "Epoch 414/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 9.2233 - val_accuracy: 0.7551\n",
      "Epoch 415/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 7.8069 - val_accuracy: 0.7652\n",
      "Epoch 416/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 9.2072 - val_accuracy: 0.7530\n",
      "Epoch 417/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 9.4548 - val_accuracy: 0.7513\n",
      "Epoch 418/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 7.9581 - val_accuracy: 0.7512\n",
      "Epoch 419/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 7.7938 - val_accuracy: 0.7469\n",
      "Epoch 420/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 8.9987 - val_accuracy: 0.7549\n",
      "Epoch 421/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 10.8798 - val_accuracy: 0.7481\n",
      "Epoch 422/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 8.3441 - val_accuracy: 0.7555\n",
      "Epoch 423/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 8.3315 - val_accuracy: 0.7547\n",
      "Epoch 424/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 9.3126 - val_accuracy: 0.7546\n",
      "Epoch 425/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 8.3367 - val_accuracy: 0.7597\n",
      "Epoch 426/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 9.4097 - val_accuracy: 0.7590\n",
      "Epoch 427/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 8.7972 - val_accuracy: 0.7632\n",
      "Epoch 428/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 8.4692 - val_accuracy: 0.7405\n",
      "Epoch 429/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 8.3503 - val_accuracy: 0.7519\n",
      "Epoch 430/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 8.5760 - val_accuracy: 0.7572\n",
      "Epoch 431/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 7.6340 - val_accuracy: 0.7597\n",
      "Epoch 432/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 9.9369 - val_accuracy: 0.7469\n",
      "Epoch 433/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 8.9937 - val_accuracy: 0.7543\n",
      "Epoch 434/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 8.6967 - val_accuracy: 0.7611\n",
      "Epoch 435/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 9.8490 - val_accuracy: 0.7544\n",
      "Epoch 436/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 8.6805 - val_accuracy: 0.7544\n",
      "Epoch 437/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 8.7679 - val_accuracy: 0.7607\n",
      "Epoch 438/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 7.2450 - val_accuracy: 0.7593\n",
      "Epoch 439/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 8.3148 - val_accuracy: 0.7609\n",
      "Epoch 440/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 9.1664 - val_accuracy: 0.7513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 8.9191 - val_accuracy: 0.7488\n",
      "Epoch 442/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 9.2290 - val_accuracy: 0.7548\n",
      "Epoch 443/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 7.6859 - val_accuracy: 0.7571\n",
      "Epoch 444/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 8.6793 - val_accuracy: 0.7593\n",
      "Epoch 445/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 8.6358 - val_accuracy: 0.7603\n",
      "Epoch 446/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 8.2261 - val_accuracy: 0.7585\n",
      "Epoch 447/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 8.1529 - val_accuracy: 0.7518\n",
      "Epoch 448/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 8.5506 - val_accuracy: 0.7608\n",
      "Epoch 449/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 8.7727 - val_accuracy: 0.7519\n",
      "Epoch 450/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 7.4991 - val_accuracy: 0.7587\n",
      "Epoch 451/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 7.7552 - val_accuracy: 0.7537\n",
      "Epoch 452/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 9.1225 - val_accuracy: 0.7514\n",
      "Epoch 453/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 7.7929 - val_accuracy: 0.7498\n",
      "Epoch 454/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 8.5847 - val_accuracy: 0.7485\n",
      "Epoch 455/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 8.2698 - val_accuracy: 0.7621\n",
      "Epoch 456/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 9.2452 - val_accuracy: 0.7602\n",
      "Epoch 457/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 8.6203 - val_accuracy: 0.7664\n",
      "Epoch 458/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 9.1619 - val_accuracy: 0.7628\n",
      "Epoch 459/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 8.5608 - val_accuracy: 0.7528\n",
      "Epoch 460/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 9.0739 - val_accuracy: 0.7536\n",
      "Epoch 461/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 8.7481 - val_accuracy: 0.7634\n",
      "Epoch 462/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 8.9410 - val_accuracy: 0.7642\n",
      "Epoch 463/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 7.9200 - val_accuracy: 0.7534\n",
      "Epoch 464/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 10.5649 - val_accuracy: 0.7482\n",
      "Epoch 465/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 7.9256 - val_accuracy: 0.7675\n",
      "Epoch 466/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 8.4073 - val_accuracy: 0.7540\n",
      "Epoch 467/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 8.9423 - val_accuracy: 0.7576\n",
      "Epoch 468/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 8.0321 - val_accuracy: 0.7596\n",
      "Epoch 469/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 7.2035 - val_accuracy: 0.7540\n",
      "Epoch 470/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 8.1260 - val_accuracy: 0.7525\n",
      "Epoch 471/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 8.2741 - val_accuracy: 0.7531\n",
      "Epoch 472/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 9.1210 - val_accuracy: 0.7520\n",
      "Epoch 473/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 9.2748 - val_accuracy: 0.7562\n",
      "Epoch 474/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 9.3548 - val_accuracy: 0.7553\n",
      "Epoch 475/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 6.1754 - val_accuracy: 0.7682\n",
      "Epoch 476/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 10.5447 - val_accuracy: 0.7621\n",
      "Epoch 477/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 7.9302 - val_accuracy: 0.7623\n",
      "Epoch 478/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 8.9077 - val_accuracy: 0.7615\n",
      "Epoch 479/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 9.8065 - val_accuracy: 0.7626\n",
      "Epoch 480/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 8.5586 - val_accuracy: 0.7621\n",
      "Epoch 481/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 8.9534 - val_accuracy: 0.7560\n",
      "Epoch 482/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 9.9730 - val_accuracy: 0.7644\n",
      "Epoch 483/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 7.8365 - val_accuracy: 0.7695\n",
      "Epoch 484/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 7.6209 - val_accuracy: 0.7608\n",
      "Epoch 485/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 10.7875 - val_accuracy: 0.7486\n",
      "Epoch 486/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 6.7539 - val_accuracy: 0.7637\n",
      "Epoch 487/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 9.0069 - val_accuracy: 0.7570\n",
      "Epoch 488/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 6.5376 - val_accuracy: 0.7686\n",
      "Epoch 489/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 7.6874 - val_accuracy: 0.7637\n",
      "Epoch 490/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 8.8928 - val_accuracy: 0.7594\n",
      "Epoch 491/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 9.7177 - val_accuracy: 0.7449\n",
      "Epoch 492/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 8.5365 - val_accuracy: 0.7643\n",
      "Epoch 493/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 9.3952 - val_accuracy: 0.7567\n",
      "Epoch 494/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 8.5304 - val_accuracy: 0.7686\n",
      "Epoch 495/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 8.5655 - val_accuracy: 0.7575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 8.7713 - val_accuracy: 0.7530\n",
      "Epoch 497/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 7.6295 - val_accuracy: 0.7526\n",
      "Epoch 498/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 8.7473 - val_accuracy: 0.7648\n",
      "Epoch 499/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 8.0405 - val_accuracy: 0.7579\n",
      "Epoch 500/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 7.8159 - val_accuracy: 0.7630\n",
      "Epoch 501/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 8.3087 - val_accuracy: 0.7496\n",
      "Epoch 502/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 7.2728 - val_accuracy: 0.7657\n",
      "Epoch 503/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 8.8109 - val_accuracy: 0.7553\n",
      "Epoch 504/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 10.3256 - val_accuracy: 0.7429\n",
      "Epoch 505/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 9.5813 - val_accuracy: 0.7582\n",
      "Epoch 506/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 8.4472 - val_accuracy: 0.7654\n",
      "Epoch 507/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 7.9088 - val_accuracy: 0.7495\n",
      "Epoch 508/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 7.3812 - val_accuracy: 0.7566\n",
      "Epoch 509/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 8.9223 - val_accuracy: 0.7578\n",
      "Epoch 510/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 8.8764 - val_accuracy: 0.7600\n",
      "Epoch 511/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 8.9348 - val_accuracy: 0.7512\n",
      "Epoch 512/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 7.4871 - val_accuracy: 0.7471\n",
      "Epoch 513/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 7.8053 - val_accuracy: 0.7587\n",
      "Epoch 514/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 9.2012 - val_accuracy: 0.7526\n",
      "Epoch 515/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 9.7363 - val_accuracy: 0.7552\n",
      "Epoch 516/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 8.0546 - val_accuracy: 0.7605\n",
      "Epoch 517/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 8.4126 - val_accuracy: 0.7498\n",
      "Epoch 518/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 9.1841 - val_accuracy: 0.7578\n",
      "Epoch 519/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 8.4167 - val_accuracy: 0.7583\n",
      "Epoch 520/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 7.9711 - val_accuracy: 0.7684\n",
      "Epoch 521/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 9.9956 - val_accuracy: 0.7458\n",
      "Epoch 522/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 8.5130 - val_accuracy: 0.7494\n",
      "Epoch 523/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 10.1193 - val_accuracy: 0.7513\n",
      "Epoch 524/1000\n",
      "1969/1969 [==============================] - 24s 12ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 8.7358 - val_accuracy: 0.7546\n",
      "Epoch 525/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 9.1334 - val_accuracy: 0.7361\n",
      "Epoch 526/1000\n",
      "1969/1969 [==============================] - 19s 9ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 8.4306 - val_accuracy: 0.7512\n",
      "Epoch 527/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 9.3794 - val_accuracy: 0.7586\n",
      "Epoch 528/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 8.1445 - val_accuracy: 0.7690\n",
      "Epoch 529/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 8.0850 - val_accuracy: 0.7570\n",
      "Epoch 530/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 9.6278 - val_accuracy: 0.7488\n",
      "Epoch 531/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 8.3965 - val_accuracy: 0.7559\n",
      "Epoch 532/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 8.9240 - val_accuracy: 0.7537\n",
      "Epoch 533/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 8.9388 - val_accuracy: 0.7533\n",
      "Epoch 534/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 9.5288 - val_accuracy: 0.7522\n",
      "Epoch 535/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 8.1514 - val_accuracy: 0.7644\n",
      "Epoch 536/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 7.9649 - val_accuracy: 0.7630\n",
      "Epoch 537/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 8.7608 - val_accuracy: 0.7482\n",
      "Epoch 538/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 9.8367 - val_accuracy: 0.7545\n",
      "Epoch 539/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 8.1833 - val_accuracy: 0.7552\n",
      "Epoch 540/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 8.7670 - val_accuracy: 0.7668\n",
      "Epoch 541/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 7.9047 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 8.1223 - val_accuracy: 0.7577\n",
      "Epoch 543/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 10.1492 - val_accuracy: 0.7536\n",
      "Epoch 544/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 8.9132 - val_accuracy: 0.7633\n",
      "Epoch 545/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 7.7338 - val_accuracy: 0.7530\n",
      "Epoch 546/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 9.5561 - val_accuracy: 0.7580\n",
      "Epoch 547/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 9.7883 - val_accuracy: 0.7494\n",
      "Epoch 548/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 9.5501 - val_accuracy: 0.7524\n",
      "Epoch 549/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 9.4003 - val_accuracy: 0.7538\n",
      "Epoch 550/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 8.3199 - val_accuracy: 0.7598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 7.8799 - val_accuracy: 0.7514\n",
      "Epoch 552/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 9.1898 - val_accuracy: 0.7497\n",
      "Epoch 553/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 8.6669 - val_accuracy: 0.7532\n",
      "Epoch 554/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 8.4271 - val_accuracy: 0.7517\n",
      "Epoch 555/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 9.0255 - val_accuracy: 0.7516\n",
      "Epoch 556/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 9.9473 - val_accuracy: 0.7624\n",
      "Epoch 557/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 9.0697 - val_accuracy: 0.7533\n",
      "Epoch 558/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 10.3107 - val_accuracy: 0.7549\n",
      "Epoch 559/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 8.2170 - val_accuracy: 0.7508\n",
      "Epoch 560/1000\n",
      "1969/1969 [==============================] - 22s 11ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 8.9438 - val_accuracy: 0.7577\n",
      "Epoch 561/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 9.1266 - val_accuracy: 0.7536\n",
      "Epoch 562/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 8.8678 - val_accuracy: 0.7601\n",
      "Epoch 563/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 8.6846 - val_accuracy: 0.7546\n",
      "Epoch 564/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 9.2345 - val_accuracy: 0.7557\n",
      "Epoch 565/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.6836 - val_accuracy: 0.7592\n",
      "Epoch 566/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 8.4766 - val_accuracy: 0.7597\n",
      "Epoch 567/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 10.3195 - val_accuracy: 0.7479\n",
      "Epoch 568/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 8.5358 - val_accuracy: 0.7671\n",
      "Epoch 569/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 10.1624 - val_accuracy: 0.7571\n",
      "Epoch 570/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 10.2034 - val_accuracy: 0.7585\n",
      "Epoch 571/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 9.0315 - val_accuracy: 0.7500\n",
      "Epoch 572/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 9.3995 - val_accuracy: 0.7561\n",
      "Epoch 573/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 9.7569 - val_accuracy: 0.7600\n",
      "Epoch 574/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 9.0520 - val_accuracy: 0.7653\n",
      "Epoch 575/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 9.5156 - val_accuracy: 0.7589\n",
      "Epoch 576/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 9.9088 - val_accuracy: 0.7620\n",
      "Epoch 577/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 9.7320 - val_accuracy: 0.7617\n",
      "Epoch 578/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 9.3890 - val_accuracy: 0.7589\n",
      "Epoch 579/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 10.5351 - val_accuracy: 0.7550\n",
      "Epoch 580/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 7.8274 - val_accuracy: 0.7593\n",
      "Epoch 581/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 8.4466 - val_accuracy: 0.7553\n",
      "Epoch 582/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 7.8320 - val_accuracy: 0.7566\n",
      "Epoch 583/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 10.6344 - val_accuracy: 0.7543\n",
      "Epoch 584/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 9.1522 - val_accuracy: 0.7532\n",
      "Epoch 585/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 8.6246 - val_accuracy: 0.7582\n",
      "Epoch 586/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 10.4064 - val_accuracy: 0.7520\n",
      "Epoch 587/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 10.2897 - val_accuracy: 0.7495\n",
      "Epoch 588/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 9.8469 - val_accuracy: 0.7614\n",
      "Epoch 589/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 9.8816 - val_accuracy: 0.7374\n",
      "Epoch 590/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.3055 - val_accuracy: 0.7547\n",
      "Epoch 591/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 8.9864 - val_accuracy: 0.7530\n",
      "Epoch 592/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 10.0980 - val_accuracy: 0.7601\n",
      "Epoch 593/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 7.9819 - val_accuracy: 0.7594\n",
      "Epoch 594/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 8.7526 - val_accuracy: 0.7546\n",
      "Epoch 595/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 10.4626 - val_accuracy: 0.7533\n",
      "Epoch 596/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 8.7130 - val_accuracy: 0.7653\n",
      "Epoch 597/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 8.2408 - val_accuracy: 0.7491\n",
      "Epoch 598/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 8.9289 - val_accuracy: 0.7554\n",
      "Epoch 599/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 9.3371 - val_accuracy: 0.7551\n",
      "Epoch 600/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 9.0408 - val_accuracy: 0.7522\n",
      "Epoch 601/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 8.6888 - val_accuracy: 0.7627\n",
      "Epoch 602/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 10.4558 - val_accuracy: 0.7556\n",
      "Epoch 603/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 8.5392 - val_accuracy: 0.7632\n",
      "Epoch 604/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 10.3052 - val_accuracy: 0.7685\n",
      "Epoch 605/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 8.7030 - val_accuracy: 0.7574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 9.3999 - val_accuracy: 0.7595\n",
      "Epoch 607/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 9.7932 - val_accuracy: 0.7531\n",
      "Epoch 608/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 8.8892 - val_accuracy: 0.7646\n",
      "Epoch 609/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 9.0733 - val_accuracy: 0.7505\n",
      "Epoch 610/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 10.5368 - val_accuracy: 0.7563\n",
      "Epoch 611/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 10.5390 - val_accuracy: 0.7584\n",
      "Epoch 612/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 10.5535 - val_accuracy: 0.7423\n",
      "Epoch 613/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 7.6712 - val_accuracy: 0.7583\n",
      "Epoch 614/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 9.0141 - val_accuracy: 0.7509\n",
      "Epoch 615/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 9.7825 - val_accuracy: 0.7575\n",
      "Epoch 616/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 9.4978 - val_accuracy: 0.7524\n",
      "Epoch 617/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 9.9718 - val_accuracy: 0.7600\n",
      "Epoch 618/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 9.1742 - val_accuracy: 0.7612\n",
      "Epoch 619/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 9.5580 - val_accuracy: 0.7562\n",
      "Epoch 620/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 10.1583 - val_accuracy: 0.7476\n",
      "Epoch 621/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 8.0815 - val_accuracy: 0.7685\n",
      "Epoch 622/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 9.0050 - val_accuracy: 0.7639\n",
      "Epoch 623/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 8.9503 - val_accuracy: 0.7456\n",
      "Epoch 624/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 10.9615 - val_accuracy: 0.7605\n",
      "Epoch 625/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 9.2029 - val_accuracy: 0.7601\n",
      "Epoch 626/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 9.8205 - val_accuracy: 0.7611\n",
      "Epoch 627/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 9.1139 - val_accuracy: 0.7550\n",
      "Epoch 628/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 8.5932 - val_accuracy: 0.7435\n",
      "Epoch 629/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 9.8202 - val_accuracy: 0.7560\n",
      "Epoch 630/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 8.0333 - val_accuracy: 0.7616\n",
      "Epoch 631/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 8.4693 - val_accuracy: 0.7524\n",
      "Epoch 632/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 8.3772 - val_accuracy: 0.7616\n",
      "Epoch 633/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 8.5936 - val_accuracy: 0.7541\n",
      "Epoch 634/1000\n",
      "1969/1969 [==============================] - 22s 11ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.0057 - val_accuracy: 0.7524\n",
      "Epoch 635/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 10.1130 - val_accuracy: 0.7520\n",
      "Epoch 636/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 9.7132 - val_accuracy: 0.7582\n",
      "Epoch 637/1000\n",
      "1969/1969 [==============================] - 23s 11ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 8.3362 - val_accuracy: 0.7564\n",
      "Epoch 638/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 10.6152 - val_accuracy: 0.7581\n",
      "Epoch 639/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 11.0872 - val_accuracy: 0.7586\n",
      "Epoch 640/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 9.8488 - val_accuracy: 0.7505\n",
      "Epoch 641/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 9.7786 - val_accuracy: 0.7534\n",
      "Epoch 642/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 11.1573 - val_accuracy: 0.7422\n",
      "Epoch 643/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 9.3644 - val_accuracy: 0.7513\n",
      "Epoch 644/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 8.9962 - val_accuracy: 0.7541\n",
      "Epoch 645/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 10.7586 - val_accuracy: 0.7496\n",
      "Epoch 646/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 8.8762 - val_accuracy: 0.7533\n",
      "Epoch 647/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 11.1529 - val_accuracy: 0.7463\n",
      "Epoch 648/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 9.3133 - val_accuracy: 0.7573\n",
      "Epoch 649/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 8.8037 - val_accuracy: 0.7541\n",
      "Epoch 650/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 9.4943 - val_accuracy: 0.7583\n",
      "Epoch 651/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 8.8279 - val_accuracy: 0.7594\n",
      "Epoch 652/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 8.6569 - val_accuracy: 0.7547\n",
      "Epoch 653/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 8.6216 - val_accuracy: 0.7472\n",
      "Epoch 654/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 9.1770 - val_accuracy: 0.7578\n",
      "Epoch 655/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 10.1180 - val_accuracy: 0.7549\n",
      "Epoch 656/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 10.8948 - val_accuracy: 0.7582\n",
      "Epoch 657/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 10.0302 - val_accuracy: 0.7479\n",
      "Epoch 658/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 10.0354 - val_accuracy: 0.7590\n",
      "Epoch 659/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 10.2120 - val_accuracy: 0.7593\n",
      "Epoch 660/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 9.7329 - val_accuracy: 0.7526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 9.2215 - val_accuracy: 0.7527\n",
      "Epoch 662/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 8.9676 - val_accuracy: 0.7624\n",
      "Epoch 663/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 10.0923 - val_accuracy: 0.7563\n",
      "Epoch 664/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 9.6973 - val_accuracy: 0.7583\n",
      "Epoch 665/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 9.9653 - val_accuracy: 0.7605\n",
      "Epoch 666/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 9.0010 - val_accuracy: 0.7513\n",
      "Epoch 667/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 8.4486 - val_accuracy: 0.7522\n",
      "Epoch 668/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 9.7048 - val_accuracy: 0.7491\n",
      "Epoch 669/1000\n",
      "1969/1969 [==============================] - 19s 9ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 9.9715 - val_accuracy: 0.7479\n",
      "Epoch 670/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 9.4981 - val_accuracy: 0.7518\n",
      "Epoch 671/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 9.2373 - val_accuracy: 0.7566\n",
      "Epoch 672/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 9.6358 - val_accuracy: 0.7497\n",
      "Epoch 673/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 8.5317 - val_accuracy: 0.7682\n",
      "Epoch 674/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 8.8252 - val_accuracy: 0.7590\n",
      "Epoch 675/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 9.4426 - val_accuracy: 0.7567\n",
      "Epoch 676/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 9.2184 - val_accuracy: 0.7520\n",
      "Epoch 677/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 10.4819 - val_accuracy: 0.7474\n",
      "Epoch 678/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 9.0907 - val_accuracy: 0.7512\n",
      "Epoch 679/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 14.9696 - val_accuracy: 0.7460\n",
      "Epoch 680/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 8.0217 - val_accuracy: 0.7472\n",
      "Epoch 681/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 10.1526 - val_accuracy: 0.7518\n",
      "Epoch 682/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 10.0334 - val_accuracy: 0.7667\n",
      "Epoch 683/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 10.2157 - val_accuracy: 0.7576\n",
      "Epoch 684/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 9.9896 - val_accuracy: 0.7622\n",
      "Epoch 685/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 10.5832 - val_accuracy: 0.7590\n",
      "Epoch 686/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 10.1008 - val_accuracy: 0.7522\n",
      "Epoch 687/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 8.5120 - val_accuracy: 0.7605\n",
      "Epoch 688/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 10.1622 - val_accuracy: 0.7534\n",
      "Epoch 689/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 10.5993 - val_accuracy: 0.7569\n",
      "Epoch 690/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 9.4242 - val_accuracy: 0.7579\n",
      "Epoch 691/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 9.9696 - val_accuracy: 0.7622\n",
      "Epoch 692/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 11.2068 - val_accuracy: 0.7484\n",
      "Epoch 693/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 9.2149 - val_accuracy: 0.7596\n",
      "Epoch 694/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 9.4159 - val_accuracy: 0.7540\n",
      "Epoch 695/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 7.8724 - val_accuracy: 0.7576\n",
      "Epoch 696/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 9.3756 - val_accuracy: 0.7527\n",
      "Epoch 697/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 9.6072 - val_accuracy: 0.7529\n",
      "Epoch 698/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 10.6602 - val_accuracy: 0.7507\n",
      "Epoch 699/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 8.4496 - val_accuracy: 0.7427\n",
      "Epoch 700/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 9.0216 - val_accuracy: 0.7622\n",
      "Epoch 701/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 9.2842 - val_accuracy: 0.7549\n",
      "Epoch 702/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 9.5212 - val_accuracy: 0.7522\n",
      "Epoch 703/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 9.6829 - val_accuracy: 0.7570\n",
      "Epoch 704/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 9.8620 - val_accuracy: 0.7577\n",
      "Epoch 705/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 9.4589 - val_accuracy: 0.7473\n",
      "Epoch 706/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 11.0340 - val_accuracy: 0.7558\n",
      "Epoch 707/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 9.0186 - val_accuracy: 0.7538\n",
      "Epoch 708/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 9.3517 - val_accuracy: 0.7525\n",
      "Epoch 709/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.4189 - val_accuracy: 0.7509\n",
      "Epoch 710/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.9475 - val_accuracy: 0.7546\n",
      "Epoch 711/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 10.0390 - val_accuracy: 0.7493\n",
      "Epoch 712/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 9.2488 - val_accuracy: 0.7504\n",
      "Epoch 713/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 8.8389 - val_accuracy: 0.7563\n",
      "Epoch 714/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 8.7273 - val_accuracy: 0.7410\n",
      "Epoch 715/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 8.6596 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 9.4655 - val_accuracy: 0.7555\n",
      "Epoch 717/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 9.2386 - val_accuracy: 0.7549\n",
      "Epoch 718/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 10.8899 - val_accuracy: 0.7542\n",
      "Epoch 719/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 9.7460 - val_accuracy: 0.7531\n",
      "Epoch 720/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 8.8635 - val_accuracy: 0.7556\n",
      "Epoch 721/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 9.8479 - val_accuracy: 0.7580\n",
      "Epoch 722/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 9.4840 - val_accuracy: 0.7623\n",
      "Epoch 723/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 10.3100 - val_accuracy: 0.7516\n",
      "Epoch 724/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 10.9976 - val_accuracy: 0.7579\n",
      "Epoch 725/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 9.7327 - val_accuracy: 0.7583\n",
      "Epoch 726/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 10.7187 - val_accuracy: 0.7542\n",
      "Epoch 727/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 9.5824 - val_accuracy: 0.7549\n",
      "Epoch 728/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 9.0631 - val_accuracy: 0.7491\n",
      "Epoch 729/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 8.6898 - val_accuracy: 0.7547\n",
      "Epoch 730/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 8.8995 - val_accuracy: 0.7569\n",
      "Epoch 731/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 9.6489 - val_accuracy: 0.7545\n",
      "Epoch 732/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 10.0023 - val_accuracy: 0.7552\n",
      "Epoch 733/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 8.6804 - val_accuracy: 0.7561\n",
      "Epoch 734/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 8.0714 - val_accuracy: 0.7586\n",
      "Epoch 735/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 10.8268 - val_accuracy: 0.7461\n",
      "Epoch 736/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 12.0921 - val_accuracy: 0.7417\n",
      "Epoch 737/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 9.7704 - val_accuracy: 0.7520\n",
      "Epoch 738/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 9.9216 - val_accuracy: 0.7548\n",
      "Epoch 739/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 11.0201 - val_accuracy: 0.7447\n",
      "Epoch 740/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 10.3627 - val_accuracy: 0.7554\n",
      "Epoch 741/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 9.8087 - val_accuracy: 0.7554\n",
      "Epoch 742/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 10.5697 - val_accuracy: 0.7580\n",
      "Epoch 743/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 10.6010 - val_accuracy: 0.7609\n",
      "Epoch 744/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 10.6551 - val_accuracy: 0.7508\n",
      "Epoch 745/1000\n",
      "1969/1969 [==============================] - 24s 12ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 10.3122 - val_accuracy: 0.7573\n",
      "Epoch 746/1000\n",
      "1969/1969 [==============================] - 22s 11ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 9.2937 - val_accuracy: 0.7516\n",
      "Epoch 747/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 10.6137 - val_accuracy: 0.7512\n",
      "Epoch 748/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 9.4449 - val_accuracy: 0.7521\n",
      "Epoch 749/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 10.5045 - val_accuracy: 0.7502\n",
      "Epoch 750/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.3005 - val_accuracy: 0.7511\n",
      "Epoch 751/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 8.3823 - val_accuracy: 0.7622\n",
      "Epoch 752/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 13.3186 - val_accuracy: 0.7434\n",
      "Epoch 753/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 8.8937 - val_accuracy: 0.7554\n",
      "Epoch 754/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 10.7817 - val_accuracy: 0.7606\n",
      "Epoch 755/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 10.8338 - val_accuracy: 0.7595\n",
      "Epoch 756/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 11.6375 - val_accuracy: 0.7583\n",
      "Epoch 757/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 8.0971 - val_accuracy: 0.7591\n",
      "Epoch 758/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 9.5986 - val_accuracy: 0.7449\n",
      "Epoch 759/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 10.7888 - val_accuracy: 0.7601\n",
      "Epoch 760/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 9.6939 - val_accuracy: 0.7564\n",
      "Epoch 761/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 9.2106 - val_accuracy: 0.7471\n",
      "Epoch 762/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 10.7252 - val_accuracy: 0.7568\n",
      "Epoch 763/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 10.3626 - val_accuracy: 0.7511\n",
      "Epoch 764/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 10.8067 - val_accuracy: 0.7614\n",
      "Epoch 765/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 10.1803 - val_accuracy: 0.7510\n",
      "Epoch 766/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 11.1756 - val_accuracy: 0.7615\n",
      "Epoch 767/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 10.0158 - val_accuracy: 0.7574\n",
      "Epoch 768/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 9.8233 - val_accuracy: 0.7560\n",
      "Epoch 769/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 8.8569 - val_accuracy: 0.7531\n",
      "Epoch 770/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 10.6125 - val_accuracy: 0.7465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 10.8652 - val_accuracy: 0.7473\n",
      "Epoch 772/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 12.4053 - val_accuracy: 0.7498\n",
      "Epoch 773/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 10.6548 - val_accuracy: 0.7479\n",
      "Epoch 774/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 10.3101 - val_accuracy: 0.7615\n",
      "Epoch 775/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 12.0326 - val_accuracy: 0.7441\n",
      "Epoch 776/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 10.4636 - val_accuracy: 0.7492\n",
      "Epoch 777/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 10.2508 - val_accuracy: 0.7508\n",
      "Epoch 778/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 9.4210 - val_accuracy: 0.7514\n",
      "Epoch 779/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 10.0743 - val_accuracy: 0.7545\n",
      "Epoch 780/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 10.1959 - val_accuracy: 0.7543\n",
      "Epoch 781/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 10.2619 - val_accuracy: 0.7607\n",
      "Epoch 782/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 10.7766 - val_accuracy: 0.7626\n",
      "Epoch 783/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 8.7315 - val_accuracy: 0.7601\n",
      "Epoch 784/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 9.4507 - val_accuracy: 0.7626\n",
      "Epoch 785/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 10.4138 - val_accuracy: 0.7584\n",
      "Epoch 786/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 8.0544 - val_accuracy: 0.7641\n",
      "Epoch 787/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.0745 - val_accuracy: 0.7538\n",
      "Epoch 788/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 9.9827 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 8.3511 - val_accuracy: 0.7567\n",
      "Epoch 790/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 9.1769 - val_accuracy: 0.7636\n",
      "Epoch 791/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 10.0739 - val_accuracy: 0.7568\n",
      "Epoch 792/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 11.8941 - val_accuracy: 0.7460\n",
      "Epoch 793/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 9.2221 - val_accuracy: 0.7661\n",
      "Epoch 794/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 11.4968 - val_accuracy: 0.7612\n",
      "Epoch 795/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 10.3680 - val_accuracy: 0.7555\n",
      "Epoch 796/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 9.6987 - val_accuracy: 0.7516\n",
      "Epoch 797/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 8.3502 - val_accuracy: 0.7491\n",
      "Epoch 798/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 10.0685 - val_accuracy: 0.7598\n",
      "Epoch 799/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 9.3200 - val_accuracy: 0.7599\n",
      "Epoch 800/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 10.9054 - val_accuracy: 0.7516\n",
      "Epoch 801/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 10.2760 - val_accuracy: 0.7568\n",
      "Epoch 802/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 10.6671 - val_accuracy: 0.7627\n",
      "Epoch 803/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 9.1669 - val_accuracy: 0.7583\n",
      "Epoch 804/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 9.4403 - val_accuracy: 0.7621\n",
      "Epoch 805/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 9.2016 - val_accuracy: 0.7496\n",
      "Epoch 806/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 8.4407 - val_accuracy: 0.7627\n",
      "Epoch 807/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 11.7446 - val_accuracy: 0.7508\n",
      "Epoch 808/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 10.3696 - val_accuracy: 0.7566\n",
      "Epoch 809/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 10.5202 - val_accuracy: 0.7597\n",
      "Epoch 810/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 10.7347 - val_accuracy: 0.7510\n",
      "Epoch 811/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 9.4407 - val_accuracy: 0.7525\n",
      "Epoch 812/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 11.1918 - val_accuracy: 0.7534\n",
      "Epoch 813/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 10.7028 - val_accuracy: 0.7502\n",
      "Epoch 814/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 9.1464 - val_accuracy: 0.7559\n",
      "Epoch 815/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 9.5490 - val_accuracy: 0.7587\n",
      "Epoch 816/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 8.3653 - val_accuracy: 0.7584\n",
      "Epoch 817/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 10.3185 - val_accuracy: 0.7479\n",
      "Epoch 818/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 11.3151 - val_accuracy: 0.7630\n",
      "Epoch 819/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 9.2939 - val_accuracy: 0.7630\n",
      "Epoch 820/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 9.8149 - val_accuracy: 0.7626\n",
      "Epoch 821/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 10.1141 - val_accuracy: 0.7567\n",
      "Epoch 822/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 9.5565 - val_accuracy: 0.7580\n",
      "Epoch 823/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 9.5171 - val_accuracy: 0.7543\n",
      "Epoch 824/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 9.3109 - val_accuracy: 0.7669\n",
      "Epoch 825/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 10.2660 - val_accuracy: 0.7609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 10.5799 - val_accuracy: 0.7609\n",
      "Epoch 827/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 8.1888 - val_accuracy: 0.7632\n",
      "Epoch 828/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 13.0954 - val_accuracy: 0.7477\n",
      "Epoch 829/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 8.6421 - val_accuracy: 0.7464\n",
      "Epoch 830/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 10.0773 - val_accuracy: 0.7572\n",
      "Epoch 831/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 10.1539 - val_accuracy: 0.7532\n",
      "Epoch 832/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 9.6171 - val_accuracy: 0.7509\n",
      "Epoch 833/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 10.2921 - val_accuracy: 0.7480\n",
      "Epoch 834/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 9.8136 - val_accuracy: 0.7479\n",
      "Epoch 835/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 8.9367 - val_accuracy: 0.7526\n",
      "Epoch 836/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 10.0600 - val_accuracy: 0.7482\n",
      "Epoch 837/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 9.9850 - val_accuracy: 0.7616\n",
      "Epoch 838/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 8.9500 - val_accuracy: 0.7645\n",
      "Epoch 839/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 10.7452 - val_accuracy: 0.7573\n",
      "Epoch 840/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 9.5802 - val_accuracy: 0.7511\n",
      "Epoch 841/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 10.4691 - val_accuracy: 0.7528\n",
      "Epoch 842/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 9.8308 - val_accuracy: 0.7598\n",
      "Epoch 843/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 9.6302 - val_accuracy: 0.7515\n",
      "Epoch 844/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 9.7293 - val_accuracy: 0.7588\n",
      "Epoch 845/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 11.3482 - val_accuracy: 0.7521\n",
      "Epoch 846/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 11.5019 - val_accuracy: 0.7564\n",
      "Epoch 847/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 11.1931 - val_accuracy: 0.7546\n",
      "Epoch 848/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 8.5151 - val_accuracy: 0.7569\n",
      "Epoch 849/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 10.1027 - val_accuracy: 0.7620\n",
      "Epoch 850/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 10.0477 - val_accuracy: 0.7557\n",
      "Epoch 851/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 11.5371 - val_accuracy: 0.7562\n",
      "Epoch 852/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 10.3548 - val_accuracy: 0.7419\n",
      "Epoch 853/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 9.7014 - val_accuracy: 0.7515\n",
      "Epoch 854/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 9.9034 - val_accuracy: 0.7562\n",
      "Epoch 855/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 9.5537 - val_accuracy: 0.7584\n",
      "Epoch 856/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 11.7974 - val_accuracy: 0.7535\n",
      "Epoch 857/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 9.7766 - val_accuracy: 0.7612\n",
      "Epoch 858/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 9.0903 - val_accuracy: 0.7539\n",
      "Epoch 859/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 11.0531 - val_accuracy: 0.7559\n",
      "Epoch 860/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 11.0167 - val_accuracy: 0.7615\n",
      "Epoch 861/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 11.4917 - val_accuracy: 0.7508\n",
      "Epoch 862/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 9.6297 - val_accuracy: 0.7599\n",
      "Epoch 863/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 10.2720 - val_accuracy: 0.7504\n",
      "Epoch 864/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.9689 - val_accuracy: 0.7609\n",
      "Epoch 865/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 10.3175 - val_accuracy: 0.7488\n",
      "Epoch 866/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 10.0232 - val_accuracy: 0.7472\n",
      "Epoch 867/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 9.9838 - val_accuracy: 0.7589\n",
      "Epoch 868/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 10.7410 - val_accuracy: 0.7520\n",
      "Epoch 869/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 10.5300 - val_accuracy: 0.7598\n",
      "Epoch 870/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 11.8355 - val_accuracy: 0.7476\n",
      "Epoch 871/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 10.4896 - val_accuracy: 0.7565\n",
      "Epoch 872/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 9.7850 - val_accuracy: 0.7467\n",
      "Epoch 873/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 10.7560 - val_accuracy: 0.7601\n",
      "Epoch 874/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 10.5702 - val_accuracy: 0.7510\n",
      "Epoch 875/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 11.3164 - val_accuracy: 0.7626\n",
      "Epoch 876/1000\n",
      "1969/1969 [==============================] - 24s 12ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 9.8864 - val_accuracy: 0.7568\n",
      "Epoch 877/1000\n",
      "1969/1969 [==============================] - 23s 11ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 12.6352 - val_accuracy: 0.7522\n",
      "Epoch 878/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 10.9402 - val_accuracy: 0.7505\n",
      "Epoch 879/1000\n",
      "1969/1969 [==============================] - 28s 14ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 9.8340 - val_accuracy: 0.7479\n",
      "Epoch 880/1000\n",
      "1969/1969 [==============================] - 25s 13ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 10.5244 - val_accuracy: 0.7484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 11.8663 - val_accuracy: 0.7598\n",
      "Epoch 882/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 10.3243 - val_accuracy: 0.7612\n",
      "Epoch 883/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 9.3478 - val_accuracy: 0.7654\n",
      "Epoch 884/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 9.7702 - val_accuracy: 0.7583\n",
      "Epoch 885/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 9.7118 - val_accuracy: 0.7581\n",
      "Epoch 886/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 9.1809 - val_accuracy: 0.7595\n",
      "Epoch 887/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 11.5972 - val_accuracy: 0.7468\n",
      "Epoch 888/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 11.1415 - val_accuracy: 0.7535\n",
      "Epoch 889/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 9.9810 - val_accuracy: 0.7535\n",
      "Epoch 890/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 9.6823 - val_accuracy: 0.7634\n",
      "Epoch 891/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 11.6672 - val_accuracy: 0.7646\n",
      "Epoch 892/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 10.4466 - val_accuracy: 0.7547\n",
      "Epoch 893/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 11.9096 - val_accuracy: 0.7465\n",
      "Epoch 894/1000\n",
      "1969/1969 [==============================] - 19s 9ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 9.6523 - val_accuracy: 0.7445\n",
      "Epoch 895/1000\n",
      "1969/1969 [==============================] - 29s 15ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 10.4076 - val_accuracy: 0.7528\n",
      "Epoch 896/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 11.2138 - val_accuracy: 0.7571\n",
      "Epoch 897/1000\n",
      "1969/1969 [==============================] - 33s 17ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 10.9160 - val_accuracy: 0.7538\n",
      "Epoch 898/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 10.8580 - val_accuracy: 0.7614\n",
      "Epoch 899/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 11.4053 - val_accuracy: 0.7480\n",
      "Epoch 900/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 11.6728 - val_accuracy: 0.7602\n",
      "Epoch 901/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 11.5870 - val_accuracy: 0.7559\n",
      "Epoch 902/1000\n",
      "1969/1969 [==============================] - 22s 11ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 9.9348 - val_accuracy: 0.7601\n",
      "Epoch 903/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 10.4813 - val_accuracy: 0.7501\n",
      "Epoch 904/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 10.9629 - val_accuracy: 0.7447\n",
      "Epoch 905/1000\n",
      "1969/1969 [==============================] - 21s 10ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 10.3935 - val_accuracy: 0.7589\n",
      "Epoch 906/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 10.9834 - val_accuracy: 0.7506\n",
      "Epoch 907/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 13.0893 - val_accuracy: 0.7563\n",
      "Epoch 908/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 8.1084 - val_accuracy: 0.7601\n",
      "Epoch 909/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 10.9283 - val_accuracy: 0.7602\n",
      "Epoch 910/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 11.7416 - val_accuracy: 0.7517\n",
      "Epoch 911/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 10.8835 - val_accuracy: 0.7535\n",
      "Epoch 912/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 9.9728 - val_accuracy: 0.7507\n",
      "Epoch 913/1000\n",
      "1969/1969 [==============================] - 19s 9ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 11.3850 - val_accuracy: 0.7472\n",
      "Epoch 914/1000\n",
      "1969/1969 [==============================] - 20s 10ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 9.6073 - val_accuracy: 0.7591\n",
      "Epoch 915/1000\n",
      "1969/1969 [==============================] - 21s 11ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 10.9447 - val_accuracy: 0.7508\n",
      "Epoch 916/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 9.5532 - val_accuracy: 0.7583\n",
      "Epoch 917/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 11.0610 - val_accuracy: 0.7576\n",
      "Epoch 918/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 9.1137 - val_accuracy: 0.7472\n",
      "Epoch 919/1000\n",
      "1969/1969 [==============================] - 17s 8ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 8.5886 - val_accuracy: 0.7470\n",
      "Epoch 920/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 10.2187 - val_accuracy: 0.7570\n",
      "Epoch 921/1000\n",
      "1969/1969 [==============================] - 18s 9ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 9.6213 - val_accuracy: 0.7465\n",
      "Epoch 922/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 9.8023 - val_accuracy: 0.7496\n",
      "Epoch 923/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 11.8481 - val_accuracy: 0.7536\n",
      "Epoch 924/1000\n",
      "1969/1969 [==============================] - 17s 9ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 10.1127 - val_accuracy: 0.7630\n",
      "Epoch 925/1000\n",
      "1969/1969 [==============================] - 19s 10ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 10.5345 - val_accuracy: 0.7572\n",
      "Epoch 926/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 11.1554 - val_accuracy: 0.7483\n",
      "Epoch 927/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 10.5257 - val_accuracy: 0.7510\n",
      "Epoch 928/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 9.3809 - val_accuracy: 0.7601\n",
      "Epoch 929/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 9.5202 - val_accuracy: 0.7622\n",
      "Epoch 930/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 9.6297 - val_accuracy: 0.7542\n",
      "Epoch 931/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 10.5671 - val_accuracy: 0.7498\n",
      "Epoch 932/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 8.8382 - val_accuracy: 0.7477\n",
      "Epoch 933/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 10.4096 - val_accuracy: 0.7541\n",
      "Epoch 934/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 9.5668 - val_accuracy: 0.7505\n",
      "Epoch 935/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 10.4233 - val_accuracy: 0.7577\n",
      "Epoch 936/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 11.1275 - val_accuracy: 0.7526\n",
      "Epoch 937/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 11.2673 - val_accuracy: 0.7540\n",
      "Epoch 938/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 10.7500 - val_accuracy: 0.7595\n",
      "Epoch 939/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 9.8820 - val_accuracy: 0.7524\n",
      "Epoch 940/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 11.3603 - val_accuracy: 0.7510\n",
      "Epoch 941/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 9.9431 - val_accuracy: 0.7545\n",
      "Epoch 942/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 10.8569 - val_accuracy: 0.7525\n",
      "Epoch 943/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 10.3656 - val_accuracy: 0.7483\n",
      "Epoch 944/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 8.3328 - val_accuracy: 0.7477\n",
      "Epoch 945/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 10.6248 - val_accuracy: 0.7433\n",
      "Epoch 946/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 12.6845 - val_accuracy: 0.7496\n",
      "Epoch 947/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 11.1896 - val_accuracy: 0.7618\n",
      "Epoch 948/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 11.5609 - val_accuracy: 0.7516\n",
      "Epoch 949/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 9.9548 - val_accuracy: 0.7532\n",
      "Epoch 950/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 10.3551 - val_accuracy: 0.7563\n",
      "Epoch 951/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 12.6821 - val_accuracy: 0.7568\n",
      "Epoch 952/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 11.4569 - val_accuracy: 0.7533\n",
      "Epoch 953/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 11.3285 - val_accuracy: 0.7533\n",
      "Epoch 954/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 9.4052 - val_accuracy: 0.7502\n",
      "Epoch 955/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 10.1718 - val_accuracy: 0.7465\n",
      "Epoch 956/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 9.0382 - val_accuracy: 0.7649\n",
      "Epoch 957/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 11.9771 - val_accuracy: 0.7565\n",
      "Epoch 958/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 9.5280 - val_accuracy: 0.7530\n",
      "Epoch 959/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 13.4235 - val_accuracy: 0.7548\n",
      "Epoch 960/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 9.8164 - val_accuracy: 0.7614\n",
      "Epoch 961/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 10.8939 - val_accuracy: 0.7576\n",
      "Epoch 962/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 10.2720 - val_accuracy: 0.7591\n",
      "Epoch 963/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 10.6951 - val_accuracy: 0.7580\n",
      "Epoch 964/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 11.4777 - val_accuracy: 0.7538\n",
      "Epoch 965/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 11.0455 - val_accuracy: 0.7608\n",
      "Epoch 966/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 10.5533 - val_accuracy: 0.7494\n",
      "Epoch 967/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 9.5301 - val_accuracy: 0.7605\n",
      "Epoch 968/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 10.7908 - val_accuracy: 0.7598\n",
      "Epoch 969/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 10.3135 - val_accuracy: 0.7563\n",
      "Epoch 970/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 10.3218 - val_accuracy: 0.7446\n",
      "Epoch 971/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 10.4633 - val_accuracy: 0.7615\n",
      "Epoch 972/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 10.3933 - val_accuracy: 0.7566\n",
      "Epoch 973/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 10.4128 - val_accuracy: 0.7621\n",
      "Epoch 974/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 11.1985 - val_accuracy: 0.7562\n",
      "Epoch 975/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 10.7902 - val_accuracy: 0.7531\n",
      "Epoch 976/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 9.5305 - val_accuracy: 0.7591\n",
      "Epoch 977/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 11.5666 - val_accuracy: 0.7550\n",
      "Epoch 978/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 13.0386 - val_accuracy: 0.7487\n",
      "Epoch 979/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 11.9346 - val_accuracy: 0.7644\n",
      "Epoch 980/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 12.3381 - val_accuracy: 0.7582\n",
      "Epoch 981/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 10.4607 - val_accuracy: 0.7499\n",
      "Epoch 982/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 11.8252 - val_accuracy: 0.7448\n",
      "Epoch 983/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 12.1781 - val_accuracy: 0.7591\n",
      "Epoch 984/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 10.8051 - val_accuracy: 0.7510\n",
      "Epoch 985/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 9.2642 - val_accuracy: 0.7485\n",
      "Epoch 986/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 11.2462 - val_accuracy: 0.7626\n",
      "Epoch 987/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 10.8359 - val_accuracy: 0.7504\n",
      "Epoch 988/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 11.0086 - val_accuracy: 0.7607\n",
      "Epoch 989/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 12.5247 - val_accuracy: 0.7611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "1969/1969 [==============================] - 16s 8ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 9.8268 - val_accuracy: 0.7609\n",
      "Epoch 991/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 11.9099 - val_accuracy: 0.7582\n",
      "Epoch 992/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 10.1916 - val_accuracy: 0.7568\n",
      "Epoch 993/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 11.6484 - val_accuracy: 0.7547\n",
      "Epoch 994/1000\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 12.1788 - val_accuracy: 0.7505\n",
      "Epoch 995/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 11.0814 - val_accuracy: 0.7606\n",
      "Epoch 996/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 9.0018 - val_accuracy: 0.7575\n",
      "Epoch 997/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 12.0895 - val_accuracy: 0.7589\n",
      "Epoch 998/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 10.6207 - val_accuracy: 0.7588\n",
      "Epoch 999/1000\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 14.5901 - val_accuracy: 0.7491\n",
      "Epoch 1000/1000\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 9.7426 - val_accuracy: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d04378f610>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "x_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "x_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "model.fit(x_train, Y_train, batch_size=64, epochs=1000, validation_data=(x_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 2s 3ms/step - loss: 9.7426 - accuracy: 0.7560\n",
      "\n",
      "Loss: 9.74, Accuracy: 75.60%\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "y_pred = model.predict_classes(x_test)\n",
    "loss, accuracy = model.evaluate(x_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\pedro\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: model_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normal vs DoS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_DoS (113270, 122)\n",
      "Dimensões de X_DoS_test (17171, 122)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensões de X_DoS', X_DoS.shape)\n",
    "print('Dimensões de X_DoS_test', X_DoS_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'DOS'\n",
    "cnnDoS = Sequential()\n",
    "cnnDoS.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnDoS.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnDoS.add(MaxPooling1D(pool_size=2))\n",
    "cnnDoS.add(Flatten())\n",
    "cnnDoS.add(Dense(128, activation=\"relu\"))\n",
    "cnnDoS.add(Dropout(0.5))\n",
    "cnnDoS.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnDoS.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_DoS_train = np.reshape(X_DoS, (X_DoS.shape[0], X_DoS.shape[1], 1))\n",
    "x_Dos_val = np.reshape(X_DoS_test, (X_DoS_test.shape[0], X_DoS_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 9.7101e-04 - accuracy: 0.9996\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92027, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.7054e-04 - accuracy: 0.9996 - val_loss: 1.7811 - val_accuracy: 0.9203\n",
      "Epoch 2/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 9.8020e-04 - accuracy: 0.9997\n",
      "Epoch 00002: val_accuracy improved from 0.92027 to 0.93285, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.7863e-04 - accuracy: 0.9997 - val_loss: 1.2170 - val_accuracy: 0.9329\n",
      "Epoch 3/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 7.4114e-04 - accuracy: 0.9997\n",
      "Epoch 00003: val_accuracy did not improve from 0.93285\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.4036e-04 - accuracy: 0.9997 - val_loss: 1.5957 - val_accuracy: 0.9245\n",
      "Epoch 4/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00004: val_accuracy did not improve from 0.93285\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.3559 - val_accuracy: 0.9044\n",
      "Epoch 5/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 6.7407e-04 - accuracy: 0.9997\n",
      "Epoch 00005: val_accuracy did not improve from 0.93285\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 6.7394e-04 - accuracy: 0.9997 - val_loss: 1.3517 - val_accuracy: 0.9309\n",
      "Epoch 6/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 7.2374e-04 - accuracy: 0.9998\n",
      "Epoch 00006: val_accuracy did not improve from 0.93285\n",
      "1770/1770 [==============================] - 19s 10ms/step - loss: 7.2306e-04 - accuracy: 0.9998 - val_loss: 1.4318 - val_accuracy: 0.9287\n",
      "Epoch 7/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 8.3060e-04 - accuracy: 0.9997\n",
      "Epoch 00007: val_accuracy improved from 0.93285 to 0.93996, saving model to results/checkpoint-best.hdf5\n",
      "1770/1770 [==============================] - 19s 10ms/step - loss: 8.3060e-04 - accuracy: 0.9997 - val_loss: 1.1749 - val_accuracy: 0.9400\n",
      "Epoch 8/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00008: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.2515 - val_accuracy: 0.9122\n",
      "Epoch 9/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 7.9952e-04 - accuracy: 0.9997\n",
      "Epoch 00009: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.9952e-04 - accuracy: 0.9997 - val_loss: 1.5147 - val_accuracy: 0.9259\n",
      "Epoch 10/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 8.6085e-04 - accuracy: 0.9997\n",
      "Epoch 00010: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.5995e-04 - accuracy: 0.9997 - val_loss: 1.8462 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996 ETA: 0s - loss: 0.0010 - accuracy: 0.99\n",
      "Epoch 00011: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 1.4934 - val_accuracy: 0.9236\n",
      "Epoch 12/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00012: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.1407 - val_accuracy: 0.9323\n",
      "Epoch 13/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 6.2407e-04 - accuracy: 0.9997\n",
      "Epoch 00013: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 6.2307e-04 - accuracy: 0.9997 - val_loss: 2.7751 - val_accuracy: 0.9138\n",
      "Epoch 14/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00014: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 10ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.0000 - val_accuracy: 0.9116\n",
      "Epoch 15/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 9.0176e-04 - accuracy: 0.9997\n",
      "Epoch 00015: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 9.0133e-04 - accuracy: 0.9997 - val_loss: 2.2153 - val_accuracy: 0.9096\n",
      "Epoch 16/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 9.4287e-04 - accuracy: 0.9997\n",
      "Epoch 00016: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.4189e-04 - accuracy: 0.9997 - val_loss: 1.6453 - val_accuracy: 0.9192\n",
      "Epoch 17/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 8.5701e-04 - accuracy: 0.9997\n",
      "Epoch 00017: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.5611e-04 - accuracy: 0.9997 - val_loss: 2.9845 - val_accuracy: 0.9106\n",
      "Epoch 18/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00018: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.1504 - val_accuracy: 0.9223\n",
      "Epoch 19/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00019: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 10ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.5180 - val_accuracy: 0.9308\n",
      "Epoch 20/100\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 00020: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 2.0862 - val_accuracy: 0.8881\n",
      "Epoch 21/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 5.9866e-04 - accuracy: 0.9997\n",
      "Epoch 00021: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 5.9866e-04 - accuracy: 0.9997 - val_loss: 2.0724 - val_accuracy: 0.9185\n",
      "Epoch 22/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00022: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.6487 - val_accuracy: 0.9172\n",
      "Epoch 23/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00023: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.3766 - val_accuracy: 0.9019\n",
      "Epoch 24/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 7.1638e-04 - accuracy: 0.9997\n",
      "Epoch 00024: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.2060e-04 - accuracy: 0.9997 - val_loss: 1.8156 - val_accuracy: 0.8953\n",
      "Epoch 25/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 8.4145e-04 - accuracy: 0.9997\n",
      "Epoch 00025: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.4145e-04 - accuracy: 0.9997 - val_loss: 1.5952 - val_accuracy: 0.9072\n",
      "Epoch 26/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 7.7971e-04 - accuracy: 0.9997\n",
      "Epoch 00026: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.7971e-04 - accuracy: 0.9997 - val_loss: 1.6769 - val_accuracy: 0.9027\n",
      "Epoch 27/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00027: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.8163 - val_accuracy: 0.9185\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1766/1770 [============================>.] - ETA: 0s - loss: 7.8762e-04 - accuracy: 0.9997\n",
      "Epoch 00028: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.8591e-04 - accuracy: 0.9997 - val_loss: 1.8446 - val_accuracy: 0.9210\n",
      "Epoch 29/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 8.2950e-04 - accuracy: 0.9997\n",
      "Epoch 00029: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.2785e-04 - accuracy: 0.9997 - val_loss: 1.9004 - val_accuracy: 0.9206\n",
      "Epoch 30/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 8.0893e-04 - accuracy: 0.9997\n",
      "Epoch 00030: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.0763e-04 - accuracy: 0.9997 - val_loss: 2.8260 - val_accuracy: 0.8852\n",
      "Epoch 31/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 6.6306e-04 - accuracy: 0.9997\n",
      "Epoch 00031: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 6.6237e-04 - accuracy: 0.9997 - val_loss: 4.4641 - val_accuracy: 0.9101\n",
      "Epoch 32/100\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00032: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.4431 - val_accuracy: 0.9108\n",
      "Epoch 33/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 00033: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.4257 - val_accuracy: 0.9353\n",
      "Epoch 34/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00034: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.6715 - val_accuracy: 0.9292\n",
      "Epoch 35/100\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 9.0617e-04 - accuracy: 0.9996\n",
      "Epoch 00035: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.0369e-04 - accuracy: 0.9996 - val_loss: 1.6061 - val_accuracy: 0.8969\n",
      "Epoch 36/100\n",
      "1764/1770 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00036: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.6882 - val_accuracy: 0.9247\n",
      "Epoch 37/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 7.4892e-04 - accuracy: 0.9997\n",
      "Epoch 00037: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.4814e-04 - accuracy: 0.9997 - val_loss: 1.9950 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 8.3164e-04 - accuracy: 0.9997\n",
      "Epoch 00038: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.2986e-04 - accuracy: 0.9997 - val_loss: 1.8613 - val_accuracy: 0.9168\n",
      "Epoch 39/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 8.9310e-04 - accuracy: 0.9997\n",
      "Epoch 00039: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.9167e-04 - accuracy: 0.9997 - val_loss: 2.0224 - val_accuracy: 0.8996\n",
      "Epoch 40/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 9.1182e-04 - accuracy: 0.9997\n",
      "Epoch 00040: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.1036e-04 - accuracy: 0.9997 - val_loss: 2.6450 - val_accuracy: 0.8888\n",
      "Epoch 41/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 9.0251e-04 - accuracy: 0.9997\n",
      "Epoch 00041: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.0157e-04 - accuracy: 0.9997 - val_loss: 2.7303 - val_accuracy: 0.8895\n",
      "Epoch 42/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00042: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.3660 - val_accuracy: 0.9174\n",
      "Epoch 43/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00043: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 3.5383 - val_accuracy: 0.8765\n",
      "Epoch 44/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 8.3127e-04 - accuracy: 0.9997\n",
      "Epoch 00044: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.2994e-04 - accuracy: 0.9997 - val_loss: 1.8068 - val_accuracy: 0.8999\n",
      "Epoch 45/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00045: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.1594 - val_accuracy: 0.9156\n",
      "Epoch 46/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 7.3765e-04 - accuracy: 0.9997\n",
      "Epoch 00046: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 7.3646e-04 - accuracy: 0.9997 - val_loss: 1.7759 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9997 ETA: \n",
      "Epoch 00047: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 1.9939 - val_accuracy: 0.9274\n",
      "Epoch 48/100\n",
      "1764/1770 [============================>.] - ETA: 0s - loss: 9.7604e-04 - accuracy: 0.9997\n",
      "Epoch 00048: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.7282e-04 - accuracy: 0.9997 - val_loss: 2.5095 - val_accuracy: 0.9207\n",
      "Epoch 49/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 6.6655e-04 - accuracy: 0.9997\n",
      "Epoch 00049: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 6.6655e-04 - accuracy: 0.9997 - val_loss: 2.0725 - val_accuracy: 0.9268\n",
      "Epoch 50/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 7.1538e-04 - accuracy: 0.9997\n",
      "Epoch 00050: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 7.1423e-04 - accuracy: 0.9997 - val_loss: 3.4753 - val_accuracy: 0.9165\n",
      "Epoch 51/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 8.7390e-04 - accuracy: 0.9997\n",
      "Epoch 00051: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 8.8871e-04 - accuracy: 0.9997 - val_loss: 2.8472 - val_accuracy: 0.8972\n",
      "Epoch 52/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 9.4361e-04 - accuracy: 0.9997\n",
      "Epoch 00052: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 9.4361e-04 - accuracy: 0.9997 - val_loss: 2.6481 - val_accuracy: 0.9209\n",
      "Epoch 53/100\n",
      "1764/1770 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00053: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.1931 - val_accuracy: 0.8987\n",
      "Epoch 54/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 6.3500e-04 - accuracy: 0.9997\n",
      "Epoch 00054: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 6.3500e-04 - accuracy: 0.9997 - val_loss: 2.3356 - val_accuracy: 0.8989\n",
      "Epoch 55/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 7.3053e-04 - accuracy: 0.9997\n",
      "Epoch 00055: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 24s 14ms/step - loss: 7.3046e-04 - accuracy: 0.9997 - val_loss: 2.1846 - val_accuracy: 0.8935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 9.5822e-04 - accuracy: 0.9997\n",
      "Epoch 00056: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 9.5560e-04 - accuracy: 0.9997 - val_loss: 2.0327 - val_accuracy: 0.8971\n",
      "Epoch 57/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 9.8145e-04 - accuracy: 0.9997\n",
      "Epoch 00057: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.8074e-04 - accuracy: 0.9997 - val_loss: 2.7054 - val_accuracy: 0.8886\n",
      "Epoch 58/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 7.6332e-04 - accuracy: 0.9997\n",
      "Epoch 00058: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 7.6332e-04 - accuracy: 0.9997 - val_loss: 3.3604 - val_accuracy: 0.9132\n",
      "Epoch 59/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 8.4027e-04 - accuracy: 0.9997\n",
      "Epoch 00059: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 8.3939e-04 - accuracy: 0.9997 - val_loss: 1.7744 - val_accuracy: 0.9291\n",
      "Epoch 60/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 00060: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 2.6159 - val_accuracy: 0.9200\n",
      "Epoch 61/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00061: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 2.4324 - val_accuracy: 0.9249\n",
      "Epoch 62/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 9.3095e-04 - accuracy: 0.9997\n",
      "Epoch 00062: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 9.2897e-04 - accuracy: 0.9997 - val_loss: 1.8530 - val_accuracy: 0.9087\n",
      "Epoch 63/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 6.8253e-04 - accuracy: 0.9997\n",
      "Epoch 00063: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 6.8143e-04 - accuracy: 0.9997 - val_loss: 2.6763 - val_accuracy: 0.9256\n",
      "Epoch 64/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 9.3990e-04 - accuracy: 0.9996\n",
      "Epoch 00064: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 9.3839e-04 - accuracy: 0.9996 - val_loss: 2.4027 - val_accuracy: 0.8948\n",
      "Epoch 65/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00065: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.4810 - val_accuracy: 0.9232\n",
      "Epoch 66/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00066: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 2.7614 - val_accuracy: 0.8862\n",
      "Epoch 67/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00067: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 3.3362 - val_accuracy: 0.8874\n",
      "Epoch 68/100\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 6.9108e-04 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 6.9011e-04 - accuracy: 0.9998 - val_loss: 3.1065 - val_accuracy: 0.8870\n",
      "Epoch 69/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 9.0415e-04 - accuracy: 0.9997\n",
      "Epoch 00069: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 9.0448e-04 - accuracy: 0.9997 - val_loss: 3.9218 - val_accuracy: 0.9020\n",
      "Epoch 70/100\n",
      "1764/1770 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 00070: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 3.1879 - val_accuracy: 0.8979\n",
      "Epoch 71/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00071: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 3.8985 - val_accuracy: 0.8795\n",
      "Epoch 72/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00072: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 2.6906 - val_accuracy: 0.9256\n",
      "Epoch 73/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 8.5779e-04 - accuracy: 0.9997\n",
      "Epoch 00073: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 8.5642e-04 - accuracy: 0.9997 - val_loss: 2.6441 - val_accuracy: 0.9198\n",
      "Epoch 74/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 9.0036e-04 - accuracy: 0.9997\n",
      "Epoch 00074: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 8.9840e-04 - accuracy: 0.9997 - val_loss: 3.0801 - val_accuracy: 0.8861\n",
      "Epoch 75/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 7.8242e-04 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 7.8242e-04 - accuracy: 0.9997 - val_loss: 4.7440 - val_accuracy: 0.8945\n",
      "Epoch 76/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 8.5324e-04 - accuracy: 0.9997\n",
      "Epoch 00076: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 8.5139e-04 - accuracy: 0.9997 - val_loss: 3.0050 - val_accuracy: 0.9128\n",
      "Epoch 77/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 8.8347e-04 - accuracy: 0.9997\n",
      "Epoch 00077: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 8.8255e-04 - accuracy: 0.9997 - val_loss: 5.0066 - val_accuracy: 0.8924\n",
      "Epoch 78/100\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00078: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.2923 - val_accuracy: 0.9223\n",
      "Epoch 79/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 7.2101e-04 - accuracy: 0.9997\n",
      "Epoch 00079: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 7.2026e-04 - accuracy: 0.9997 - val_loss: 3.2460 - val_accuracy: 0.8939\n",
      "Epoch 80/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 9.5888e-04 - accuracy: 0.9996\n",
      "Epoch 00080: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 9.5680e-04 - accuracy: 0.9996 - val_loss: 1.7281 - val_accuracy: 0.9096\n",
      "Epoch 81/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 7.0223e-04 - accuracy: 0.9997\n",
      "Epoch 00081: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 7.0190e-04 - accuracy: 0.9997 - val_loss: 2.0371 - val_accuracy: 0.9019\n",
      "Epoch 82/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9997\n",
      "Epoch 00082: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 12ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 2.3027 - val_accuracy: 0.9270\n",
      "Epoch 83/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 6.8662e-04 - accuracy: 0.9997\n",
      "Epoch 00083: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 6.8513e-04 - accuracy: 0.9997 - val_loss: 2.2955 - val_accuracy: 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 8.3764e-04 - accuracy: 0.9997\n",
      "Epoch 00084: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 18s 10ms/step - loss: 8.3630e-04 - accuracy: 0.9997 - val_loss: 1.7050 - val_accuracy: 0.9216\n",
      "Epoch 85/100\n",
      "1769/1770 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9996\n",
      "Epoch 00085: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 0.0085 - accuracy: 0.9996 - val_loss: 2.3558 - val_accuracy: 0.9121\n",
      "Epoch 86/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 9.2446e-04 - accuracy: 0.9997\n",
      "Epoch 00086: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 9.2909e-04 - accuracy: 0.9997 - val_loss: 3.7943 - val_accuracy: 0.9124\n",
      "Epoch 87/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00087: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 3.6471 - val_accuracy: 0.9146\n",
      "Epoch 88/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 7.0907e-04 - accuracy: 0.9997\n",
      "Epoch 00088: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 22s 12ms/step - loss: 7.0833e-04 - accuracy: 0.9997 - val_loss: 2.6320 - val_accuracy: 0.9059\n",
      "Epoch 89/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 9.2389e-04 - accuracy: 0.9997\n",
      "Epoch 00089: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 9.2389e-04 - accuracy: 0.9997 - val_loss: 1.6507 - val_accuracy: 0.9105\n",
      "Epoch 90/100\n",
      "1765/1770 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00090: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 12ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.8298 - val_accuracy: 0.9086\n",
      "Epoch 91/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 9.8812e-04 - accuracy: 0.9996\n",
      "Epoch 00091: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 9.8653e-04 - accuracy: 0.9996 - val_loss: 2.9017 - val_accuracy: 0.9004\n",
      "Epoch 92/100\n",
      "1766/1770 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00092: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 2.5846 - val_accuracy: 0.9021\n",
      "Epoch 93/100\n",
      "1768/1770 [============================>.] - ETA: 0s - loss: 8.7305e-04 - accuracy: 0.9997\n",
      "Epoch 00093: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 8.7214e-04 - accuracy: 0.9997 - val_loss: 2.7977 - val_accuracy: 0.9002\n",
      "Epoch 94/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 8.8109e-04 - accuracy: 0.9997\n",
      "Epoch 00094: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 8.7967e-04 - accuracy: 0.9997 - val_loss: 2.1765 - val_accuracy: 0.9063\n",
      "Epoch 95/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 7.7025e-04 - accuracy: 0.9996\n",
      "Epoch 00095: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 12ms/step - loss: 7.6901e-04 - accuracy: 0.9996 - val_loss: 2.5450 - val_accuracy: 0.8993\n",
      "Epoch 96/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 9.5983e-04 - accuracy: 0.9997\n",
      "Epoch 00096: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 20s 11ms/step - loss: 9.5983e-04 - accuracy: 0.9997 - val_loss: 1.8448 - val_accuracy: 0.9059\n",
      "Epoch 97/100\n",
      "1767/1770 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00097: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 23s 13ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 2.0189 - val_accuracy: 0.9311\n",
      "Epoch 98/100\n",
      "1770/1770 [==============================] - ETA: 0s - loss: 7.2846e-04 - accuracy: 0.9997\n",
      "Epoch 00098: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 21s 12ms/step - loss: 7.2846e-04 - accuracy: 0.9997 - val_loss: 2.0718 - val_accuracy: 0.9066\n",
      "Epoch 99/100\n",
      "1764/1770 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9997\n",
      "Epoch 00099: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 3.7470 - val_accuracy: 0.9184\n",
      "Epoch 100/100\n",
      "1764/1770 [============================>.] - ETA: 0s - loss: 7.6623e-04 - accuracy: 0.9997\n",
      "Epoch 00100: val_accuracy did not improve from 0.93996\n",
      "1770/1770 [==============================] - 19s 11ms/step - loss: 7.7991e-04 - accuracy: 0.9997 - val_loss: 2.1287 - val_accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "#Treino\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-best.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n",
    "csv_logger = CSVLogger('results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnnDoS.fit(x_DoS_train, Y_DoS, batch_size=64, epochs=100, validation_data=(x_Dos_val, Y_DoS_test), callbacks=[checkpointer,csv_logger])\n",
    "cnnDoS.save(\"results/cnn_DoS_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnDoS.load_weights(\"results/checkpoint-best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9614</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>934</td>\n",
       "      <td>6526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks   0.0   1.0\n",
       "Actual attacks               \n",
       "0                  9614    97\n",
       "1                   934  6526"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_DoS_pred=cnnDoS.predict(x_Dos_val)\n",
    "y_DoS_pred = np.around(np.reshape(y_DoS_pred, y_DoS_pred.shape[0]))\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_DoS_test, y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.939957\n",
      "racall\n",
      "0.874799\n",
      "precision\n",
      "0.985354\n",
      "f1score\n",
      "0.926791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "accuracyDoS = accuracy_score(Y_DoS_test, y_DoS_pred)\n",
    "recallDoS = recall_score(Y_DoS_test, y_DoS_pred, average=\"binary\")\n",
    "precisionDoS = precision_score(Y_DoS_test, y_DoS_pred, average=\"binary\")\n",
    "f1DoS = f1_score(Y_DoS_test, y_DoS_pred, average=\"binary\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracyDoS)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recallDoS)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precisionDoS)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1DoS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normal vs Probe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_Probe (78999, 122)\n",
      "Dimensões de X_Probe_test (12132, 122)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensões de X_Probe', X_Probe.shape)\n",
    "print('Dimensões de X_Probe_test', X_Probe_test.shape)\n",
    "Y_Probe2 = Y_Probe.replace(2,1)\n",
    "Y_Probe_test2 = Y_Probe_test.replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'Probe'\n",
    "cnnProbe = Sequential()\n",
    "cnnProbe.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnProbe.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnProbe.add(MaxPooling1D(pool_size=2))\n",
    "cnnProbe.add(Flatten())\n",
    "cnnProbe.add(Dense(128, activation=\"relu\"))\n",
    "cnnProbe.add(Dropout(0.5))\n",
    "cnnProbe.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnProbe.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_Probe_train = np.reshape(X_Probe, (X_Probe.shape[0], X_Probe.shape[1], 1))\n",
    "x_Probe_val = np.reshape(X_Probe_test, (X_Probe_test.shape[0], X_Probe_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9889\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88724, saving model to results/checkpointProbe-best.hdf5\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0384 - accuracy: 0.9889 - val_loss: 0.3462 - val_accuracy: 0.8872\n",
      "Epoch 2/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9943\n",
      "Epoch 00002: val_accuracy improved from 0.88724 to 0.90422, saving model to results/checkpointProbe-best.hdf5\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.2558 - val_accuracy: 0.9042\n",
      "Epoch 3/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9956\n",
      "Epoch 00003: val_accuracy improved from 0.90422 to 0.90669, saving model to results/checkpointProbe-best.hdf5\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.3532 - val_accuracy: 0.9067\n",
      "Epoch 4/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9966\n",
      "Epoch 00004: val_accuracy improved from 0.90669 to 0.91551, saving model to results/checkpointProbe-best.hdf5\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.3501 - val_accuracy: 0.9155\n",
      "Epoch 5/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9968\n",
      "Epoch 00005: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.3637 - val_accuracy: 0.8970\n",
      "Epoch 6/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 00006: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.4096 - val_accuracy: 0.8818\n",
      "Epoch 7/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 00007: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.4985 - val_accuracy: 0.8926\n",
      "Epoch 8/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9974\n",
      "Epoch 00008: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6012 - val_accuracy: 0.8875\n",
      "Epoch 9/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9977\n",
      "Epoch 00009: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.5294 - val_accuracy: 0.8947\n",
      "Epoch 10/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 00010: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.5565 - val_accuracy: 0.8807\n",
      "Epoch 11/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 00011: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.6332 - val_accuracy: 0.8971\n",
      "Epoch 12/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9976\n",
      "Epoch 00012: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.7482 - val_accuracy: 0.8877\n",
      "Epoch 13/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 00013: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.8014 - val_accuracy: 0.8938\n",
      "Epoch 14/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 00014: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.7993 - val_accuracy: 0.8998\n",
      "Epoch 15/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 00015: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.8665 - val_accuracy: 0.8794\n",
      "Epoch 16/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 00016: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.1557 - val_accuracy: 0.8887\n",
      "Epoch 17/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 00017: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.7892 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00018: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.8143 - val_accuracy: 0.8934\n",
      "Epoch 19/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9982\n",
      "Epoch 00019: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.9822 - val_accuracy: 0.8819\n",
      "Epoch 20/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00020: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 1.0302 - val_accuracy: 0.8869\n",
      "Epoch 21/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 00021: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.1631 - val_accuracy: 0.8862\n",
      "Epoch 22/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 00022: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 1.1140 - val_accuracy: 0.8811\n",
      "Epoch 23/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 00023: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.1192 - val_accuracy: 0.8830\n",
      "Epoch 24/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9983\n",
      "Epoch 00024: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 1.3705 - val_accuracy: 0.8809\n",
      "Epoch 25/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 00025: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.0374 - val_accuracy: 0.8961\n",
      "Epoch 26/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 00026: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.0365 - val_accuracy: 0.8918\n",
      "Epoch 27/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 00027: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 1.0982 - val_accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00028: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 19s 15ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.9885 - val_accuracy: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 00029: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 12ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 1.4968 - val_accuracy: 0.8881\n",
      "Epoch 30/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 00030: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.4694 - val_accuracy: 0.8971\n",
      "Epoch 31/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 00031: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 1.7242 - val_accuracy: 0.8856\n",
      "Epoch 32/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 00032: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.5549 - val_accuracy: 0.8853\n",
      "Epoch 33/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 00033: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 1.6074 - val_accuracy: 0.8856\n",
      "Epoch 34/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9985\n",
      "Epoch 00034: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 1.9014 - val_accuracy: 0.8869\n",
      "Epoch 35/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 00035: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 1.4034 - val_accuracy: 0.8936\n",
      "Epoch 36/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 00036: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 1.1590 - val_accuracy: 0.9032\n",
      "Epoch 37/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 00037: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 1.5948 - val_accuracy: 0.8871\n",
      "Epoch 38/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 00038: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 1.8706 - val_accuracy: 0.8880\n",
      "Epoch 39/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 00039: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 1.6723 - val_accuracy: 0.8866\n",
      "Epoch 40/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00040: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 1.9079 - val_accuracy: 0.8892\n",
      "Epoch 41/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00041: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 12ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 1.9543 - val_accuracy: 0.8882\n",
      "Epoch 42/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 00042: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 15s 12ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 1.7118 - val_accuracy: 0.8844\n",
      "Epoch 43/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00043: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 2.1106 - val_accuracy: 0.8774\n",
      "Epoch 44/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9988\n",
      "Epoch 00044: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 15s 12ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 2.0909 - val_accuracy: 0.8800\n",
      "Epoch 45/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 00045: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.8775 - val_accuracy: 0.8903\n",
      "Epoch 46/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 00046: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 2.3765 - val_accuracy: 0.8895\n",
      "Epoch 47/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 00047: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.7609 - val_accuracy: 0.8894\n",
      "Epoch 48/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 00048: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 15s 12ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.5818 - val_accuracy: 0.9055\n",
      "Epoch 49/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 00049: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.9536 - val_accuracy: 0.8923\n",
      "Epoch 50/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9988\n",
      "Epoch 00050: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.6525 - val_accuracy: 0.8985\n",
      "Epoch 51/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 00051: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 1.8848 - val_accuracy: 0.8944\n",
      "Epoch 52/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n",
      "Epoch 00052: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 2.2048 - val_accuracy: 0.8872\n",
      "Epoch 53/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 00053: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 2.4314 - val_accuracy: 0.8850\n",
      "Epoch 54/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 00054: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 1.8349 - val_accuracy: 0.8994\n",
      "Epoch 55/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9988\n",
      "Epoch 00055: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 2.4476 - val_accuracy: 0.8880\n",
      "Epoch 56/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9986 ETA: 0s - loss: 0.0031 - accuracy: 0.\n",
      "Epoch 00056: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 1.8817 - val_accuracy: 0.8876\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9988\n",
      "Epoch 00057: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 1.7296 - val_accuracy: 0.8907\n",
      "Epoch 58/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 00058: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.9995 - val_accuracy: 0.8911\n",
      "Epoch 59/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 00059: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 2.0242 - val_accuracy: 0.8876\n",
      "Epoch 60/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9985 ETA: 0s - loss: 0.0035 - accu\n",
      "Epoch 00060: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 1.8786 - val_accuracy: 0.8925\n",
      "Epoch 61/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9988\n",
      "Epoch 00061: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.7561 - val_accuracy: 0.8975\n",
      "Epoch 62/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00062: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.3012 - val_accuracy: 0.8933\n",
      "Epoch 63/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n",
      "Epoch 00063: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 2.2693 - val_accuracy: 0.8891\n",
      "Epoch 64/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00064: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 2.3218 - val_accuracy: 0.8863\n",
      "Epoch 65/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 00065: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 15s 12ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 2.6546 - val_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 00066: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 14s 11ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 2.6286 - val_accuracy: 0.8862\n",
      "Epoch 67/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00067: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.5245 - val_accuracy: 0.8924\n",
      "Epoch 68/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 00068: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.3797 - val_accuracy: 0.8933\n",
      "Epoch 69/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 00069: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 3.1887 - val_accuracy: 0.8890\n",
      "Epoch 70/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9988\n",
      "Epoch 00070: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 2.7924 - val_accuracy: 0.8869\n",
      "Epoch 71/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00071: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 2.2742 - val_accuracy: 0.8905\n",
      "Epoch 72/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00072: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.6044 - val_accuracy: 0.8847\n",
      "Epoch 73/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 00073: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 2.6291 - val_accuracy: 0.8777\n",
      "Epoch 74/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n",
      "Epoch 00074: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 2.4617 - val_accuracy: 0.8830\n",
      "Epoch 75/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 00075: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 2.1298 - val_accuracy: 0.8877\n",
      "Epoch 76/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 00076: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 2.5642 - val_accuracy: 0.8901\n",
      "Epoch 77/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00077: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 2.3244 - val_accuracy: 0.8877\n",
      "Epoch 78/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n",
      "Epoch 00078: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.3785 - val_accuracy: 0.8899\n",
      "Epoch 79/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9988\n",
      "Epoch 00079: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 2.3416 - val_accuracy: 0.8808\n",
      "Epoch 80/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00080: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 2.3555 - val_accuracy: 0.8914\n",
      "Epoch 81/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9989\n",
      "Epoch 00081: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 2.2191 - val_accuracy: 0.8867\n",
      "Epoch 82/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9989\n",
      "Epoch 00082: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 2.0652 - val_accuracy: 0.8905\n",
      "Epoch 83/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00083: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.9357 - val_accuracy: 0.8897\n",
      "Epoch 84/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9988\n",
      "Epoch 00084: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.9082 - val_accuracy: 0.8867\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 00085: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 2.7560 - val_accuracy: 0.8844\n",
      "Epoch 86/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00086: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 11ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 2.6009 - val_accuracy: 0.8840\n",
      "Epoch 87/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 00087: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 2.5344 - val_accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00088: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.7876 - val_accuracy: 0.8870\n",
      "Epoch 89/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00089: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.6397 - val_accuracy: 0.8914\n",
      "Epoch 90/100\n",
      "1229/1235 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 00090: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 2.6967 - val_accuracy: 0.8911\n",
      "Epoch 91/100\n",
      "1232/1235 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n",
      "Epoch 00091: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 2.2542 - val_accuracy: 0.8922\n",
      "Epoch 92/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 00092: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 2.6847 - val_accuracy: 0.8870\n",
      "Epoch 93/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00093: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.9073 - val_accuracy: 0.8952\n",
      "Epoch 94/100\n",
      "1231/1235 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 00094: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 2.8038 - val_accuracy: 0.8863\n",
      "Epoch 95/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00095: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.7007 - val_accuracy: 0.8918\n",
      "Epoch 96/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 00096: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 3.3810 - val_accuracy: 0.8864\n",
      "Epoch 97/100\n",
      "1235/1235 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 00097: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 2.7718 - val_accuracy: 0.8966\n",
      "Epoch 98/100\n",
      "1230/1235 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9989\n",
      "Epoch 00098: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 12s 10ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 2.7295 - val_accuracy: 0.8985\n",
      "Epoch 99/100\n",
      "1233/1235 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 00099: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 2.5539 - val_accuracy: 0.8912\n",
      "Epoch 100/100\n",
      "1234/1235 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 00100: val_accuracy did not improve from 0.91551\n",
      "1235/1235 [==============================] - 13s 10ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 2.5644 - val_accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "#Treino\n",
    "checkpointerProbe = callbacks.ModelCheckpoint(filepath=\"results/checkpointProbe-best.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n",
    "csv_loggerProbe = CSVLogger('results/cnntrainanalysisprobe2.csv',separator=',', append=False)\n",
    "cnnProbe.fit(x_Probe_train, Y_Probe2, batch_size=64, epochs=100, validation_data=(x_Probe_val, Y_Probe_test2), callbacks=[checkpointerProbe,csv_loggerProbe])\n",
    "cnnProbe.save(\"results/cnn_Probe_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnProbe.load_weights(\"results/checkpointProbe-best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9388</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702</td>\n",
       "      <td>1719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks   0.0   1.0\n",
       "Actual attacks               \n",
       "0                  9388   323\n",
       "1                   702  1719"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Probe_pred= cnnProbe.predict(x_Probe_val)\n",
    "y_Probe_pred = np.around(np.reshape(y_Probe_pred, y_Probe_pred.shape[0]))\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_Probe_test2, y_Probe_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.915513\n",
      "racall\n",
      "0.710037\n",
      "precision\n",
      "0.841822\n",
      "f1score\n",
      "0.770334\n"
     ]
    }
   ],
   "source": [
    "accuracyProbe = accuracy_score(Y_Probe_test2, y_Probe_pred)\n",
    "recallProbe = recall_score(Y_Probe_test2, y_Probe_pred, average=\"binary\")\n",
    "precisionProbe = precision_score(Y_Probe_test2, y_Probe_pred, average=\"binary\")\n",
    "f1Probe = f1_score(Y_Probe_test2, y_Probe_pred, average=\"binary\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracyProbe)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recallProbe)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precisionProbe)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1Probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normal vs R2L</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_R2L (68338, 122)\n",
      "Dimensões de X_R2L (12596, 122)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensões de X_R2L', X_R2L.shape)\n",
    "print('Dimensões de X_R2L', X_R2L_test.shape)\n",
    "Y_R2L2 = Y_R2L.replace(3,1)\n",
    "Y_R2L_test2 = Y_R2L_test.replace(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'Probe'\n",
    "cnnR2L = Sequential()\n",
    "cnnR2L.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnR2L.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnR2L.add(MaxPooling1D(pool_size=2))\n",
    "cnnR2L.add(Flatten())\n",
    "cnnR2L.add(Dense(128, activation=\"relu\"))\n",
    "cnnR2L.add(Dropout(0.5))\n",
    "cnnR2L.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "cnnR2L.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_R2L_train = np.reshape(X_R2L, (X_R2L.shape[0], X_R2L.shape[1], 1))\n",
    "x_R2L_val = np.reshape(X_R2L_test, (X_R2L_test.shape[0], X_R2L_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0068 - auc: 0.9960\n",
      "Epoch 00001: val_auc improved from -inf to 0.55877, saving model to results/checkpointR2L-best.hdf5\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0067 - auc: 0.9960 - val_loss: 3.7942 - val_auc: 0.5588\n",
      "Epoch 2/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0069 - auc: 0.9955\n",
      "Epoch 00002: val_auc improved from 0.55877 to 0.60344, saving model to results/checkpointR2L-best.hdf5\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0069 - auc: 0.9955 - val_loss: 3.2198 - val_auc: 0.6034\n",
      "Epoch 3/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0062 - auc: 0.9990\n",
      "Epoch 00003: val_auc did not improve from 0.60344\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0062 - auc: 0.9990 - val_loss: 4.2447 - val_auc: 0.5402\n",
      "Epoch 4/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0070 - auc: 0.9975\n",
      "Epoch 00004: val_auc improved from 0.60344 to 0.62545, saving model to results/checkpointR2L-best.hdf5\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0070 - auc: 0.9975 - val_loss: 3.4168 - val_auc: 0.6254\n",
      "Epoch 5/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0061 - auc: 0.9975\n",
      "Epoch 00005: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0061 - auc: 0.9976 - val_loss: 4.6654 - val_auc: 0.5510\n",
      "Epoch 6/100\n",
      "1063/1068 [============================>.] - ETA: 0s - loss: 0.0056 - auc: 0.9986\n",
      "Epoch 00006: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 11s 11ms/step - loss: 0.0056 - auc: 0.9986 - val_loss: 4.5481 - val_auc: 0.5156\n",
      "Epoch 7/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0054 - auc: 0.9971\n",
      "Epoch 00007: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0054 - auc: 0.9971 - val_loss: 4.6063 - val_auc: 0.5527\n",
      "Epoch 8/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0057 - auc: 0.9977\n",
      "Epoch 00008: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0057 - auc: 0.9977 - val_loss: 4.8748 - val_auc: 0.5487\n",
      "Epoch 9/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0053 - auc: 0.9972\n",
      "Epoch 00009: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0053 - auc: 0.9972 - val_loss: 4.6408 - val_auc: 0.5364\n",
      "Epoch 10/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0050 - auc: 0.9967\n",
      "Epoch 00010: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0051 - auc: 0.9967 - val_loss: 4.7312 - val_auc: 0.5404\n",
      "Epoch 11/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0055 - auc: 0.9972\n",
      "Epoch 00011: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0055 - auc: 0.9972 - val_loss: 3.8536 - val_auc: 0.6060\n",
      "Epoch 12/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0052 - auc: 0.9977\n",
      "Epoch 00012: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0052 - auc: 0.9977 - val_loss: 4.3676 - val_auc: 0.5519\n",
      "Epoch 13/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0049 - auc: 0.9972\n",
      "Epoch 00013: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0049 - auc: 0.9972 - val_loss: 4.7989 - val_auc: 0.5811\n",
      "Epoch 14/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0048 - auc: 0.9982\n",
      "Epoch 00014: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0048 - auc: 0.9982 - val_loss: 4.6847 - val_auc: 0.5837\n",
      "Epoch 15/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0044 - auc: 0.9988\n",
      "Epoch 00015: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0044 - auc: 0.9988 - val_loss: 4.2841 - val_auc: 0.5697\n",
      "Epoch 16/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0049 - auc: 0.9987- ETA: 0s - loss: 0.00\n",
      "Epoch 00016: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0049 - auc: 0.9987 - val_loss: 5.6823 - val_auc: 0.5215\n",
      "Epoch 17/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0046 - auc: 0.9973\n",
      "Epoch 00017: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0046 - auc: 0.9973 - val_loss: 5.7375 - val_auc: 0.5258\n",
      "Epoch 18/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0042 - auc: 0.9993\n",
      "Epoch 00018: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0042 - auc: 0.9993 - val_loss: 5.9143 - val_auc: 0.5494\n",
      "Epoch 19/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0044 - auc: 0.9978\n",
      "Epoch 00019: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 13ms/step - loss: 0.0044 - auc: 0.9978 - val_loss: 3.7773 - val_auc: 0.6075\n",
      "Epoch 20/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0043 - auc: 0.9988\n",
      "Epoch 00020: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0044 - auc: 0.9988 - val_loss: 5.3490 - val_auc: 0.5516\n",
      "Epoch 21/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0037 - auc: 0.9993\n",
      "Epoch 00021: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0037 - auc: 0.9993 - val_loss: 5.2066 - val_auc: 0.5738\n",
      "Epoch 22/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0041 - auc: 0.9988\n",
      "Epoch 00022: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0041 - auc: 0.9988 - val_loss: 5.3291 - val_auc: 0.5406\n",
      "Epoch 23/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0045 - auc: 0.9978\n",
      "Epoch 00023: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0045 - auc: 0.9978 - val_loss: 5.8288 - val_auc: 0.5618\n",
      "Epoch 24/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0038 - auc: 0.9998\n",
      "Epoch 00024: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 13ms/step - loss: 0.0039 - auc: 0.9998 - val_loss: 6.7621 - val_auc: 0.5435\n",
      "Epoch 25/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0045 - auc: 0.9973\n",
      "Epoch 00025: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0045 - auc: 0.9973 - val_loss: 5.5557 - val_auc: 0.5500\n",
      "Epoch 26/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0033 - auc: 0.9994\n",
      "Epoch 00026: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0033 - auc: 0.9994 - val_loss: 5.9007 - val_auc: 0.5838\n",
      "Epoch 27/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0038 - auc: 0.9993\n",
      "Epoch 00027: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0038 - auc: 0.9993 - val_loss: 6.8775 - val_auc: 0.5632\n",
      "Epoch 28/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0040 - auc: 0.9978\n",
      "Epoch 00028: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0040 - auc: 0.9978 - val_loss: 6.1183 - val_auc: 0.5606\n",
      "Epoch 29/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0036 - auc: 0.9989\n",
      "Epoch 00029: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0036 - auc: 0.9989 - val_loss: 6.1269 - val_auc: 0.5661\n",
      "Epoch 30/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0035 - auc: 0.9994\n",
      "Epoch 00030: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0035 - auc: 0.9994 - val_loss: 5.7313 - val_auc: 0.5937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0036 - auc: 0.9989\n",
      "Epoch 00031: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0036 - auc: 0.9989 - val_loss: 7.5212 - val_auc: 0.5373\n",
      "Epoch 32/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0044 - auc: 0.9988\n",
      "Epoch 00032: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0044 - auc: 0.9988 - val_loss: 6.8547 - val_auc: 0.5569\n",
      "Epoch 33/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0041 - auc: 0.9973\n",
      "Epoch 00033: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0041 - auc: 0.9973 - val_loss: 6.5453 - val_auc: 0.5713\n",
      "Epoch 34/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0037 - auc: 0.9989\n",
      "Epoch 00034: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0037 - auc: 0.9989 - val_loss: 7.3569 - val_auc: 0.5537\n",
      "Epoch 35/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0036 - auc: 0.9994- ETA: \n",
      "Epoch 00035: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0037 - auc: 0.9988 - val_loss: 6.8747 - val_auc: 0.5598\n",
      "Epoch 36/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0038 - auc: 0.9988- ETA:\n",
      "Epoch 00036: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0038 - auc: 0.9988 - val_loss: 5.2010 - val_auc: 0.5795\n",
      "Epoch 37/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0037 - auc: 0.9984\n",
      "Epoch 00037: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0037 - auc: 0.9984 - val_loss: 6.0453 - val_auc: 0.5669\n",
      "Epoch 38/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0038 - auc: 0.9973\n",
      "Epoch 00038: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0038 - auc: 0.9974 - val_loss: 6.1515 - val_auc: 0.5723\n",
      "Epoch 39/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0036 - auc: 0.9978\n",
      "Epoch 00039: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0036 - auc: 0.9979 - val_loss: 5.5752 - val_auc: 0.5744\n",
      "Epoch 40/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0036 - auc: 0.9989\n",
      "Epoch 00040: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0036 - auc: 0.9989 - val_loss: 7.4033 - val_auc: 0.5744\n",
      "Epoch 41/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0035 - auc: 0.9999\n",
      "Epoch 00041: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0035 - auc: 0.9999 - val_loss: 7.4073 - val_auc: 0.5681\n",
      "Epoch 42/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0034 - auc: 0.9989\n",
      "Epoch 00042: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0034 - auc: 0.9989 - val_loss: 8.0318 - val_auc: 0.5389\n",
      "Epoch 43/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0037 - auc: 0.9993\n",
      "Epoch 00043: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0037 - auc: 0.9993 - val_loss: 6.7367 - val_auc: 0.5519\n",
      "Epoch 44/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0039 - auc: 0.9983\n",
      "Epoch 00044: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 13ms/step - loss: 0.0040 - auc: 0.9983 - val_loss: 9.2824 - val_auc: 0.5205\n",
      "Epoch 45/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0035 - auc: 0.9999\n",
      "Epoch 00045: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0035 - auc: 0.9999 - val_loss: 7.5410 - val_auc: 0.5623\n",
      "Epoch 46/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0031 - auc: 0.9994\n",
      "Epoch 00046: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0031 - auc: 0.9994 - val_loss: 7.2141 - val_auc: 0.5666\n",
      "Epoch 47/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0034 - auc: 0.9994\n",
      "Epoch 00047: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0034 - auc: 0.9994 - val_loss: 6.7933 - val_auc: 0.5762\n",
      "Epoch 48/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0033 - auc: 0.9989\n",
      "Epoch 00048: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0033 - auc: 0.9989 - val_loss: 10.1788 - val_auc: 0.4973\n",
      "Epoch 49/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0035 - auc: 0.9979\n",
      "Epoch 00049: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0035 - auc: 0.9979 - val_loss: 7.6677 - val_auc: 0.5305\n",
      "Epoch 50/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0038 - auc: 0.9988\n",
      "Epoch 00050: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0038 - auc: 0.9988 - val_loss: 8.3589 - val_auc: 0.5492\n",
      "Epoch 51/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0030 - auc: 0.9984- ETA: 1s - loss: \n",
      "Epoch 00051: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0030 - auc: 0.9984 - val_loss: 8.7914 - val_auc: 0.5431\n",
      "Epoch 52/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0028 - auc: 0.9994\n",
      "Epoch 00052: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0028 - auc: 0.9994 - val_loss: 9.8563 - val_auc: 0.5286\n",
      "Epoch 53/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0032 - auc: 0.9984\n",
      "Epoch 00053: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0032 - auc: 0.9984 - val_loss: 8.3704 - val_auc: 0.5305\n",
      "Epoch 54/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0032 - auc: 0.9989\n",
      "Epoch 00054: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0032 - auc: 0.9989 - val_loss: 6.5580 - val_auc: 0.5729\n",
      "Epoch 55/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0032 - auc: 0.9989\n",
      "Epoch 00055: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 14ms/step - loss: 0.0032 - auc: 0.9989 - val_loss: 7.2274 - val_auc: 0.5483\n",
      "Epoch 56/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0038 - auc: 0.9993\n",
      "Epoch 00056: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0038 - auc: 0.9994 - val_loss: 7.7218 - val_auc: 0.5530\n",
      "Epoch 57/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0027 - auc: 0.9994\n",
      "Epoch 00057: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0027 - auc: 0.9994 - val_loss: 7.2019 - val_auc: 0.5739\n",
      "Epoch 58/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0037 - auc: 0.9983\n",
      "Epoch 00058: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0037 - auc: 0.9983 - val_loss: 7.1461 - val_auc: 0.5656\n",
      "Epoch 59/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0030 - auc: 0.9999- ETA: 0s - loss: 0.0029 - auc: 0\n",
      "Epoch 00059: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0030 - auc: 0.9999 - val_loss: 7.2914 - val_auc: 0.5736\n",
      "Epoch 60/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0035 - auc: 0.9984\n",
      "Epoch 00060: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0035 - auc: 0.9984 - val_loss: 6.9103 - val_auc: 0.5827\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0041 - auc: 0.9983\n",
      "Epoch 00061: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0041 - auc: 0.9984 - val_loss: 6.4902 - val_auc: 0.5691\n",
      "Epoch 62/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0027 - auc: 0.9994\n",
      "Epoch 00062: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0027 - auc: 0.9994 - val_loss: 9.3618 - val_auc: 0.5604\n",
      "Epoch 63/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0036 - auc: 0.9989\n",
      "Epoch 00063: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0036 - auc: 0.9989 - val_loss: 6.7008 - val_auc: 0.5934\n",
      "Epoch 64/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0029 - auc: 0.9994\n",
      "Epoch 00064: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 14ms/step - loss: 0.0029 - auc: 0.9994 - val_loss: 8.2452 - val_auc: 0.5529\n",
      "Epoch 65/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0033 - auc: 0.9994\n",
      "Epoch 00065: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0033 - auc: 0.9994 - val_loss: 7.6099 - val_auc: 0.5541\n",
      "Epoch 66/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0031 - auc: 0.9984\n",
      "Epoch 00066: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0031 - auc: 0.9984 - val_loss: 6.4034 - val_auc: 0.5899\n",
      "Epoch 67/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0031 - auc: 0.9989\n",
      "Epoch 00067: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0031 - auc: 0.9989 - val_loss: 9.0252 - val_auc: 0.5168\n",
      "Epoch 68/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0030 - auc: 0.9984\n",
      "Epoch 00068: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 13ms/step - loss: 0.0030 - auc: 0.9984 - val_loss: 7.3442 - val_auc: 0.5494\n",
      "Epoch 69/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0031 - auc: 0.9974\n",
      "Epoch 00069: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0032 - auc: 0.9974 - val_loss: 6.0818 - val_auc: 0.5891\n",
      "Epoch 70/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0027 - auc: 0.9994\n",
      "Epoch 00070: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0027 - auc: 0.9994 - val_loss: 7.0275 - val_auc: 0.5878\n",
      "Epoch 71/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0034 - auc: 0.9974\n",
      "Epoch 00071: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0034 - auc: 0.9974 - val_loss: 7.1801 - val_auc: 0.5834\n",
      "Epoch 72/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0030 - auc: 0.9989\n",
      "Epoch 00072: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0030 - auc: 0.9989 - val_loss: 8.6988 - val_auc: 0.5843\n",
      "Epoch 73/100\n",
      "1063/1068 [============================>.] - ETA: 0s - loss: 0.0030 - auc: 0.9984\n",
      "Epoch 00073: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0030 - auc: 0.9984 - val_loss: 7.9891 - val_auc: 0.5722\n",
      "Epoch 74/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0025 - auc: 0.9999\n",
      "Epoch 00074: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0025 - auc: 0.9999 - val_loss: 8.2872 - val_auc: 0.5683\n",
      "Epoch 75/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0027 - auc: 0.9994\n",
      "Epoch 00075: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0029 - auc: 0.9989 - val_loss: 10.0562 - val_auc: 0.5259\n",
      "Epoch 76/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0028 - auc: 0.9994\n",
      "Epoch 00076: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0028 - auc: 0.9994 - val_loss: 8.8799 - val_auc: 0.5560\n",
      "Epoch 77/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0029 - auc: 0.9989\n",
      "Epoch 00077: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0029 - auc: 0.9989 - val_loss: 8.0540 - val_auc: 0.5741\n",
      "Epoch 78/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0030 - auc: 0.9984\n",
      "Epoch 00078: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 13ms/step - loss: 0.0030 - auc: 0.9984 - val_loss: 8.8409 - val_auc: 0.5678\n",
      "Epoch 79/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0030 - auc: 0.9989\n",
      "Epoch 00079: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0030 - auc: 0.9989 - val_loss: 6.9434 - val_auc: 0.5771\n",
      "Epoch 80/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0031 - auc: 0.9994\n",
      "Epoch 00080: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 13ms/step - loss: 0.0031 - auc: 0.9994 - val_loss: 6.4024 - val_auc: 0.5910\n",
      "Epoch 81/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0026 - auc: 0.9989\n",
      "Epoch 00081: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0027 - auc: 0.9984 - val_loss: 7.7009 - val_auc: 0.5836\n",
      "Epoch 82/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0027 - auc: 0.9989\n",
      "Epoch 00082: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0027 - auc: 0.9989 - val_loss: 6.6292 - val_auc: 0.5783\n",
      "Epoch 83/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0028 - auc: 0.9989\n",
      "Epoch 00083: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0028 - auc: 0.9989 - val_loss: 6.5755 - val_auc: 0.5825\n",
      "Epoch 84/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0030 - auc: 0.9989\n",
      "Epoch 00084: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 15s 14ms/step - loss: 0.0030 - auc: 0.9989 - val_loss: 8.0691 - val_auc: 0.5685\n",
      "Epoch 85/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0039 - auc: 0.9969\n",
      "Epoch 00085: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0039 - auc: 0.9969 - val_loss: 7.8183 - val_auc: 0.6197\n",
      "Epoch 86/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0030 - auc: 0.9989\n",
      "Epoch 00086: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0030 - auc: 0.9989 - val_loss: 10.3488 - val_auc: 0.5370\n",
      "Epoch 87/100\n",
      "1065/1068 [============================>.] - ETA: 0s - loss: 0.0029 - auc: 0.9989\n",
      "Epoch 00087: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0029 - auc: 0.9989 - val_loss: 9.0511 - val_auc: 0.5466\n",
      "Epoch 88/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0024 - auc: 0.9994\n",
      "Epoch 00088: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0024 - auc: 0.9994 - val_loss: 8.2522 - val_auc: 0.5671\n",
      "Epoch 89/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0027 - auc: 0.9989\n",
      "Epoch 00089: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0027 - auc: 0.9989 - val_loss: 7.9560 - val_auc: 0.5602\n",
      "Epoch 90/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0025 - auc: 0.9994\n",
      "Epoch 00090: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0025 - auc: 0.9994 - val_loss: 11.4887 - val_auc: 0.5457\n",
      "Epoch 91/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0029 - auc: 0.9994\n",
      "Epoch 00091: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0029 - auc: 0.9994 - val_loss: 9.0142 - val_auc: 0.5579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0034 - auc: 0.9974\n",
      "Epoch 00092: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0034 - auc: 0.9974 - val_loss: 7.8247 - val_auc: 0.5631\n",
      "Epoch 93/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0023 - auc: 0.9999\n",
      "Epoch 00093: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0023 - auc: 0.9999 - val_loss: 9.6938 - val_auc: 0.5236\n",
      "Epoch 94/100\n",
      "1064/1068 [============================>.] - ETA: 0s - loss: 0.0029 - auc: 0.9984\n",
      "Epoch 00094: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0029 - auc: 0.9984 - val_loss: 8.5622 - val_auc: 0.5399\n",
      "Epoch 95/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0027 - auc: 0.9999\n",
      "Epoch 00095: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 14s 13ms/step - loss: 0.0027 - auc: 0.9999 - val_loss: 8.4448 - val_auc: 0.5398\n",
      "Epoch 96/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0029 - auc: 0.9994\n",
      "Epoch 00096: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 13s 12ms/step - loss: 0.0029 - auc: 0.9994 - val_loss: 13.4615 - val_auc: 0.5121\n",
      "Epoch 97/100\n",
      "1066/1068 [============================>.] - ETA: 0s - loss: 0.0027 - auc: 0.9994\n",
      "Epoch 00097: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0027 - auc: 0.9994 - val_loss: 8.5572 - val_auc: 0.5388\n",
      "Epoch 98/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0025 - auc: 0.9989\n",
      "Epoch 00098: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0025 - auc: 0.9989 - val_loss: 7.7729 - val_auc: 0.5543\n",
      "Epoch 99/100\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.0026 - auc: 0.9984\n",
      "Epoch 00099: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 12ms/step - loss: 0.0026 - auc: 0.9984 - val_loss: 8.7680 - val_auc: 0.5575\n",
      "Epoch 100/100\n",
      "1067/1068 [============================>.] - ETA: 0s - loss: 0.0043 - auc: 0.9968\n",
      "Epoch 00100: val_auc did not improve from 0.62545\n",
      "1068/1068 [==============================] - 12s 11ms/step - loss: 0.0043 - auc: 0.9968 - val_loss: 9.8864 - val_auc: 0.5243\n"
     ]
    }
   ],
   "source": [
    "#Treino\n",
    "checkpointerR2L = callbacks.ModelCheckpoint(filepath=\"results/checkpointR2L-best.hdf5\", verbose=1, save_best_only=True, monitor='val_auc',mode='max')\n",
    "csv_loggerR2L = CSVLogger('results/cnntrainanalysir2l2.csv',separator=',', append=False)\n",
    "cnnR2L.fit(x_R2L_train, Y_R2L2, batch_size=64, epochs=100, validation_data=(x_R2L_val, Y_R2L_test2), callbacks=[checkpointerR2L,csv_loggerR2L])\n",
    "cnnR2L.save(\"results/cnn_R2L_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnR2L.load_weights(\"results/checkpointR2L-best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9645</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2716</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks   0.0  1.0\n",
       "Actual attacks              \n",
       "0                  9645   66\n",
       "1                  2716  169"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_R2L_pred= cnnR2L.predict(x_R2L_val)\n",
    "y_R2L_pred = np.around(np.reshape(y_R2L_pred, y_R2L_pred.shape[0]))\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_R2L_test2, y_R2L_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.779136\n",
      "racall\n",
      "0.058579\n",
      "precision\n",
      "0.719149\n",
      "f1score\n",
      "0.108333\n"
     ]
    }
   ],
   "source": [
    "accuracyR2L = accuracy_score(Y_R2L_test2, y_R2L_pred)\n",
    "recallR2L = recall_score(Y_R2L_test2, y_R2L_pred, average=\"binary\")\n",
    "precisionR2L = precision_score(Y_R2L_test2, y_R2L_pred, average=\"binary\")\n",
    "f1R2L = f1_score(Y_R2L_test2, y_R2L_pred, average=\"binary\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracyR2L)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recallR2L)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precisionR2L)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1R2L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normal vs U2R</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_U2R (67395, 122)\n",
      "Dimensões de X_U2R_test (9778, 122)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensões de X_U2R', X_U2R.shape)\n",
    "print('Dimensões de X_U2R_test', X_U2R_test.shape)\n",
    "Y_U2R2 = Y_U2R.replace(4,1)\n",
    "Y_U2R_test2 = Y_U2R_test.replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN para classificação de amostras entre 'Normal' e 'Probe'\n",
    "cnnU2R = Sequential()\n",
    "cnnU2R.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(122, 1)))\n",
    "cnnU2R.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\"))\n",
    "cnnU2R.add(MaxPooling1D(pool_size=2))\n",
    "cnnU2R.add(Flatten())\n",
    "cnnU2R.add(Dense(128, activation=\"relu\"))\n",
    "cnnU2R.add(Dropout(0.5))\n",
    "cnnU2R.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnU2R.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionando dados para o modelo\n",
    "x_U2R_train = np.reshape(X_U2R, (X_U2R.shape[0], X_U2R.shape[1], 1))\n",
    "x_U2R_val = np.reshape(X_U2R_test, (X_U2R_test.shape[0], X_U2R_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9985 ETA: 0s - loss:\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99315, saving model to results/checkpointU2R-best.hdf5\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0893 - val_accuracy: 0.9931\n",
      "Epoch 2/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 00002: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1104 - val_accuracy: 0.9931\n",
      "Epoch 3/100\n",
      "1048/1054 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00003: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1503 - val_accuracy: 0.9928\n",
      "Epoch 4/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 00004: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1636 - val_accuracy: 0.9928\n",
      "Epoch 5/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00005: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 13ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1637 - val_accuracy: 0.9931\n",
      "Epoch 6/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 00006: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1774 - val_accuracy: 0.9931\n",
      "Epoch 7/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00007: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2124 - val_accuracy: 0.9929\n",
      "Epoch 8/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00008: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1813 - val_accuracy: 0.9929\n",
      "Epoch 9/100\n",
      "1048/1054 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00009: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1891 - val_accuracy: 0.9930\n",
      "Epoch 10/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00010: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2396 - val_accuracy: 0.9930\n",
      "Epoch 11/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00011: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1671 - val_accuracy: 0.9929\n",
      "Epoch 12/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00012: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2585 - val_accuracy: 0.9929\n",
      "Epoch 13/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00013: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1782 - val_accuracy: 0.9930\n",
      "Epoch 14/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00014: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2705 - val_accuracy: 0.9929\n",
      "Epoch 15/100\n",
      "1049/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00015: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2229 - val_accuracy: 0.9929\n",
      "Epoch 16/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00016: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2223 - val_accuracy: 0.9929\n",
      "Epoch 17/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00017: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.2895 - val_accuracy: 0.9927\n",
      "Epoch 18/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00018: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3090 - val_accuracy: 0.9925\n",
      "Epoch 19/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00019: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2766 - val_accuracy: 0.9929\n",
      "Epoch 20/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00020: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2649 - val_accuracy: 0.9926\n",
      "Epoch 21/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00021: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2259 - val_accuracy: 0.9930\n",
      "Epoch 22/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00022: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3129 - val_accuracy: 0.9924\n",
      "Epoch 23/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00023: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.2366 - val_accuracy: 0.9929\n",
      "Epoch 24/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00024: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2266 - val_accuracy: 0.9924\n",
      "Epoch 25/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00025: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1784 - val_accuracy: 0.9924\n",
      "Epoch 26/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00026: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 14s 14ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2813 - val_accuracy: 0.9925\n",
      "Epoch 27/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00027: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2127 - val_accuracy: 0.9925\n",
      "Epoch 28/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00028: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2980 - val_accuracy: 0.9925\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048/1054 [============================>.] - ETA: 0s - loss: 9.8997e-04 - accuracy: 0.9998\n",
      "Epoch 00029: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 9.8899e-04 - accuracy: 0.9998 - val_loss: 0.2183 - val_accuracy: 0.9928\n",
      "Epoch 30/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00030: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2172 - val_accuracy: 0.9929\n",
      "Epoch 31/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00031: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.2215 - val_accuracy: 0.9925\n",
      "Epoch 32/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00032: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2423 - val_accuracy: 0.9926\n",
      "Epoch 33/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00033: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1992 - val_accuracy: 0.9924\n",
      "Epoch 34/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00034: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2664 - val_accuracy: 0.9925\n",
      "Epoch 35/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00035: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3271 - val_accuracy: 0.9931\n",
      "Epoch 36/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00036: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2844 - val_accuracy: 0.9923\n",
      "Epoch 37/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00037: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2943 - val_accuracy: 0.9929\n",
      "Epoch 38/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996 ETA: 0s - loss: 0.0017 - accuracy: \n",
      "Epoch 00038: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.2486 - val_accuracy: 0.9923\n",
      "Epoch 39/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00039: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.2589 - val_accuracy: 0.9925\n",
      "Epoch 40/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00040: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2461 - val_accuracy: 0.9923\n",
      "Epoch 41/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00041: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3860 - val_accuracy: 0.9930\n",
      "Epoch 42/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00042: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3716 - val_accuracy: 0.9930\n",
      "Epoch 43/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00043: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.2796 - val_accuracy: 0.9928\n",
      "Epoch 44/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00044: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2828 - val_accuracy: 0.9922\n",
      "Epoch 45/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00045: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3003 - val_accuracy: 0.9924\n",
      "Epoch 46/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00046: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3227 - val_accuracy: 0.9928\n",
      "Epoch 47/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00047: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2595 - val_accuracy: 0.9928\n",
      "Epoch 48/100\n",
      "1049/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00048: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2522 - val_accuracy: 0.9925\n",
      "Epoch 49/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 00049: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.3723 - val_accuracy: 0.9927\n",
      "Epoch 50/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00050: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2843 - val_accuracy: 0.9929\n",
      "Epoch 51/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00051: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 16s 16ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3260 - val_accuracy: 0.9928\n",
      "Epoch 52/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00052: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 14s 14ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3245 - val_accuracy: 0.9925\n",
      "Epoch 53/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00053: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3168 - val_accuracy: 0.9923\n",
      "Epoch 54/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00054: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3004 - val_accuracy: 0.9926\n",
      "Epoch 55/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00055: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2354 - val_accuracy: 0.9928\n",
      "Epoch 56/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00056: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3158 - val_accuracy: 0.9926\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00057: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.3082 - val_accuracy: 0.9922\n",
      "Epoch 58/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00058: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3307 - val_accuracy: 0.9925\n",
      "Epoch 59/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998 ETA: 0s - loss: 0.0010 - \n",
      "Epoch 00059: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3946 - val_accuracy: 0.9928\n",
      "Epoch 60/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00060: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3901 - val_accuracy: 0.9926\n",
      "Epoch 61/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997     ETA: 0s - loss: 9.5665e-0\n",
      "Epoch 00061: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3231 - val_accuracy: 0.9928\n",
      "Epoch 62/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00062: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3707 - val_accuracy: 0.9928\n",
      "Epoch 63/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00063: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 13ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4331 - val_accuracy: 0.9925\n",
      "Epoch 64/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 8.8528e-04 - accuracy: 0.9998\n",
      "Epoch 00064: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 8.8528e-04 - accuracy: 0.9998 - val_loss: 0.3785 - val_accuracy: 0.9928\n",
      "Epoch 65/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00065: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3649 - val_accuracy: 0.9925\n",
      "Epoch 66/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00066: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3211 - val_accuracy: 0.9928\n",
      "Epoch 67/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 9.9870e-04 - accuracy: 0.9997\n",
      "Epoch 00067: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 9.9771e-04 - accuracy: 0.9997 - val_loss: 0.3315 - val_accuracy: 0.9926\n",
      "Epoch 68/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997    \n",
      "Epoch 00068: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3163 - val_accuracy: 0.9923\n",
      "Epoch 69/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 9.4838e-04 - accuracy: 0.9997\n",
      "Epoch 00069: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 9.4834e-04 - accuracy: 0.9997 - val_loss: 0.4447 - val_accuracy: 0.9928\n",
      "Epoch 70/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 9.7053e-04 - accuracy: 0.9998\n",
      "Epoch 00070: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 9.7053e-04 - accuracy: 0.9998 - val_loss: 0.2734 - val_accuracy: 0.9927\n",
      "Epoch 71/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 9.5713e-04 - accuracy: 0.9998\n",
      "Epoch 00071: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 9.5852e-04 - accuracy: 0.9998 - val_loss: 0.2597 - val_accuracy: 0.9928\n",
      "Epoch 72/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00072: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4100 - val_accuracy: 0.9927\n",
      "Epoch 73/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 9.5220e-04 - accuracy: 0.9997\n",
      "Epoch 00073: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 9.5215e-04 - accuracy: 0.9997 - val_loss: 0.3899 - val_accuracy: 0.9924\n",
      "Epoch 74/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 9.1931e-04 - accuracy: 0.9997\n",
      "Epoch 00074: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 9.1927e-04 - accuracy: 0.9997 - val_loss: 0.3204 - val_accuracy: 0.9928\n",
      "Epoch 75/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3640 - val_accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00076: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.3045 - val_accuracy: 0.9929\n",
      "Epoch 77/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00077: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3094 - val_accuracy: 0.9928\n",
      "Epoch 78/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997 ETA: 0s - loss: 0\n",
      "Epoch 00078: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 13s 12ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4523 - val_accuracy: 0.9928\n",
      "Epoch 79/100\n",
      "1048/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00079: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4469 - val_accuracy: 0.9927\n",
      "Epoch 80/100\n",
      "1048/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997  \n",
      "Epoch 00080: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3204 - val_accuracy: 0.9927\n",
      "Epoch 81/100\n",
      "1049/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00081: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.3446 - val_accuracy: 0.9929\n",
      "Epoch 82/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 8.6345e-04 - accuracy: 0.9997\n",
      "Epoch 00082: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 8.6483e-04 - accuracy: 0.9997 - val_loss: 0.3331 - val_accuracy: 0.9923\n",
      "Epoch 83/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 9.5939e-04 - accuracy: 0.9997\n",
      "Epoch 00083: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 9.5891e-04 - accuracy: 0.9997 - val_loss: 0.3644 - val_accuracy: 0.9928\n",
      "Epoch 84/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00084: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3251 - val_accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "1051/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00085: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2341 - val_accuracy: 0.9926\n",
      "Epoch 86/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 8.5293e-04 - accuracy: 0.9998\n",
      "Epoch 00086: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 8.5047e-04 - accuracy: 0.9998 - val_loss: 0.3645 - val_accuracy: 0.9928\n",
      "Epoch 87/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 9.8957e-04 - accuracy: 0.9997\n",
      "Epoch 00087: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 9.8673e-04 - accuracy: 0.9997 - val_loss: 0.4653 - val_accuracy: 0.9925\n",
      "Epoch 88/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00088: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4301 - val_accuracy: 0.9924\n",
      "Epoch 89/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00089: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3329 - val_accuracy: 0.9927\n",
      "Epoch 90/100\n",
      "1049/1054 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00090: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 10ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3491 - val_accuracy: 0.9926\n",
      "Epoch 91/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00091: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3277 - val_accuracy: 0.9928\n",
      "Epoch 92/100\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00092: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.3988 - val_accuracy: 0.9929\n",
      "Epoch 93/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 9.5515e-04 - accuracy: 0.9997\n",
      "Epoch 00093: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 9.5515e-04 - accuracy: 0.9997 - val_loss: 0.4145 - val_accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "1050/1054 [============================>.] - ETA: 0s - loss: 8.7331e-04 - accuracy: 0.9997\n",
      "Epoch 00094: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 8.7269e-04 - accuracy: 0.9997 - val_loss: 0.3243 - val_accuracy: 0.9929\n",
      "Epoch 95/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 7.5740e-04 - accuracy: 0.9998\n",
      "Epoch 00095: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 7.5737e-04 - accuracy: 0.9998 - val_loss: 0.4443 - val_accuracy: 0.9929\n",
      "Epoch 96/100\n",
      "1048/1054 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00096: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.4519 - val_accuracy: 0.9929\n",
      "Epoch 97/100\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00097: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3493 - val_accuracy: 0.9923\n",
      "Epoch 98/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 00098: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 12ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.3265 - val_accuracy: 0.9924\n",
      "Epoch 99/100\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998 ETA\n",
      "Epoch 00099: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 12s 11ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4213 - val_accuracy: 0.9931\n",
      "Epoch 100/100\n",
      "1048/1054 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00100: val_accuracy did not improve from 0.99315\n",
      "1054/1054 [==============================] - 11s 11ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3337 - val_accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "#Treino\n",
    "checkpointerU2R = callbacks.ModelCheckpoint(filepath=\"results/checkpointU2R-best.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n",
    "csv_loggerU2R = CSVLogger('results/cnntrainanalysiU2R2.csv',separator=',', append=False)\n",
    "cnnU2R.fit(x_U2R_train, Y_U2R2, batch_size=64, epochs=100, validation_data=(x_U2R_val, Y_U2R_test2), callbacks=[checkpointerU2R,csv_loggerU2R])\n",
    "cnnU2R.save(\"results/cnn_U2R_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnU2R.load_weights(\"results/checkpointU2R-best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks   0.0\n",
       "Actual attacks         \n",
       "0                  9711\n",
       "1                    67"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_U2R_pred= cnnU2R.predict(x_U2R_val)\n",
    "y_U2R_pred = np.around(np.reshape(y_U2R_pred, y_U2R_pred.shape[0]))\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_U2R_test2, y_U2R_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.789933\n",
      "racall\n",
      "0.085269\n",
      "precision\n",
      "0.972332\n",
      "f1score\n",
      "0.156788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pedro\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracyU2R = accuracy_score(Y_U2R_test2, y_U2R_pred)\n",
    "recallU2R = recall_score(Y_U2R_test2, y_U2R_pred, average=\"binary\")\n",
    "precisionU2R = precision_score(Y_U2R_test2, y_U2R_pred, average=\"binary\")\n",
    "f1U2R = f1_score(Y_U2R_test2, y_U2R_pred, average=\"binary\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracyR2L)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recallR2L)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precisionR2L)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1R2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
